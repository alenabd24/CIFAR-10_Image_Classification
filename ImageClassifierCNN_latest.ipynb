{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVGJxwGtgLxx"
      },
      "source": [
        "# **Image Classification CNN - Alen Abdrakhamnov**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IaXeJfHNlef"
      },
      "source": [
        "###1. The first task is to create a DataLoader for the training & testing datasets, which should generate batches of examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCKSoQBWOJRc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hd8sDGPOxIz"
      },
      "source": [
        "transform ensures the PyTorch tensor is of correct shape (Channel, Height, Width), and scales values [-1,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJDfoaspOJ8l"
      },
      "source": [
        "Loading the CIFAR-10 datasets:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5daqhEjEPKOq"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# train dataset\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# testing dataset\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lB8PXIb2mAMH"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mb0MDrACPqPt"
      },
      "source": [
        "Fetching a batch of data from the training loader and printing the shape:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtxTKy-nP94x"
      },
      "source": [
        "The below was also done for test loader, to ensure the tensor shapes are equivalent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI5V9RyAPuQA",
        "outputId": "c99cf6a6-3851-4f0e-a665-6ca322d942d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128])\n"
          ]
        }
      ],
      "source": [
        "for images, labels in train_loader:\n",
        "    print(images.shape)  # (batch_size, 3, 32, 32)\n",
        "    print(labels.shape)  # (batch_size,)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxM4XbgMOJ-2"
      },
      "source": [
        "Creating DataLoaders:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29Xq9ZthP3VD"
      },
      "source": [
        "| Tensor | Shape           | Meaning                                                                          |\n",
        "|--------|-----------------|----------------------------------------------------------------------------------|\n",
        "| images | [128, 3, 32, 32] | 128 images, each with 3 channels (RGB), 32×32 pixels                              |\n",
        "| labels | [128]           | 128 integer labels (one for each image), values from 0–9 (CIFAR-10 classes)        |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBYL2hH3Piyg"
      },
      "source": [
        "Setting up intermediate block:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imIAK9ZkSIW-"
      },
      "outputs": [],
      "source": [
        "class IntermediateBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_convs, kernel_size=3):\n",
        "        super().__init__()\n",
        "        self.num_convs = num_convs\n",
        "\n",
        "\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=kernel_size // 2),\n",
        "                nn.BatchNorm2d(out_channels),  # Added BatchNorm and ReLU\n",
        "                nn.ReLU()\n",
        "            ) for _ in range(num_convs)\n",
        "        ])\n",
        "\n",
        "\n",
        "        self.weight_fc = nn.Linear(in_channels, num_convs) #fully connected layer\n",
        "        self.softmax = nn.Softmax(dim=1)  # softmax activation\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "\n",
        "        conv_outputs = [conv(x) for conv in self.convs]\n",
        "\n",
        "\n",
        "        m = x.mean(dim=[2, 3])  # channel wise input\n",
        "\n",
        "        a = self.weight_fc(m)  # fc to produce weights\n",
        "        a = self.softmax(a)    # softmax to get normalized weights\n",
        "\n",
        "        # Weighted sum of convolution outputs\n",
        "        a = a.view(batch_size, self.num_convs, 1, 1, 1)\n",
        "        stacked = torch.stack(conv_outputs, dim=1)\n",
        "        x_out = (a * stacked).sum(dim=1)\n",
        "\n",
        "        return x_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rCvx_0lPi0V"
      },
      "source": [
        "Output Block:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsQ18tS3Sil1"
      },
      "outputs": [],
      "source": [
        "class OutputBlock(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_dim=0, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        if hidden_dim > 0:\n",
        "            self.block = nn.Sequential(\n",
        "                nn.Linear(in_channels, hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "        else:\n",
        "            self.block = nn.Linear(in_channels, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        m = x.mean(dim=[2, 3])\n",
        "        return self.block(m)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIRJqF7pSkTo"
      },
      "source": [
        "Complete Architecture:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6dOhJ47Slpa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self, in_channels=3, num_blocks=7, num_convs_per_block=7,\n",
        "                 base_channels=32, num_classes=64, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.blocks = nn.ModuleList()\n",
        "        c_in = in_channels\n",
        "\n",
        "        channels = [base_channels for _ in range(num_blocks)] # constant channels\n",
        "\n",
        "        for i in range(num_blocks):\n",
        "            block = IntermediateBlock(\n",
        "                in_channels=c_in,\n",
        "                out_channels=channels[i],\n",
        "                num_convs=num_convs_per_block\n",
        "            )\n",
        "            self.blocks.append(block)\n",
        "            c_in = channels[i]  # constant channel count for next block\n",
        "\n",
        "        self.output_block = OutputBlock(\n",
        "            in_channels=channels[-1],\n",
        "            hidden_dim=hidden_dim,\n",
        "            num_classes=num_classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        return self.output_block(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XI3Tcm39VEjZ"
      },
      "source": [
        "Now we're ready to train the neural network. I'm using corss entropy loss for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB_nQ9CXDMeQ",
        "outputId": "67374821-33a2-4e5c-b747-1b6a50401293"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch [23/200] Batch [99/391] Loss: 0.2814\n",
            "Epoch [23/200] Batch [100/391] Loss: 0.1888\n",
            "Epoch [23/200] Batch [101/391] Loss: 0.1563\n",
            "Epoch [23/200] Batch [102/391] Loss: 0.1676\n",
            "Epoch [23/200] Batch [103/391] Loss: 0.2100\n",
            "Epoch [23/200] Batch [104/391] Loss: 0.2578\n",
            "Epoch [23/200] Batch [105/391] Loss: 0.1293\n",
            "Epoch [23/200] Batch [106/391] Loss: 0.1639\n",
            "Epoch [23/200] Batch [107/391] Loss: 0.2172\n",
            "Epoch [23/200] Batch [108/391] Loss: 0.1863\n",
            "Epoch [23/200] Batch [109/391] Loss: 0.1795\n",
            "Epoch [23/200] Batch [110/391] Loss: 0.2208\n",
            "Epoch [23/200] Batch [111/391] Loss: 0.2806\n",
            "Epoch [23/200] Batch [112/391] Loss: 0.0923\n",
            "Epoch [23/200] Batch [113/391] Loss: 0.1734\n",
            "Epoch [23/200] Batch [114/391] Loss: 0.1485\n",
            "Epoch [23/200] Batch [115/391] Loss: 0.1425\n",
            "Epoch [23/200] Batch [116/391] Loss: 0.1882\n",
            "Epoch [23/200] Batch [117/391] Loss: 0.1892\n",
            "Epoch [23/200] Batch [118/391] Loss: 0.1605\n",
            "Epoch [23/200] Batch [119/391] Loss: 0.1489\n",
            "Epoch [23/200] Batch [120/391] Loss: 0.2664\n",
            "Epoch [23/200] Batch [121/391] Loss: 0.1562\n",
            "Epoch [23/200] Batch [122/391] Loss: 0.1378\n",
            "Epoch [23/200] Batch [123/391] Loss: 0.1357\n",
            "Epoch [23/200] Batch [124/391] Loss: 0.1705\n",
            "Epoch [23/200] Batch [125/391] Loss: 0.2156\n",
            "Epoch [23/200] Batch [126/391] Loss: 0.2781\n",
            "Epoch [23/200] Batch [127/391] Loss: 0.1903\n",
            "Epoch [23/200] Batch [128/391] Loss: 0.1466\n",
            "Epoch [23/200] Batch [129/391] Loss: 0.1648\n",
            "Epoch [23/200] Batch [130/391] Loss: 0.1855\n",
            "Epoch [23/200] Batch [131/391] Loss: 0.1379\n",
            "Epoch [23/200] Batch [132/391] Loss: 0.1597\n",
            "Epoch [23/200] Batch [133/391] Loss: 0.2568\n",
            "Epoch [23/200] Batch [134/391] Loss: 0.1552\n",
            "Epoch [23/200] Batch [135/391] Loss: 0.1824\n",
            "Epoch [23/200] Batch [136/391] Loss: 0.2075\n",
            "Epoch [23/200] Batch [137/391] Loss: 0.1932\n",
            "Epoch [23/200] Batch [138/391] Loss: 0.1466\n",
            "Epoch [23/200] Batch [139/391] Loss: 0.1469\n",
            "Epoch [23/200] Batch [140/391] Loss: 0.2122\n",
            "Epoch [23/200] Batch [141/391] Loss: 0.2378\n",
            "Epoch [23/200] Batch [142/391] Loss: 0.2155\n",
            "Epoch [23/200] Batch [143/391] Loss: 0.2478\n",
            "Epoch [23/200] Batch [144/391] Loss: 0.1706\n",
            "Epoch [23/200] Batch [145/391] Loss: 0.1873\n",
            "Epoch [23/200] Batch [146/391] Loss: 0.1041\n",
            "Epoch [23/200] Batch [147/391] Loss: 0.1328\n",
            "Epoch [23/200] Batch [148/391] Loss: 0.2005\n",
            "Epoch [23/200] Batch [149/391] Loss: 0.1457\n",
            "Epoch [23/200] Batch [150/391] Loss: 0.2182\n",
            "Epoch [23/200] Batch [151/391] Loss: 0.1632\n",
            "Epoch [23/200] Batch [152/391] Loss: 0.2790\n",
            "Epoch [23/200] Batch [153/391] Loss: 0.2480\n",
            "Epoch [23/200] Batch [154/391] Loss: 0.1631\n",
            "Epoch [23/200] Batch [155/391] Loss: 0.2640\n",
            "Epoch [23/200] Batch [156/391] Loss: 0.2101\n",
            "Epoch [23/200] Batch [157/391] Loss: 0.2886\n",
            "Epoch [23/200] Batch [158/391] Loss: 0.1765\n",
            "Epoch [23/200] Batch [159/391] Loss: 0.2195\n",
            "Epoch [23/200] Batch [160/391] Loss: 0.2214\n",
            "Epoch [23/200] Batch [161/391] Loss: 0.2052\n",
            "Epoch [23/200] Batch [162/391] Loss: 0.2139\n",
            "Epoch [23/200] Batch [163/391] Loss: 0.1864\n",
            "Epoch [23/200] Batch [164/391] Loss: 0.3925\n",
            "Epoch [23/200] Batch [165/391] Loss: 0.1293\n",
            "Epoch [23/200] Batch [166/391] Loss: 0.2251\n",
            "Epoch [23/200] Batch [167/391] Loss: 0.1486\n",
            "Epoch [23/200] Batch [168/391] Loss: 0.1199\n",
            "Epoch [23/200] Batch [169/391] Loss: 0.1734\n",
            "Epoch [23/200] Batch [170/391] Loss: 0.1053\n",
            "Epoch [23/200] Batch [171/391] Loss: 0.1898\n",
            "Epoch [23/200] Batch [172/391] Loss: 0.2163\n",
            "Epoch [23/200] Batch [173/391] Loss: 0.2066\n",
            "Epoch [23/200] Batch [174/391] Loss: 0.2422\n",
            "Epoch [23/200] Batch [175/391] Loss: 0.2149\n",
            "Epoch [23/200] Batch [176/391] Loss: 0.1070\n",
            "Epoch [23/200] Batch [177/391] Loss: 0.2290\n",
            "Epoch [23/200] Batch [178/391] Loss: 0.2313\n",
            "Epoch [23/200] Batch [179/391] Loss: 0.1787\n",
            "Epoch [23/200] Batch [180/391] Loss: 0.2711\n",
            "Epoch [23/200] Batch [181/391] Loss: 0.1329\n",
            "Epoch [23/200] Batch [182/391] Loss: 0.1816\n",
            "Epoch [23/200] Batch [183/391] Loss: 0.2712\n",
            "Epoch [23/200] Batch [184/391] Loss: 0.1507\n",
            "Epoch [23/200] Batch [185/391] Loss: 0.1615\n",
            "Epoch [23/200] Batch [186/391] Loss: 0.2175\n",
            "Epoch [23/200] Batch [187/391] Loss: 0.1937\n",
            "Epoch [23/200] Batch [188/391] Loss: 0.2511\n",
            "Epoch [23/200] Batch [189/391] Loss: 0.2193\n",
            "Epoch [23/200] Batch [190/391] Loss: 0.1844\n",
            "Epoch [23/200] Batch [191/391] Loss: 0.1596\n",
            "Epoch [23/200] Batch [192/391] Loss: 0.2070\n",
            "Epoch [23/200] Batch [193/391] Loss: 0.2144\n",
            "Epoch [23/200] Batch [194/391] Loss: 0.1899\n",
            "Epoch [23/200] Batch [195/391] Loss: 0.2734\n",
            "Epoch [23/200] Batch [196/391] Loss: 0.2200\n",
            "Epoch [23/200] Batch [197/391] Loss: 0.2346\n",
            "Epoch [23/200] Batch [198/391] Loss: 0.1757\n",
            "Epoch [23/200] Batch [199/391] Loss: 0.1176\n",
            "Epoch [23/200] Batch [200/391] Loss: 0.2383\n",
            "Epoch [23/200] Batch [201/391] Loss: 0.2136\n",
            "Epoch [23/200] Batch [202/391] Loss: 0.1780\n",
            "Epoch [23/200] Batch [203/391] Loss: 0.3541\n",
            "Epoch [23/200] Batch [204/391] Loss: 0.1478\n",
            "Epoch [23/200] Batch [205/391] Loss: 0.1124\n",
            "Epoch [23/200] Batch [206/391] Loss: 0.1134\n",
            "Epoch [23/200] Batch [207/391] Loss: 0.2149\n",
            "Epoch [23/200] Batch [208/391] Loss: 0.2119\n",
            "Epoch [23/200] Batch [209/391] Loss: 0.2690\n",
            "Epoch [23/200] Batch [210/391] Loss: 0.2429\n",
            "Epoch [23/200] Batch [211/391] Loss: 0.1829\n",
            "Epoch [23/200] Batch [212/391] Loss: 0.2475\n",
            "Epoch [23/200] Batch [213/391] Loss: 0.2270\n",
            "Epoch [23/200] Batch [214/391] Loss: 0.1410\n",
            "Epoch [23/200] Batch [215/391] Loss: 0.3456\n",
            "Epoch [23/200] Batch [216/391] Loss: 0.1588\n",
            "Epoch [23/200] Batch [217/391] Loss: 0.2285\n",
            "Epoch [23/200] Batch [218/391] Loss: 0.3046\n",
            "Epoch [23/200] Batch [219/391] Loss: 0.1702\n",
            "Epoch [23/200] Batch [220/391] Loss: 0.2362\n",
            "Epoch [23/200] Batch [221/391] Loss: 0.1962\n",
            "Epoch [23/200] Batch [222/391] Loss: 0.2150\n",
            "Epoch [23/200] Batch [223/391] Loss: 0.2363\n",
            "Epoch [23/200] Batch [224/391] Loss: 0.2037\n",
            "Epoch [23/200] Batch [225/391] Loss: 0.1463\n",
            "Epoch [23/200] Batch [226/391] Loss: 0.1999\n",
            "Epoch [23/200] Batch [227/391] Loss: 0.3887\n",
            "Epoch [23/200] Batch [228/391] Loss: 0.2227\n",
            "Epoch [23/200] Batch [229/391] Loss: 0.3123\n",
            "Epoch [23/200] Batch [230/391] Loss: 0.2143\n",
            "Epoch [23/200] Batch [231/391] Loss: 0.3432\n",
            "Epoch [23/200] Batch [232/391] Loss: 0.1965\n",
            "Epoch [23/200] Batch [233/391] Loss: 0.2447\n",
            "Epoch [23/200] Batch [234/391] Loss: 0.1930\n",
            "Epoch [23/200] Batch [235/391] Loss: 0.2569\n",
            "Epoch [23/200] Batch [236/391] Loss: 0.2799\n",
            "Epoch [23/200] Batch [237/391] Loss: 0.2755\n",
            "Epoch [23/200] Batch [238/391] Loss: 0.1784\n",
            "Epoch [23/200] Batch [239/391] Loss: 0.3078\n",
            "Epoch [23/200] Batch [240/391] Loss: 0.1884\n",
            "Epoch [23/200] Batch [241/391] Loss: 0.2597\n",
            "Epoch [23/200] Batch [242/391] Loss: 0.1682\n",
            "Epoch [23/200] Batch [243/391] Loss: 0.1557\n",
            "Epoch [23/200] Batch [244/391] Loss: 0.1012\n",
            "Epoch [23/200] Batch [245/391] Loss: 0.2012\n",
            "Epoch [23/200] Batch [246/391] Loss: 0.2053\n",
            "Epoch [23/200] Batch [247/391] Loss: 0.2400\n",
            "Epoch [23/200] Batch [248/391] Loss: 0.2151\n",
            "Epoch [23/200] Batch [249/391] Loss: 0.1852\n",
            "Epoch [23/200] Batch [250/391] Loss: 0.1747\n",
            "Epoch [23/200] Batch [251/391] Loss: 0.1593\n",
            "Epoch [23/200] Batch [252/391] Loss: 0.2615\n",
            "Epoch [23/200] Batch [253/391] Loss: 0.2632\n",
            "Epoch [23/200] Batch [254/391] Loss: 0.2212\n",
            "Epoch [23/200] Batch [255/391] Loss: 0.1709\n",
            "Epoch [23/200] Batch [256/391] Loss: 0.1909\n",
            "Epoch [23/200] Batch [257/391] Loss: 0.2729\n",
            "Epoch [23/200] Batch [258/391] Loss: 0.2748\n",
            "Epoch [23/200] Batch [259/391] Loss: 0.2917\n",
            "Epoch [23/200] Batch [260/391] Loss: 0.2378\n",
            "Epoch [23/200] Batch [261/391] Loss: 0.1673\n",
            "Epoch [23/200] Batch [262/391] Loss: 0.1747\n",
            "Epoch [23/200] Batch [263/391] Loss: 0.1698\n",
            "Epoch [23/200] Batch [264/391] Loss: 0.1799\n",
            "Epoch [23/200] Batch [265/391] Loss: 0.1929\n",
            "Epoch [23/200] Batch [266/391] Loss: 0.1810\n",
            "Epoch [23/200] Batch [267/391] Loss: 0.2163\n",
            "Epoch [23/200] Batch [268/391] Loss: 0.1124\n",
            "Epoch [23/200] Batch [269/391] Loss: 0.1723\n",
            "Epoch [23/200] Batch [270/391] Loss: 0.2456\n",
            "Epoch [23/200] Batch [271/391] Loss: 0.2593\n",
            "Epoch [23/200] Batch [272/391] Loss: 0.1210\n",
            "Epoch [23/200] Batch [273/391] Loss: 0.1769\n",
            "Epoch [23/200] Batch [274/391] Loss: 0.1951\n",
            "Epoch [23/200] Batch [275/391] Loss: 0.1680\n",
            "Epoch [23/200] Batch [276/391] Loss: 0.0904\n",
            "Epoch [23/200] Batch [277/391] Loss: 0.1874\n",
            "Epoch [23/200] Batch [278/391] Loss: 0.2884\n",
            "Epoch [23/200] Batch [279/391] Loss: 0.1866\n",
            "Epoch [23/200] Batch [280/391] Loss: 0.1500\n",
            "Epoch [23/200] Batch [281/391] Loss: 0.1765\n",
            "Epoch [23/200] Batch [282/391] Loss: 0.1830\n",
            "Epoch [23/200] Batch [283/391] Loss: 0.2392\n",
            "Epoch [23/200] Batch [284/391] Loss: 0.2829\n",
            "Epoch [23/200] Batch [285/391] Loss: 0.1830\n",
            "Epoch [23/200] Batch [286/391] Loss: 0.1522\n",
            "Epoch [23/200] Batch [287/391] Loss: 0.2587\n",
            "Epoch [23/200] Batch [288/391] Loss: 0.2269\n",
            "Epoch [23/200] Batch [289/391] Loss: 0.2490\n",
            "Epoch [23/200] Batch [290/391] Loss: 0.2704\n",
            "Epoch [23/200] Batch [291/391] Loss: 0.3389\n",
            "Epoch [23/200] Batch [292/391] Loss: 0.1618\n",
            "Epoch [23/200] Batch [293/391] Loss: 0.2829\n",
            "Epoch [23/200] Batch [294/391] Loss: 0.1705\n",
            "Epoch [23/200] Batch [295/391] Loss: 0.1977\n",
            "Epoch [23/200] Batch [296/391] Loss: 0.1693\n",
            "Epoch [23/200] Batch [297/391] Loss: 0.1090\n",
            "Epoch [23/200] Batch [298/391] Loss: 0.1710\n",
            "Epoch [23/200] Batch [299/391] Loss: 0.1235\n",
            "Epoch [23/200] Batch [300/391] Loss: 0.2466\n",
            "Epoch [23/200] Batch [301/391] Loss: 0.3129\n",
            "Epoch [23/200] Batch [302/391] Loss: 0.1256\n",
            "Epoch [23/200] Batch [303/391] Loss: 0.1763\n",
            "Epoch [23/200] Batch [304/391] Loss: 0.2262\n",
            "Epoch [23/200] Batch [305/391] Loss: 0.1257\n",
            "Epoch [23/200] Batch [306/391] Loss: 0.1340\n",
            "Epoch [23/200] Batch [307/391] Loss: 0.2090\n",
            "Epoch [23/200] Batch [308/391] Loss: 0.3632\n",
            "Epoch [23/200] Batch [309/391] Loss: 0.2130\n",
            "Epoch [23/200] Batch [310/391] Loss: 0.2372\n",
            "Epoch [23/200] Batch [311/391] Loss: 0.2271\n",
            "Epoch [23/200] Batch [312/391] Loss: 0.1827\n",
            "Epoch [23/200] Batch [313/391] Loss: 0.2613\n",
            "Epoch [23/200] Batch [314/391] Loss: 0.2136\n",
            "Epoch [23/200] Batch [315/391] Loss: 0.1330\n",
            "Epoch [23/200] Batch [316/391] Loss: 0.1763\n",
            "Epoch [23/200] Batch [317/391] Loss: 0.1778\n",
            "Epoch [23/200] Batch [318/391] Loss: 0.2112\n",
            "Epoch [23/200] Batch [319/391] Loss: 0.1798\n",
            "Epoch [23/200] Batch [320/391] Loss: 0.1882\n",
            "Epoch [23/200] Batch [321/391] Loss: 0.2916\n",
            "Epoch [23/200] Batch [322/391] Loss: 0.1728\n",
            "Epoch [23/200] Batch [323/391] Loss: 0.2895\n",
            "Epoch [23/200] Batch [324/391] Loss: 0.3127\n",
            "Epoch [23/200] Batch [325/391] Loss: 0.1613\n",
            "Epoch [23/200] Batch [326/391] Loss: 0.2134\n",
            "Epoch [23/200] Batch [327/391] Loss: 0.3406\n",
            "Epoch [23/200] Batch [328/391] Loss: 0.1311\n",
            "Epoch [23/200] Batch [329/391] Loss: 0.2376\n",
            "Epoch [23/200] Batch [330/391] Loss: 0.2687\n",
            "Epoch [23/200] Batch [331/391] Loss: 0.1654\n",
            "Epoch [23/200] Batch [332/391] Loss: 0.1964\n",
            "Epoch [23/200] Batch [333/391] Loss: 0.1996\n",
            "Epoch [23/200] Batch [334/391] Loss: 0.1614\n",
            "Epoch [23/200] Batch [335/391] Loss: 0.1817\n",
            "Epoch [23/200] Batch [336/391] Loss: 0.2430\n",
            "Epoch [23/200] Batch [337/391] Loss: 0.1744\n",
            "Epoch [23/200] Batch [338/391] Loss: 0.1555\n",
            "Epoch [23/200] Batch [339/391] Loss: 0.1535\n",
            "Epoch [23/200] Batch [340/391] Loss: 0.3340\n",
            "Epoch [23/200] Batch [341/391] Loss: 0.3152\n",
            "Epoch [23/200] Batch [342/391] Loss: 0.1437\n",
            "Epoch [23/200] Batch [343/391] Loss: 0.2332\n",
            "Epoch [23/200] Batch [344/391] Loss: 0.2359\n",
            "Epoch [23/200] Batch [345/391] Loss: 0.3556\n",
            "Epoch [23/200] Batch [346/391] Loss: 0.1283\n",
            "Epoch [23/200] Batch [347/391] Loss: 0.2090\n",
            "Epoch [23/200] Batch [348/391] Loss: 0.2322\n",
            "Epoch [23/200] Batch [349/391] Loss: 0.1802\n",
            "Epoch [23/200] Batch [350/391] Loss: 0.2709\n",
            "Epoch [23/200] Batch [351/391] Loss: 0.1990\n",
            "Epoch [23/200] Batch [352/391] Loss: 0.2893\n",
            "Epoch [23/200] Batch [353/391] Loss: 0.1602\n",
            "Epoch [23/200] Batch [354/391] Loss: 0.1662\n",
            "Epoch [23/200] Batch [355/391] Loss: 0.1024\n",
            "Epoch [23/200] Batch [356/391] Loss: 0.2254\n",
            "Epoch [23/200] Batch [357/391] Loss: 0.2379\n",
            "Epoch [23/200] Batch [358/391] Loss: 0.1543\n",
            "Epoch [23/200] Batch [359/391] Loss: 0.3045\n",
            "Epoch [23/200] Batch [360/391] Loss: 0.2139\n",
            "Epoch [23/200] Batch [361/391] Loss: 0.1548\n",
            "Epoch [23/200] Batch [362/391] Loss: 0.3796\n",
            "Epoch [23/200] Batch [363/391] Loss: 0.2792\n",
            "Epoch [23/200] Batch [364/391] Loss: 0.2348\n",
            "Epoch [23/200] Batch [365/391] Loss: 0.2909\n",
            "Epoch [23/200] Batch [366/391] Loss: 0.1583\n",
            "Epoch [23/200] Batch [367/391] Loss: 0.1588\n",
            "Epoch [23/200] Batch [368/391] Loss: 0.1954\n",
            "Epoch [23/200] Batch [369/391] Loss: 0.1630\n",
            "Epoch [23/200] Batch [370/391] Loss: 0.2033\n",
            "Epoch [23/200] Batch [371/391] Loss: 0.2782\n",
            "Epoch [23/200] Batch [372/391] Loss: 0.1601\n",
            "Epoch [23/200] Batch [373/391] Loss: 0.1665\n",
            "Epoch [23/200] Batch [374/391] Loss: 0.2302\n",
            "Epoch [23/200] Batch [375/391] Loss: 0.2182\n",
            "Epoch [23/200] Batch [376/391] Loss: 0.2691\n",
            "Epoch [23/200] Batch [377/391] Loss: 0.2229\n",
            "Epoch [23/200] Batch [378/391] Loss: 0.1520\n",
            "Epoch [23/200] Batch [379/391] Loss: 0.1798\n",
            "Epoch [23/200] Batch [380/391] Loss: 0.1344\n",
            "Epoch [23/200] Batch [381/391] Loss: 0.2551\n",
            "Epoch [23/200] Batch [382/391] Loss: 0.2045\n",
            "Epoch [23/200] Batch [383/391] Loss: 0.3141\n",
            "Epoch [23/200] Batch [384/391] Loss: 0.2264\n",
            "Epoch [23/200] Batch [385/391] Loss: 0.1825\n",
            "Epoch [23/200] Batch [386/391] Loss: 0.2322\n",
            "Epoch [23/200] Batch [387/391] Loss: 0.2450\n",
            "Epoch [23/200] Batch [388/391] Loss: 0.2996\n",
            "Epoch [23/200] Batch [389/391] Loss: 0.3291\n",
            "Epoch [23/200] Batch [390/391] Loss: 0.2658\n",
            "Epoch [23/200] Batch [391/391] Loss: 0.1234\n",
            "Epoch [23/200] - Train Loss: 0.1979 - Test Loss: 0.7085 - Train Acc: 87.54% - Test Acc: 79.11%\n",
            "Epoch [24/200] Batch [1/391] Loss: 0.1981\n",
            "Epoch [24/200] Batch [2/391] Loss: 0.1194\n",
            "Epoch [24/200] Batch [3/391] Loss: 0.1988\n",
            "Epoch [24/200] Batch [4/391] Loss: 0.2075\n",
            "Epoch [24/200] Batch [5/391] Loss: 0.2938\n",
            "Epoch [24/200] Batch [6/391] Loss: 0.2295\n",
            "Epoch [24/200] Batch [7/391] Loss: 0.2114\n",
            "Epoch [24/200] Batch [8/391] Loss: 0.1965\n",
            "Epoch [24/200] Batch [9/391] Loss: 0.2583\n",
            "Epoch [24/200] Batch [10/391] Loss: 0.1032\n",
            "Epoch [24/200] Batch [11/391] Loss: 0.1352\n",
            "Epoch [24/200] Batch [12/391] Loss: 0.1257\n",
            "Epoch [24/200] Batch [13/391] Loss: 0.2287\n",
            "Epoch [24/200] Batch [14/391] Loss: 0.1540\n",
            "Epoch [24/200] Batch [15/391] Loss: 0.2123\n",
            "Epoch [24/200] Batch [16/391] Loss: 0.1234\n",
            "Epoch [24/200] Batch [17/391] Loss: 0.1764\n",
            "Epoch [24/200] Batch [18/391] Loss: 0.1420\n",
            "Epoch [24/200] Batch [19/391] Loss: 0.1791\n",
            "Epoch [24/200] Batch [20/391] Loss: 0.1789\n",
            "Epoch [24/200] Batch [21/391] Loss: 0.2024\n",
            "Epoch [24/200] Batch [22/391] Loss: 0.1261\n",
            "Epoch [24/200] Batch [23/391] Loss: 0.1631\n",
            "Epoch [24/200] Batch [24/391] Loss: 0.2308\n",
            "Epoch [24/200] Batch [25/391] Loss: 0.1923\n",
            "Epoch [24/200] Batch [26/391] Loss: 0.1504\n",
            "Epoch [24/200] Batch [27/391] Loss: 0.1679\n",
            "Epoch [24/200] Batch [28/391] Loss: 0.1102\n",
            "Epoch [24/200] Batch [29/391] Loss: 0.2144\n",
            "Epoch [24/200] Batch [30/391] Loss: 0.2105\n",
            "Epoch [24/200] Batch [31/391] Loss: 0.1975\n",
            "Epoch [24/200] Batch [32/391] Loss: 0.2161\n",
            "Epoch [24/200] Batch [33/391] Loss: 0.1119\n",
            "Epoch [24/200] Batch [34/391] Loss: 0.1661\n",
            "Epoch [24/200] Batch [35/391] Loss: 0.1784\n",
            "Epoch [24/200] Batch [36/391] Loss: 0.2524\n",
            "Epoch [24/200] Batch [37/391] Loss: 0.1320\n",
            "Epoch [24/200] Batch [38/391] Loss: 0.1022\n",
            "Epoch [24/200] Batch [39/391] Loss: 0.1745\n",
            "Epoch [24/200] Batch [40/391] Loss: 0.2643\n",
            "Epoch [24/200] Batch [41/391] Loss: 0.1634\n",
            "Epoch [24/200] Batch [42/391] Loss: 0.1236\n",
            "Epoch [24/200] Batch [43/391] Loss: 0.1440\n",
            "Epoch [24/200] Batch [44/391] Loss: 0.2074\n",
            "Epoch [24/200] Batch [45/391] Loss: 0.1837\n",
            "Epoch [24/200] Batch [46/391] Loss: 0.2405\n",
            "Epoch [24/200] Batch [47/391] Loss: 0.1707\n",
            "Epoch [24/200] Batch [48/391] Loss: 0.2117\n",
            "Epoch [24/200] Batch [49/391] Loss: 0.1390\n",
            "Epoch [24/200] Batch [50/391] Loss: 0.1740\n",
            "Epoch [24/200] Batch [51/391] Loss: 0.1314\n",
            "Epoch [24/200] Batch [52/391] Loss: 0.1382\n",
            "Epoch [24/200] Batch [53/391] Loss: 0.2089\n",
            "Epoch [24/200] Batch [54/391] Loss: 0.2337\n",
            "Epoch [24/200] Batch [55/391] Loss: 0.1808\n",
            "Epoch [24/200] Batch [56/391] Loss: 0.1366\n",
            "Epoch [24/200] Batch [57/391] Loss: 0.1537\n",
            "Epoch [24/200] Batch [58/391] Loss: 0.1733\n",
            "Epoch [24/200] Batch [59/391] Loss: 0.1475\n",
            "Epoch [24/200] Batch [60/391] Loss: 0.1466\n",
            "Epoch [24/200] Batch [61/391] Loss: 0.1116\n",
            "Epoch [24/200] Batch [62/391] Loss: 0.1001\n",
            "Epoch [24/200] Batch [63/391] Loss: 0.2030\n",
            "Epoch [24/200] Batch [64/391] Loss: 0.1456\n",
            "Epoch [24/200] Batch [65/391] Loss: 0.1691\n",
            "Epoch [24/200] Batch [66/391] Loss: 0.1629\n",
            "Epoch [24/200] Batch [67/391] Loss: 0.2060\n",
            "Epoch [24/200] Batch [68/391] Loss: 0.0899\n",
            "Epoch [24/200] Batch [69/391] Loss: 0.0785\n",
            "Epoch [24/200] Batch [70/391] Loss: 0.2002\n",
            "Epoch [24/200] Batch [71/391] Loss: 0.1892\n",
            "Epoch [24/200] Batch [72/391] Loss: 0.1120\n",
            "Epoch [24/200] Batch [73/391] Loss: 0.1965\n",
            "Epoch [24/200] Batch [74/391] Loss: 0.2272\n",
            "Epoch [24/200] Batch [75/391] Loss: 0.1244\n",
            "Epoch [24/200] Batch [76/391] Loss: 0.1611\n",
            "Epoch [24/200] Batch [77/391] Loss: 0.2392\n",
            "Epoch [24/200] Batch [78/391] Loss: 0.1361\n",
            "Epoch [24/200] Batch [79/391] Loss: 0.1460\n",
            "Epoch [24/200] Batch [80/391] Loss: 0.1953\n",
            "Epoch [24/200] Batch [81/391] Loss: 0.1902\n",
            "Epoch [24/200] Batch [82/391] Loss: 0.1899\n",
            "Epoch [24/200] Batch [83/391] Loss: 0.1636\n",
            "Epoch [24/200] Batch [84/391] Loss: 0.1210\n",
            "Epoch [24/200] Batch [85/391] Loss: 0.1341\n",
            "Epoch [24/200] Batch [86/391] Loss: 0.2957\n",
            "Epoch [24/200] Batch [87/391] Loss: 0.1345\n",
            "Epoch [24/200] Batch [88/391] Loss: 0.1912\n",
            "Epoch [24/200] Batch [89/391] Loss: 0.1539\n",
            "Epoch [24/200] Batch [90/391] Loss: 0.0866\n",
            "Epoch [24/200] Batch [91/391] Loss: 0.1548\n",
            "Epoch [24/200] Batch [92/391] Loss: 0.1647\n",
            "Epoch [24/200] Batch [93/391] Loss: 0.2504\n",
            "Epoch [24/200] Batch [94/391] Loss: 0.1167\n",
            "Epoch [24/200] Batch [95/391] Loss: 0.1756\n",
            "Epoch [24/200] Batch [96/391] Loss: 0.1704\n",
            "Epoch [24/200] Batch [97/391] Loss: 0.1883\n",
            "Epoch [24/200] Batch [98/391] Loss: 0.1173\n",
            "Epoch [24/200] Batch [99/391] Loss: 0.1392\n",
            "Epoch [24/200] Batch [100/391] Loss: 0.2019\n",
            "Epoch [24/200] Batch [101/391] Loss: 0.2197\n",
            "Epoch [24/200] Batch [102/391] Loss: 0.2213\n",
            "Epoch [24/200] Batch [103/391] Loss: 0.2625\n",
            "Epoch [24/200] Batch [104/391] Loss: 0.1535\n",
            "Epoch [24/200] Batch [105/391] Loss: 0.2009\n",
            "Epoch [24/200] Batch [106/391] Loss: 0.1008\n",
            "Epoch [24/200] Batch [107/391] Loss: 0.2757\n",
            "Epoch [24/200] Batch [108/391] Loss: 0.0981\n",
            "Epoch [24/200] Batch [109/391] Loss: 0.1681\n",
            "Epoch [24/200] Batch [110/391] Loss: 0.2152\n",
            "Epoch [24/200] Batch [111/391] Loss: 0.1316\n",
            "Epoch [24/200] Batch [112/391] Loss: 0.1602\n",
            "Epoch [24/200] Batch [113/391] Loss: 0.2075\n",
            "Epoch [24/200] Batch [114/391] Loss: 0.1858\n",
            "Epoch [24/200] Batch [115/391] Loss: 0.1015\n",
            "Epoch [24/200] Batch [116/391] Loss: 0.2153\n",
            "Epoch [24/200] Batch [117/391] Loss: 0.1585\n",
            "Epoch [24/200] Batch [118/391] Loss: 0.1740\n",
            "Epoch [24/200] Batch [119/391] Loss: 0.1783\n",
            "Epoch [24/200] Batch [120/391] Loss: 0.1261\n",
            "Epoch [24/200] Batch [121/391] Loss: 0.1960\n",
            "Epoch [24/200] Batch [122/391] Loss: 0.1533\n",
            "Epoch [24/200] Batch [123/391] Loss: 0.1502\n",
            "Epoch [24/200] Batch [124/391] Loss: 0.1220\n",
            "Epoch [24/200] Batch [125/391] Loss: 0.1733\n",
            "Epoch [24/200] Batch [126/391] Loss: 0.1754\n",
            "Epoch [24/200] Batch [127/391] Loss: 0.1933\n",
            "Epoch [24/200] Batch [128/391] Loss: 0.0717\n",
            "Epoch [24/200] Batch [129/391] Loss: 0.0932\n",
            "Epoch [24/200] Batch [130/391] Loss: 0.1888\n",
            "Epoch [24/200] Batch [131/391] Loss: 0.1408\n",
            "Epoch [24/200] Batch [132/391] Loss: 0.2011\n",
            "Epoch [24/200] Batch [133/391] Loss: 0.2530\n",
            "Epoch [24/200] Batch [134/391] Loss: 0.1524\n",
            "Epoch [24/200] Batch [135/391] Loss: 0.1958\n",
            "Epoch [24/200] Batch [136/391] Loss: 0.1205\n",
            "Epoch [24/200] Batch [137/391] Loss: 0.2655\n",
            "Epoch [24/200] Batch [138/391] Loss: 0.1126\n",
            "Epoch [24/200] Batch [139/391] Loss: 0.1320\n",
            "Epoch [24/200] Batch [140/391] Loss: 0.2328\n",
            "Epoch [24/200] Batch [141/391] Loss: 0.1834\n",
            "Epoch [24/200] Batch [142/391] Loss: 0.1713\n",
            "Epoch [24/200] Batch [143/391] Loss: 0.1458\n",
            "Epoch [24/200] Batch [144/391] Loss: 0.1681\n",
            "Epoch [24/200] Batch [145/391] Loss: 0.2433\n",
            "Epoch [24/200] Batch [146/391] Loss: 0.2992\n",
            "Epoch [24/200] Batch [147/391] Loss: 0.2290\n",
            "Epoch [24/200] Batch [148/391] Loss: 0.0941\n",
            "Epoch [24/200] Batch [149/391] Loss: 0.2027\n",
            "Epoch [24/200] Batch [150/391] Loss: 0.1810\n",
            "Epoch [24/200] Batch [151/391] Loss: 0.2443\n",
            "Epoch [24/200] Batch [152/391] Loss: 0.2022\n",
            "Epoch [24/200] Batch [153/391] Loss: 0.1212\n",
            "Epoch [24/200] Batch [154/391] Loss: 0.1757\n",
            "Epoch [24/200] Batch [155/391] Loss: 0.0907\n",
            "Epoch [24/200] Batch [156/391] Loss: 0.1791\n",
            "Epoch [24/200] Batch [157/391] Loss: 0.1500\n",
            "Epoch [24/200] Batch [158/391] Loss: 0.2491\n",
            "Epoch [24/200] Batch [159/391] Loss: 0.2298\n",
            "Epoch [24/200] Batch [160/391] Loss: 0.1594\n",
            "Epoch [24/200] Batch [161/391] Loss: 0.1287\n",
            "Epoch [24/200] Batch [162/391] Loss: 0.2094\n",
            "Epoch [24/200] Batch [163/391] Loss: 0.1271\n",
            "Epoch [24/200] Batch [164/391] Loss: 0.2546\n",
            "Epoch [24/200] Batch [165/391] Loss: 0.1341\n",
            "Epoch [24/200] Batch [166/391] Loss: 0.2010\n",
            "Epoch [24/200] Batch [167/391] Loss: 0.1628\n",
            "Epoch [24/200] Batch [168/391] Loss: 0.1818\n",
            "Epoch [24/200] Batch [169/391] Loss: 0.2569\n",
            "Epoch [24/200] Batch [170/391] Loss: 0.1375\n",
            "Epoch [24/200] Batch [171/391] Loss: 0.2022\n",
            "Epoch [24/200] Batch [172/391] Loss: 0.2487\n",
            "Epoch [24/200] Batch [173/391] Loss: 0.1928\n",
            "Epoch [24/200] Batch [174/391] Loss: 0.2354\n",
            "Epoch [24/200] Batch [175/391] Loss: 0.1758\n",
            "Epoch [24/200] Batch [176/391] Loss: 0.1912\n",
            "Epoch [24/200] Batch [177/391] Loss: 0.1591\n",
            "Epoch [24/200] Batch [178/391] Loss: 0.2325\n",
            "Epoch [24/200] Batch [179/391] Loss: 0.0906\n",
            "Epoch [24/200] Batch [180/391] Loss: 0.2700\n",
            "Epoch [24/200] Batch [181/391] Loss: 0.1876\n",
            "Epoch [24/200] Batch [182/391] Loss: 0.1755\n",
            "Epoch [24/200] Batch [183/391] Loss: 0.2743\n",
            "Epoch [24/200] Batch [184/391] Loss: 0.1707\n",
            "Epoch [24/200] Batch [185/391] Loss: 0.1918\n",
            "Epoch [24/200] Batch [186/391] Loss: 0.1833\n",
            "Epoch [24/200] Batch [187/391] Loss: 0.2685\n",
            "Epoch [24/200] Batch [188/391] Loss: 0.2103\n",
            "Epoch [24/200] Batch [189/391] Loss: 0.1363\n",
            "Epoch [24/200] Batch [190/391] Loss: 0.2408\n",
            "Epoch [24/200] Batch [191/391] Loss: 0.2713\n",
            "Epoch [24/200] Batch [192/391] Loss: 0.2201\n",
            "Epoch [24/200] Batch [193/391] Loss: 0.2613\n",
            "Epoch [24/200] Batch [194/391] Loss: 0.1706\n",
            "Epoch [24/200] Batch [195/391] Loss: 0.1677\n",
            "Epoch [24/200] Batch [196/391] Loss: 0.2346\n",
            "Epoch [24/200] Batch [197/391] Loss: 0.3693\n",
            "Epoch [24/200] Batch [198/391] Loss: 0.1288\n",
            "Epoch [24/200] Batch [199/391] Loss: 0.1173\n",
            "Epoch [24/200] Batch [200/391] Loss: 0.2146\n",
            "Epoch [24/200] Batch [201/391] Loss: 0.2377\n",
            "Epoch [24/200] Batch [202/391] Loss: 0.1577\n",
            "Epoch [24/200] Batch [203/391] Loss: 0.1599\n",
            "Epoch [24/200] Batch [204/391] Loss: 0.2130\n",
            "Epoch [24/200] Batch [205/391] Loss: 0.1827\n",
            "Epoch [24/200] Batch [206/391] Loss: 0.2286\n",
            "Epoch [24/200] Batch [207/391] Loss: 0.2001\n",
            "Epoch [24/200] Batch [208/391] Loss: 0.2494\n",
            "Epoch [24/200] Batch [209/391] Loss: 0.2807\n",
            "Epoch [24/200] Batch [210/391] Loss: 0.1631\n",
            "Epoch [24/200] Batch [211/391] Loss: 0.1866\n",
            "Epoch [24/200] Batch [212/391] Loss: 0.2288\n",
            "Epoch [24/200] Batch [213/391] Loss: 0.1647\n",
            "Epoch [24/200] Batch [214/391] Loss: 0.1574\n",
            "Epoch [24/200] Batch [215/391] Loss: 0.2082\n",
            "Epoch [24/200] Batch [216/391] Loss: 0.1909\n",
            "Epoch [24/200] Batch [217/391] Loss: 0.1516\n",
            "Epoch [24/200] Batch [218/391] Loss: 0.2806\n",
            "Epoch [24/200] Batch [219/391] Loss: 0.2364\n",
            "Epoch [24/200] Batch [220/391] Loss: 0.1565\n",
            "Epoch [24/200] Batch [221/391] Loss: 0.3610\n",
            "Epoch [24/200] Batch [222/391] Loss: 0.1969\n",
            "Epoch [24/200] Batch [223/391] Loss: 0.3296\n",
            "Epoch [24/200] Batch [224/391] Loss: 0.1577\n",
            "Epoch [24/200] Batch [225/391] Loss: 0.2210\n",
            "Epoch [24/200] Batch [226/391] Loss: 0.1713\n",
            "Epoch [24/200] Batch [227/391] Loss: 0.2768\n",
            "Epoch [24/200] Batch [228/391] Loss: 0.1553\n",
            "Epoch [24/200] Batch [229/391] Loss: 0.1664\n",
            "Epoch [24/200] Batch [230/391] Loss: 0.1367\n",
            "Epoch [24/200] Batch [231/391] Loss: 0.1843\n",
            "Epoch [24/200] Batch [232/391] Loss: 0.1789\n",
            "Epoch [24/200] Batch [233/391] Loss: 0.3345\n",
            "Epoch [24/200] Batch [234/391] Loss: 0.2865\n",
            "Epoch [24/200] Batch [235/391] Loss: 0.3251\n",
            "Epoch [24/200] Batch [236/391] Loss: 0.2375\n",
            "Epoch [24/200] Batch [237/391] Loss: 0.1749\n",
            "Epoch [24/200] Batch [238/391] Loss: 0.1721\n",
            "Epoch [24/200] Batch [239/391] Loss: 0.1992\n",
            "Epoch [24/200] Batch [240/391] Loss: 0.1483\n",
            "Epoch [24/200] Batch [241/391] Loss: 0.2292\n",
            "Epoch [24/200] Batch [242/391] Loss: 0.1797\n",
            "Epoch [24/200] Batch [243/391] Loss: 0.2765\n",
            "Epoch [24/200] Batch [244/391] Loss: 0.1695\n",
            "Epoch [24/200] Batch [245/391] Loss: 0.0753\n",
            "Epoch [24/200] Batch [246/391] Loss: 0.2587\n",
            "Epoch [24/200] Batch [247/391] Loss: 0.2126\n",
            "Epoch [24/200] Batch [248/391] Loss: 0.2034\n",
            "Epoch [24/200] Batch [249/391] Loss: 0.2095\n",
            "Epoch [24/200] Batch [250/391] Loss: 0.2026\n",
            "Epoch [24/200] Batch [251/391] Loss: 0.1800\n",
            "Epoch [24/200] Batch [252/391] Loss: 0.2318\n",
            "Epoch [24/200] Batch [253/391] Loss: 0.3414\n",
            "Epoch [24/200] Batch [254/391] Loss: 0.2690\n",
            "Epoch [24/200] Batch [255/391] Loss: 0.1916\n",
            "Epoch [24/200] Batch [256/391] Loss: 0.2380\n",
            "Epoch [24/200] Batch [257/391] Loss: 0.1815\n",
            "Epoch [24/200] Batch [258/391] Loss: 0.2492\n",
            "Epoch [24/200] Batch [259/391] Loss: 0.1226\n",
            "Epoch [24/200] Batch [260/391] Loss: 0.3393\n",
            "Epoch [24/200] Batch [261/391] Loss: 0.1555\n",
            "Epoch [24/200] Batch [262/391] Loss: 0.2195\n",
            "Epoch [24/200] Batch [263/391] Loss: 0.2601\n",
            "Epoch [24/200] Batch [264/391] Loss: 0.2438\n",
            "Epoch [24/200] Batch [265/391] Loss: 0.1413\n",
            "Epoch [24/200] Batch [266/391] Loss: 0.3020\n",
            "Epoch [24/200] Batch [267/391] Loss: 0.1621\n",
            "Epoch [24/200] Batch [268/391] Loss: 0.1390\n",
            "Epoch [24/200] Batch [269/391] Loss: 0.1164\n",
            "Epoch [24/200] Batch [270/391] Loss: 0.2643\n",
            "Epoch [24/200] Batch [271/391] Loss: 0.2298\n",
            "Epoch [24/200] Batch [272/391] Loss: 0.1856\n",
            "Epoch [24/200] Batch [273/391] Loss: 0.1325\n",
            "Epoch [24/200] Batch [274/391] Loss: 0.1814\n",
            "Epoch [24/200] Batch [275/391] Loss: 0.1666\n",
            "Epoch [24/200] Batch [276/391] Loss: 0.2140\n",
            "Epoch [24/200] Batch [277/391] Loss: 0.2323\n",
            "Epoch [24/200] Batch [278/391] Loss: 0.2501\n",
            "Epoch [24/200] Batch [279/391] Loss: 0.2358\n",
            "Epoch [24/200] Batch [280/391] Loss: 0.1780\n",
            "Epoch [24/200] Batch [281/391] Loss: 0.2129\n",
            "Epoch [24/200] Batch [282/391] Loss: 0.2280\n",
            "Epoch [24/200] Batch [283/391] Loss: 0.3013\n",
            "Epoch [24/200] Batch [284/391] Loss: 0.2416\n",
            "Epoch [24/200] Batch [285/391] Loss: 0.1255\n",
            "Epoch [24/200] Batch [286/391] Loss: 0.1661\n",
            "Epoch [24/200] Batch [287/391] Loss: 0.1546\n",
            "Epoch [24/200] Batch [288/391] Loss: 0.2642\n",
            "Epoch [24/200] Batch [289/391] Loss: 0.2190\n",
            "Epoch [24/200] Batch [290/391] Loss: 0.2629\n",
            "Epoch [24/200] Batch [291/391] Loss: 0.2250\n",
            "Epoch [24/200] Batch [292/391] Loss: 0.3911\n",
            "Epoch [24/200] Batch [293/391] Loss: 0.2225\n",
            "Epoch [24/200] Batch [294/391] Loss: 0.1904\n",
            "Epoch [24/200] Batch [295/391] Loss: 0.1749\n",
            "Epoch [24/200] Batch [296/391] Loss: 0.3513\n",
            "Epoch [24/200] Batch [297/391] Loss: 0.1384\n",
            "Epoch [24/200] Batch [298/391] Loss: 0.2425\n",
            "Epoch [24/200] Batch [299/391] Loss: 0.2612\n",
            "Epoch [24/200] Batch [300/391] Loss: 0.1811\n",
            "Epoch [24/200] Batch [301/391] Loss: 0.2123\n",
            "Epoch [24/200] Batch [302/391] Loss: 0.3641\n",
            "Epoch [24/200] Batch [303/391] Loss: 0.2873\n",
            "Epoch [24/200] Batch [304/391] Loss: 0.2312\n",
            "Epoch [24/200] Batch [305/391] Loss: 0.1802\n",
            "Epoch [24/200] Batch [306/391] Loss: 0.2432\n",
            "Epoch [24/200] Batch [307/391] Loss: 0.2668\n",
            "Epoch [24/200] Batch [308/391] Loss: 0.1359\n",
            "Epoch [24/200] Batch [309/391] Loss: 0.2547\n",
            "Epoch [24/200] Batch [310/391] Loss: 0.2674\n",
            "Epoch [24/200] Batch [311/391] Loss: 0.2402\n",
            "Epoch [24/200] Batch [312/391] Loss: 0.1627\n",
            "Epoch [24/200] Batch [313/391] Loss: 0.2112\n",
            "Epoch [24/200] Batch [314/391] Loss: 0.2497\n",
            "Epoch [24/200] Batch [315/391] Loss: 0.1880\n",
            "Epoch [24/200] Batch [316/391] Loss: 0.1580\n",
            "Epoch [24/200] Batch [317/391] Loss: 0.2599\n",
            "Epoch [24/200] Batch [318/391] Loss: 0.2022\n",
            "Epoch [24/200] Batch [319/391] Loss: 0.1537\n",
            "Epoch [24/200] Batch [320/391] Loss: 0.2051\n",
            "Epoch [24/200] Batch [321/391] Loss: 0.3076\n",
            "Epoch [24/200] Batch [322/391] Loss: 0.1850\n",
            "Epoch [24/200] Batch [323/391] Loss: 0.2124\n",
            "Epoch [24/200] Batch [324/391] Loss: 0.1926\n",
            "Epoch [24/200] Batch [325/391] Loss: 0.1946\n",
            "Epoch [24/200] Batch [326/391] Loss: 0.3711\n",
            "Epoch [24/200] Batch [327/391] Loss: 0.2589\n",
            "Epoch [24/200] Batch [328/391] Loss: 0.2265\n",
            "Epoch [24/200] Batch [329/391] Loss: 0.1586\n",
            "Epoch [24/200] Batch [330/391] Loss: 0.2447\n",
            "Epoch [24/200] Batch [331/391] Loss: 0.1487\n",
            "Epoch [24/200] Batch [332/391] Loss: 0.1681\n",
            "Epoch [24/200] Batch [333/391] Loss: 0.2433\n",
            "Epoch [24/200] Batch [334/391] Loss: 0.2117\n",
            "Epoch [24/200] Batch [335/391] Loss: 0.2697\n",
            "Epoch [24/200] Batch [336/391] Loss: 0.1612\n",
            "Epoch [24/200] Batch [337/391] Loss: 0.1768\n",
            "Epoch [24/200] Batch [338/391] Loss: 0.1912\n",
            "Epoch [24/200] Batch [339/391] Loss: 0.3151\n",
            "Epoch [24/200] Batch [340/391] Loss: 0.1818\n",
            "Epoch [24/200] Batch [341/391] Loss: 0.2606\n",
            "Epoch [24/200] Batch [342/391] Loss: 0.1714\n",
            "Epoch [24/200] Batch [343/391] Loss: 0.1335\n",
            "Epoch [24/200] Batch [344/391] Loss: 0.3102\n",
            "Epoch [24/200] Batch [345/391] Loss: 0.2102\n",
            "Epoch [24/200] Batch [346/391] Loss: 0.2795\n",
            "Epoch [24/200] Batch [347/391] Loss: 0.1577\n",
            "Epoch [24/200] Batch [348/391] Loss: 0.2057\n",
            "Epoch [24/200] Batch [349/391] Loss: 0.1437\n",
            "Epoch [24/200] Batch [350/391] Loss: 0.2274\n",
            "Epoch [24/200] Batch [351/391] Loss: 0.3027\n",
            "Epoch [24/200] Batch [352/391] Loss: 0.2218\n",
            "Epoch [24/200] Batch [353/391] Loss: 0.1806\n",
            "Epoch [24/200] Batch [354/391] Loss: 0.2218\n",
            "Epoch [24/200] Batch [355/391] Loss: 0.2776\n",
            "Epoch [24/200] Batch [356/391] Loss: 0.3293\n",
            "Epoch [24/200] Batch [357/391] Loss: 0.1431\n",
            "Epoch [24/200] Batch [358/391] Loss: 0.1870\n",
            "Epoch [24/200] Batch [359/391] Loss: 0.3050\n",
            "Epoch [24/200] Batch [360/391] Loss: 0.1403\n",
            "Epoch [24/200] Batch [361/391] Loss: 0.1535\n",
            "Epoch [24/200] Batch [362/391] Loss: 0.0969\n",
            "Epoch [24/200] Batch [363/391] Loss: 0.1680\n",
            "Epoch [24/200] Batch [364/391] Loss: 0.1594\n",
            "Epoch [24/200] Batch [365/391] Loss: 0.1883\n",
            "Epoch [24/200] Batch [366/391] Loss: 0.1323\n",
            "Epoch [24/200] Batch [367/391] Loss: 0.1838\n",
            "Epoch [24/200] Batch [368/391] Loss: 0.1251\n",
            "Epoch [24/200] Batch [369/391] Loss: 0.1762\n",
            "Epoch [24/200] Batch [370/391] Loss: 0.1446\n",
            "Epoch [24/200] Batch [371/391] Loss: 0.3112\n",
            "Epoch [24/200] Batch [372/391] Loss: 0.1373\n",
            "Epoch [24/200] Batch [373/391] Loss: 0.2247\n",
            "Epoch [24/200] Batch [374/391] Loss: 0.2044\n",
            "Epoch [24/200] Batch [375/391] Loss: 0.1707\n",
            "Epoch [24/200] Batch [376/391] Loss: 0.2412\n",
            "Epoch [24/200] Batch [377/391] Loss: 0.1961\n",
            "Epoch [24/200] Batch [378/391] Loss: 0.2362\n",
            "Epoch [24/200] Batch [379/391] Loss: 0.1860\n",
            "Epoch [24/200] Batch [380/391] Loss: 0.2010\n",
            "Epoch [24/200] Batch [381/391] Loss: 0.2266\n",
            "Epoch [24/200] Batch [382/391] Loss: 0.1669\n",
            "Epoch [24/200] Batch [383/391] Loss: 0.2872\n",
            "Epoch [24/200] Batch [384/391] Loss: 0.2889\n",
            "Epoch [24/200] Batch [385/391] Loss: 0.2883\n",
            "Epoch [24/200] Batch [386/391] Loss: 0.2898\n",
            "Epoch [24/200] Batch [387/391] Loss: 0.1639\n",
            "Epoch [24/200] Batch [388/391] Loss: 0.1436\n",
            "Epoch [24/200] Batch [389/391] Loss: 0.1919\n",
            "Epoch [24/200] Batch [390/391] Loss: 0.2876\n",
            "Epoch [24/200] Batch [391/391] Loss: 0.2304\n",
            "Epoch [24/200] - Train Loss: 0.1960 - Test Loss: 0.8325 - Train Acc: 85.24% - Test Acc: 77.02%\n",
            "Epoch [25/200] Batch [1/391] Loss: 0.1208\n",
            "Epoch [25/200] Batch [2/391] Loss: 0.1299\n",
            "Epoch [25/200] Batch [3/391] Loss: 0.2614\n",
            "Epoch [25/200] Batch [4/391] Loss: 0.0885\n",
            "Epoch [25/200] Batch [5/391] Loss: 0.3240\n",
            "Epoch [25/200] Batch [6/391] Loss: 0.1896\n",
            "Epoch [25/200] Batch [7/391] Loss: 0.1217\n",
            "Epoch [25/200] Batch [8/391] Loss: 0.2662\n",
            "Epoch [25/200] Batch [9/391] Loss: 0.1411\n",
            "Epoch [25/200] Batch [10/391] Loss: 0.1025\n",
            "Epoch [25/200] Batch [11/391] Loss: 0.1412\n",
            "Epoch [25/200] Batch [12/391] Loss: 0.2619\n",
            "Epoch [25/200] Batch [13/391] Loss: 0.0794\n",
            "Epoch [25/200] Batch [14/391] Loss: 0.1583\n",
            "Epoch [25/200] Batch [15/391] Loss: 0.1485\n",
            "Epoch [25/200] Batch [16/391] Loss: 0.1527\n",
            "Epoch [25/200] Batch [17/391] Loss: 0.1623\n",
            "Epoch [25/200] Batch [18/391] Loss: 0.1216\n",
            "Epoch [25/200] Batch [19/391] Loss: 0.1502\n",
            "Epoch [25/200] Batch [20/391] Loss: 0.1661\n",
            "Epoch [25/200] Batch [21/391] Loss: 0.1488\n",
            "Epoch [25/200] Batch [22/391] Loss: 0.1018\n",
            "Epoch [25/200] Batch [23/391] Loss: 0.1122\n",
            "Epoch [25/200] Batch [24/391] Loss: 0.1388\n",
            "Epoch [25/200] Batch [25/391] Loss: 0.1715\n",
            "Epoch [25/200] Batch [26/391] Loss: 0.0948\n",
            "Epoch [25/200] Batch [27/391] Loss: 0.1841\n",
            "Epoch [25/200] Batch [28/391] Loss: 0.1487\n",
            "Epoch [25/200] Batch [29/391] Loss: 0.2083\n",
            "Epoch [25/200] Batch [30/391] Loss: 0.1128\n",
            "Epoch [25/200] Batch [31/391] Loss: 0.1214\n",
            "Epoch [25/200] Batch [32/391] Loss: 0.1192\n",
            "Epoch [25/200] Batch [33/391] Loss: 0.1727\n",
            "Epoch [25/200] Batch [34/391] Loss: 0.1772\n",
            "Epoch [25/200] Batch [35/391] Loss: 0.0708\n",
            "Epoch [25/200] Batch [36/391] Loss: 0.1255\n",
            "Epoch [25/200] Batch [37/391] Loss: 0.1467\n",
            "Epoch [25/200] Batch [38/391] Loss: 0.1637\n",
            "Epoch [25/200] Batch [39/391] Loss: 0.1047\n",
            "Epoch [25/200] Batch [40/391] Loss: 0.1416\n",
            "Epoch [25/200] Batch [41/391] Loss: 0.1921\n",
            "Epoch [25/200] Batch [42/391] Loss: 0.1082\n",
            "Epoch [25/200] Batch [43/391] Loss: 0.1924\n",
            "Epoch [25/200] Batch [44/391] Loss: 0.0753\n",
            "Epoch [25/200] Batch [45/391] Loss: 0.2187\n",
            "Epoch [25/200] Batch [46/391] Loss: 0.1218\n",
            "Epoch [25/200] Batch [47/391] Loss: 0.0927\n",
            "Epoch [25/200] Batch [48/391] Loss: 0.2154\n",
            "Epoch [25/200] Batch [49/391] Loss: 0.1236\n",
            "Epoch [25/200] Batch [50/391] Loss: 0.1068\n",
            "Epoch [25/200] Batch [51/391] Loss: 0.1750\n",
            "Epoch [25/200] Batch [52/391] Loss: 0.1242\n",
            "Epoch [25/200] Batch [53/391] Loss: 0.0813\n",
            "Epoch [25/200] Batch [54/391] Loss: 0.0453\n",
            "Epoch [25/200] Batch [55/391] Loss: 0.1753\n",
            "Epoch [25/200] Batch [56/391] Loss: 0.1297\n",
            "Epoch [25/200] Batch [57/391] Loss: 0.1406\n",
            "Epoch [25/200] Batch [58/391] Loss: 0.1302\n",
            "Epoch [25/200] Batch [59/391] Loss: 0.0630\n",
            "Epoch [25/200] Batch [60/391] Loss: 0.1135\n",
            "Epoch [25/200] Batch [61/391] Loss: 0.1030\n",
            "Epoch [25/200] Batch [62/391] Loss: 0.2134\n",
            "Epoch [25/200] Batch [63/391] Loss: 0.1635\n",
            "Epoch [25/200] Batch [64/391] Loss: 0.1673\n",
            "Epoch [25/200] Batch [65/391] Loss: 0.1043\n",
            "Epoch [25/200] Batch [66/391] Loss: 0.1596\n",
            "Epoch [25/200] Batch [67/391] Loss: 0.1680\n",
            "Epoch [25/200] Batch [68/391] Loss: 0.1540\n",
            "Epoch [25/200] Batch [69/391] Loss: 0.1353\n",
            "Epoch [25/200] Batch [70/391] Loss: 0.1432\n",
            "Epoch [25/200] Batch [71/391] Loss: 0.1465\n",
            "Epoch [25/200] Batch [72/391] Loss: 0.1459\n",
            "Epoch [25/200] Batch [73/391] Loss: 0.1325\n",
            "Epoch [25/200] Batch [74/391] Loss: 0.0885\n",
            "Epoch [25/200] Batch [75/391] Loss: 0.2967\n",
            "Epoch [25/200] Batch [76/391] Loss: 0.0790\n",
            "Epoch [25/200] Batch [77/391] Loss: 0.1817\n",
            "Epoch [25/200] Batch [78/391] Loss: 0.0820\n",
            "Epoch [25/200] Batch [79/391] Loss: 0.1937\n",
            "Epoch [25/200] Batch [80/391] Loss: 0.1078\n",
            "Epoch [25/200] Batch [81/391] Loss: 0.1636\n",
            "Epoch [25/200] Batch [82/391] Loss: 0.1160\n",
            "Epoch [25/200] Batch [83/391] Loss: 0.1635\n",
            "Epoch [25/200] Batch [84/391] Loss: 0.1460\n",
            "Epoch [25/200] Batch [85/391] Loss: 0.1588\n",
            "Epoch [25/200] Batch [86/391] Loss: 0.2684\n",
            "Epoch [25/200] Batch [87/391] Loss: 0.1210\n",
            "Epoch [25/200] Batch [88/391] Loss: 0.1221\n",
            "Epoch [25/200] Batch [89/391] Loss: 0.1582\n",
            "Epoch [25/200] Batch [90/391] Loss: 0.0975\n",
            "Epoch [25/200] Batch [91/391] Loss: 0.1728\n",
            "Epoch [25/200] Batch [92/391] Loss: 0.1814\n",
            "Epoch [25/200] Batch [93/391] Loss: 0.1358\n",
            "Epoch [25/200] Batch [94/391] Loss: 0.0640\n",
            "Epoch [25/200] Batch [95/391] Loss: 0.1172\n",
            "Epoch [25/200] Batch [96/391] Loss: 0.1342\n",
            "Epoch [25/200] Batch [97/391] Loss: 0.1269\n",
            "Epoch [25/200] Batch [98/391] Loss: 0.1351\n",
            "Epoch [25/200] Batch [99/391] Loss: 0.1460\n",
            "Epoch [25/200] Batch [100/391] Loss: 0.1912\n",
            "Epoch [25/200] Batch [101/391] Loss: 0.1458\n",
            "Epoch [25/200] Batch [102/391] Loss: 0.1479\n",
            "Epoch [25/200] Batch [103/391] Loss: 0.1748\n",
            "Epoch [25/200] Batch [104/391] Loss: 0.1980\n",
            "Epoch [25/200] Batch [105/391] Loss: 0.1575\n",
            "Epoch [25/200] Batch [106/391] Loss: 0.1866\n",
            "Epoch [25/200] Batch [107/391] Loss: 0.1252\n",
            "Epoch [25/200] Batch [108/391] Loss: 0.1383\n",
            "Epoch [25/200] Batch [109/391] Loss: 0.0937\n",
            "Epoch [25/200] Batch [110/391] Loss: 0.1174\n",
            "Epoch [25/200] Batch [111/391] Loss: 0.1686\n",
            "Epoch [25/200] Batch [112/391] Loss: 0.2099\n",
            "Epoch [25/200] Batch [113/391] Loss: 0.1116\n",
            "Epoch [25/200] Batch [114/391] Loss: 0.1259\n",
            "Epoch [25/200] Batch [115/391] Loss: 0.1395\n",
            "Epoch [25/200] Batch [116/391] Loss: 0.1383\n",
            "Epoch [25/200] Batch [117/391] Loss: 0.2056\n",
            "Epoch [25/200] Batch [118/391] Loss: 0.1798\n",
            "Epoch [25/200] Batch [119/391] Loss: 0.1556\n",
            "Epoch [25/200] Batch [120/391] Loss: 0.1431\n",
            "Epoch [25/200] Batch [121/391] Loss: 0.1451\n",
            "Epoch [25/200] Batch [122/391] Loss: 0.1151\n",
            "Epoch [25/200] Batch [123/391] Loss: 0.1012\n",
            "Epoch [25/200] Batch [124/391] Loss: 0.1143\n",
            "Epoch [25/200] Batch [125/391] Loss: 0.1881\n",
            "Epoch [25/200] Batch [126/391] Loss: 0.2279\n",
            "Epoch [25/200] Batch [127/391] Loss: 0.1173\n",
            "Epoch [25/200] Batch [128/391] Loss: 0.1764\n",
            "Epoch [25/200] Batch [129/391] Loss: 0.1934\n",
            "Epoch [25/200] Batch [130/391] Loss: 0.2086\n",
            "Epoch [25/200] Batch [131/391] Loss: 0.0976\n",
            "Epoch [25/200] Batch [132/391] Loss: 0.1960\n",
            "Epoch [25/200] Batch [133/391] Loss: 0.1218\n",
            "Epoch [25/200] Batch [134/391] Loss: 0.1079\n",
            "Epoch [25/200] Batch [135/391] Loss: 0.1445\n",
            "Epoch [25/200] Batch [136/391] Loss: 0.1637\n",
            "Epoch [25/200] Batch [137/391] Loss: 0.1401\n",
            "Epoch [25/200] Batch [138/391] Loss: 0.1683\n",
            "Epoch [25/200] Batch [139/391] Loss: 0.1492\n",
            "Epoch [25/200] Batch [140/391] Loss: 0.1555\n",
            "Epoch [25/200] Batch [141/391] Loss: 0.0677\n",
            "Epoch [25/200] Batch [142/391] Loss: 0.1025\n",
            "Epoch [25/200] Batch [143/391] Loss: 0.1920\n",
            "Epoch [25/200] Batch [144/391] Loss: 0.1603\n",
            "Epoch [25/200] Batch [145/391] Loss: 0.1876\n",
            "Epoch [25/200] Batch [146/391] Loss: 0.2787\n",
            "Epoch [25/200] Batch [147/391] Loss: 0.2033\n",
            "Epoch [25/200] Batch [148/391] Loss: 0.1185\n",
            "Epoch [25/200] Batch [149/391] Loss: 0.1578\n",
            "Epoch [25/200] Batch [150/391] Loss: 0.1765\n",
            "Epoch [25/200] Batch [151/391] Loss: 0.1638\n",
            "Epoch [25/200] Batch [152/391] Loss: 0.2016\n",
            "Epoch [25/200] Batch [153/391] Loss: 0.1436\n",
            "Epoch [25/200] Batch [154/391] Loss: 0.2805\n",
            "Epoch [25/200] Batch [155/391] Loss: 0.1717\n",
            "Epoch [25/200] Batch [156/391] Loss: 0.1680\n",
            "Epoch [25/200] Batch [157/391] Loss: 0.1123\n",
            "Epoch [25/200] Batch [158/391] Loss: 0.1987\n",
            "Epoch [25/200] Batch [159/391] Loss: 0.1665\n",
            "Epoch [25/200] Batch [160/391] Loss: 0.2447\n",
            "Epoch [25/200] Batch [161/391] Loss: 0.1874\n",
            "Epoch [25/200] Batch [162/391] Loss: 0.1569\n",
            "Epoch [25/200] Batch [163/391] Loss: 0.0893\n",
            "Epoch [25/200] Batch [164/391] Loss: 0.1308\n",
            "Epoch [25/200] Batch [165/391] Loss: 0.2410\n",
            "Epoch [25/200] Batch [166/391] Loss: 0.1370\n",
            "Epoch [25/200] Batch [167/391] Loss: 0.1976\n",
            "Epoch [25/200] Batch [168/391] Loss: 0.3938\n",
            "Epoch [25/200] Batch [169/391] Loss: 0.2079\n",
            "Epoch [25/200] Batch [170/391] Loss: 0.1264\n",
            "Epoch [25/200] Batch [171/391] Loss: 0.2377\n",
            "Epoch [25/200] Batch [172/391] Loss: 0.1327\n",
            "Epoch [25/200] Batch [173/391] Loss: 0.1738\n",
            "Epoch [25/200] Batch [174/391] Loss: 0.1891\n",
            "Epoch [25/200] Batch [175/391] Loss: 0.2016\n",
            "Epoch [25/200] Batch [176/391] Loss: 0.1775\n",
            "Epoch [25/200] Batch [177/391] Loss: 0.2414\n",
            "Epoch [25/200] Batch [178/391] Loss: 0.1649\n",
            "Epoch [25/200] Batch [179/391] Loss: 0.1293\n",
            "Epoch [25/200] Batch [180/391] Loss: 0.1562\n",
            "Epoch [25/200] Batch [181/391] Loss: 0.1934\n",
            "Epoch [25/200] Batch [182/391] Loss: 0.1910\n",
            "Epoch [25/200] Batch [183/391] Loss: 0.2005\n",
            "Epoch [25/200] Batch [184/391] Loss: 0.2794\n",
            "Epoch [25/200] Batch [185/391] Loss: 0.1371\n",
            "Epoch [25/200] Batch [186/391] Loss: 0.2666\n",
            "Epoch [25/200] Batch [187/391] Loss: 0.1293\n",
            "Epoch [25/200] Batch [188/391] Loss: 0.1035\n",
            "Epoch [25/200] Batch [189/391] Loss: 0.1342\n",
            "Epoch [25/200] Batch [190/391] Loss: 0.1026\n",
            "Epoch [25/200] Batch [191/391] Loss: 0.2088\n",
            "Epoch [25/200] Batch [192/391] Loss: 0.1621\n",
            "Epoch [25/200] Batch [193/391] Loss: 0.1861\n",
            "Epoch [25/200] Batch [194/391] Loss: 0.1696\n",
            "Epoch [25/200] Batch [195/391] Loss: 0.1733\n",
            "Epoch [25/200] Batch [196/391] Loss: 0.1317\n",
            "Epoch [25/200] Batch [197/391] Loss: 0.1644\n",
            "Epoch [25/200] Batch [198/391] Loss: 0.1148\n",
            "Epoch [25/200] Batch [199/391] Loss: 0.2372\n",
            "Epoch [25/200] Batch [200/391] Loss: 0.2609\n",
            "Epoch [25/200] Batch [201/391] Loss: 0.1817\n",
            "Epoch [25/200] Batch [202/391] Loss: 0.1671\n",
            "Epoch [25/200] Batch [203/391] Loss: 0.1885\n",
            "Epoch [25/200] Batch [204/391] Loss: 0.1441\n",
            "Epoch [25/200] Batch [205/391] Loss: 0.1171\n",
            "Epoch [25/200] Batch [206/391] Loss: 0.2237\n",
            "Epoch [25/200] Batch [207/391] Loss: 0.1401\n",
            "Epoch [25/200] Batch [208/391] Loss: 0.1385\n",
            "Epoch [25/200] Batch [209/391] Loss: 0.1444\n",
            "Epoch [25/200] Batch [210/391] Loss: 0.1303\n",
            "Epoch [25/200] Batch [211/391] Loss: 0.1709\n",
            "Epoch [25/200] Batch [212/391] Loss: 0.1141\n",
            "Epoch [25/200] Batch [213/391] Loss: 0.2192\n",
            "Epoch [25/200] Batch [214/391] Loss: 0.1791\n",
            "Epoch [25/200] Batch [215/391] Loss: 0.1987\n",
            "Epoch [25/200] Batch [216/391] Loss: 0.1342\n",
            "Epoch [25/200] Batch [217/391] Loss: 0.2691\n",
            "Epoch [25/200] Batch [218/391] Loss: 0.1527\n",
            "Epoch [25/200] Batch [219/391] Loss: 0.1633\n",
            "Epoch [25/200] Batch [220/391] Loss: 0.2238\n",
            "Epoch [25/200] Batch [221/391] Loss: 0.1920\n",
            "Epoch [25/200] Batch [222/391] Loss: 0.1068\n",
            "Epoch [25/200] Batch [223/391] Loss: 0.2503\n",
            "Epoch [25/200] Batch [224/391] Loss: 0.1627\n",
            "Epoch [25/200] Batch [225/391] Loss: 0.1934\n",
            "Epoch [25/200] Batch [226/391] Loss: 0.1259\n",
            "Epoch [25/200] Batch [227/391] Loss: 0.1603\n",
            "Epoch [25/200] Batch [228/391] Loss: 0.1572\n",
            "Epoch [25/200] Batch [229/391] Loss: 0.1107\n",
            "Epoch [25/200] Batch [230/391] Loss: 0.1317\n",
            "Epoch [25/200] Batch [231/391] Loss: 0.1819\n",
            "Epoch [25/200] Batch [232/391] Loss: 0.1729\n",
            "Epoch [25/200] Batch [233/391] Loss: 0.1945\n",
            "Epoch [25/200] Batch [234/391] Loss: 0.2744\n",
            "Epoch [25/200] Batch [235/391] Loss: 0.0844\n",
            "Epoch [25/200] Batch [236/391] Loss: 0.1979\n",
            "Epoch [25/200] Batch [237/391] Loss: 0.1570\n",
            "Epoch [25/200] Batch [238/391] Loss: 0.1080\n",
            "Epoch [25/200] Batch [239/391] Loss: 0.1420\n",
            "Epoch [25/200] Batch [240/391] Loss: 0.1742\n",
            "Epoch [25/200] Batch [241/391] Loss: 0.2159\n",
            "Epoch [25/200] Batch [242/391] Loss: 0.1829\n",
            "Epoch [25/200] Batch [243/391] Loss: 0.1816\n",
            "Epoch [25/200] Batch [244/391] Loss: 0.2906\n",
            "Epoch [25/200] Batch [245/391] Loss: 0.1638\n",
            "Epoch [25/200] Batch [246/391] Loss: 0.1482\n",
            "Epoch [25/200] Batch [247/391] Loss: 0.1512\n",
            "Epoch [25/200] Batch [248/391] Loss: 0.1536\n",
            "Epoch [25/200] Batch [249/391] Loss: 0.1753\n",
            "Epoch [25/200] Batch [250/391] Loss: 0.1394\n",
            "Epoch [25/200] Batch [251/391] Loss: 0.1552\n",
            "Epoch [25/200] Batch [252/391] Loss: 0.3230\n",
            "Epoch [25/200] Batch [253/391] Loss: 0.1857\n",
            "Epoch [25/200] Batch [254/391] Loss: 0.2538\n",
            "Epoch [25/200] Batch [255/391] Loss: 0.2438\n",
            "Epoch [25/200] Batch [256/391] Loss: 0.2114\n",
            "Epoch [25/200] Batch [257/391] Loss: 0.2370\n",
            "Epoch [25/200] Batch [258/391] Loss: 0.1462\n",
            "Epoch [25/200] Batch [259/391] Loss: 0.2290\n",
            "Epoch [25/200] Batch [260/391] Loss: 0.1486\n",
            "Epoch [25/200] Batch [261/391] Loss: 0.2806\n",
            "Epoch [25/200] Batch [262/391] Loss: 0.1111\n",
            "Epoch [25/200] Batch [263/391] Loss: 0.1923\n",
            "Epoch [25/200] Batch [264/391] Loss: 0.2025\n",
            "Epoch [25/200] Batch [265/391] Loss: 0.1830\n",
            "Epoch [25/200] Batch [266/391] Loss: 0.1498\n",
            "Epoch [25/200] Batch [267/391] Loss: 0.1800\n",
            "Epoch [25/200] Batch [268/391] Loss: 0.1289\n",
            "Epoch [25/200] Batch [269/391] Loss: 0.2012\n",
            "Epoch [25/200] Batch [270/391] Loss: 0.1484\n",
            "Epoch [25/200] Batch [271/391] Loss: 0.2765\n",
            "Epoch [25/200] Batch [272/391] Loss: 0.3430\n",
            "Epoch [25/200] Batch [273/391] Loss: 0.1452\n",
            "Epoch [25/200] Batch [274/391] Loss: 0.1547\n",
            "Epoch [25/200] Batch [275/391] Loss: 0.1533\n",
            "Epoch [25/200] Batch [276/391] Loss: 0.1138\n",
            "Epoch [25/200] Batch [277/391] Loss: 0.2098\n",
            "Epoch [25/200] Batch [278/391] Loss: 0.2326\n",
            "Epoch [25/200] Batch [279/391] Loss: 0.1562\n",
            "Epoch [25/200] Batch [280/391] Loss: 0.1618\n",
            "Epoch [25/200] Batch [281/391] Loss: 0.1580\n",
            "Epoch [25/200] Batch [282/391] Loss: 0.1604\n",
            "Epoch [25/200] Batch [283/391] Loss: 0.2488\n",
            "Epoch [25/200] Batch [284/391] Loss: 0.1952\n",
            "Epoch [25/200] Batch [285/391] Loss: 0.2339\n",
            "Epoch [25/200] Batch [286/391] Loss: 0.2072\n",
            "Epoch [25/200] Batch [287/391] Loss: 0.1973\n",
            "Epoch [25/200] Batch [288/391] Loss: 0.2909\n",
            "Epoch [25/200] Batch [289/391] Loss: 0.1958\n",
            "Epoch [25/200] Batch [290/391] Loss: 0.2147\n",
            "Epoch [25/200] Batch [291/391] Loss: 0.1657\n",
            "Epoch [25/200] Batch [292/391] Loss: 0.1985\n",
            "Epoch [25/200] Batch [293/391] Loss: 0.1909\n",
            "Epoch [25/200] Batch [294/391] Loss: 0.2288\n",
            "Epoch [25/200] Batch [295/391] Loss: 0.1289\n",
            "Epoch [25/200] Batch [296/391] Loss: 0.3255\n",
            "Epoch [25/200] Batch [297/391] Loss: 0.2163\n",
            "Epoch [25/200] Batch [298/391] Loss: 0.3436\n",
            "Epoch [25/200] Batch [299/391] Loss: 0.1810\n",
            "Epoch [25/200] Batch [300/391] Loss: 0.2803\n",
            "Epoch [25/200] Batch [301/391] Loss: 0.1580\n",
            "Epoch [25/200] Batch [302/391] Loss: 0.2044\n",
            "Epoch [25/200] Batch [303/391] Loss: 0.3146\n",
            "Epoch [25/200] Batch [304/391] Loss: 0.1884\n",
            "Epoch [25/200] Batch [305/391] Loss: 0.2429\n",
            "Epoch [25/200] Batch [306/391] Loss: 0.1321\n",
            "Epoch [25/200] Batch [307/391] Loss: 0.1837\n",
            "Epoch [25/200] Batch [308/391] Loss: 0.2190\n",
            "Epoch [25/200] Batch [309/391] Loss: 0.1668\n",
            "Epoch [25/200] Batch [310/391] Loss: 0.2911\n",
            "Epoch [25/200] Batch [311/391] Loss: 0.1829\n",
            "Epoch [25/200] Batch [312/391] Loss: 0.3132\n",
            "Epoch [25/200] Batch [313/391] Loss: 0.2268\n",
            "Epoch [25/200] Batch [314/391] Loss: 0.1929\n",
            "Epoch [25/200] Batch [315/391] Loss: 0.1638\n",
            "Epoch [25/200] Batch [316/391] Loss: 0.2569\n",
            "Epoch [25/200] Batch [317/391] Loss: 0.1978\n",
            "Epoch [25/200] Batch [318/391] Loss: 0.1644\n",
            "Epoch [25/200] Batch [319/391] Loss: 0.1985\n",
            "Epoch [25/200] Batch [320/391] Loss: 0.1618\n",
            "Epoch [25/200] Batch [321/391] Loss: 0.2347\n",
            "Epoch [25/200] Batch [322/391] Loss: 0.3085\n",
            "Epoch [25/200] Batch [323/391] Loss: 0.2717\n",
            "Epoch [25/200] Batch [324/391] Loss: 0.1977\n",
            "Epoch [25/200] Batch [325/391] Loss: 0.1090\n",
            "Epoch [25/200] Batch [326/391] Loss: 0.1317\n",
            "Epoch [25/200] Batch [327/391] Loss: 0.2037\n",
            "Epoch [25/200] Batch [328/391] Loss: 0.1073\n",
            "Epoch [25/200] Batch [329/391] Loss: 0.1947\n",
            "Epoch [25/200] Batch [330/391] Loss: 0.1583\n",
            "Epoch [25/200] Batch [331/391] Loss: 0.2141\n",
            "Epoch [25/200] Batch [332/391] Loss: 0.1459\n",
            "Epoch [25/200] Batch [333/391] Loss: 0.1534\n",
            "Epoch [25/200] Batch [334/391] Loss: 0.1822\n",
            "Epoch [25/200] Batch [335/391] Loss: 0.2475\n",
            "Epoch [25/200] Batch [336/391] Loss: 0.1512\n",
            "Epoch [25/200] Batch [337/391] Loss: 0.1592\n",
            "Epoch [25/200] Batch [338/391] Loss: 0.1101\n",
            "Epoch [25/200] Batch [339/391] Loss: 0.1597\n",
            "Epoch [25/200] Batch [340/391] Loss: 0.0749\n",
            "Epoch [25/200] Batch [341/391] Loss: 0.2160\n",
            "Epoch [25/200] Batch [342/391] Loss: 0.2871\n",
            "Epoch [25/200] Batch [343/391] Loss: 0.2848\n",
            "Epoch [25/200] Batch [344/391] Loss: 0.1193\n",
            "Epoch [25/200] Batch [345/391] Loss: 0.1412\n",
            "Epoch [25/200] Batch [346/391] Loss: 0.1881\n",
            "Epoch [25/200] Batch [347/391] Loss: 0.2015\n",
            "Epoch [25/200] Batch [348/391] Loss: 0.1963\n",
            "Epoch [25/200] Batch [349/391] Loss: 0.1578\n",
            "Epoch [25/200] Batch [350/391] Loss: 0.1063\n",
            "Epoch [25/200] Batch [351/391] Loss: 0.1420\n",
            "Epoch [25/200] Batch [352/391] Loss: 0.2179\n",
            "Epoch [25/200] Batch [353/391] Loss: 0.1616\n",
            "Epoch [25/200] Batch [354/391] Loss: 0.1122\n",
            "Epoch [25/200] Batch [355/391] Loss: 0.1459\n",
            "Epoch [25/200] Batch [356/391] Loss: 0.2437\n",
            "Epoch [25/200] Batch [357/391] Loss: 0.0860\n",
            "Epoch [25/200] Batch [358/391] Loss: 0.2594\n",
            "Epoch [25/200] Batch [359/391] Loss: 0.1435\n",
            "Epoch [25/200] Batch [360/391] Loss: 0.1527\n",
            "Epoch [25/200] Batch [361/391] Loss: 0.2073\n",
            "Epoch [25/200] Batch [362/391] Loss: 0.1624\n",
            "Epoch [25/200] Batch [363/391] Loss: 0.2816\n",
            "Epoch [25/200] Batch [364/391] Loss: 0.1472\n",
            "Epoch [25/200] Batch [365/391] Loss: 0.1674\n",
            "Epoch [25/200] Batch [366/391] Loss: 0.1585\n",
            "Epoch [25/200] Batch [367/391] Loss: 0.1902\n",
            "Epoch [25/200] Batch [368/391] Loss: 0.1744\n",
            "Epoch [25/200] Batch [369/391] Loss: 0.1471\n",
            "Epoch [25/200] Batch [370/391] Loss: 0.1677\n",
            "Epoch [25/200] Batch [371/391] Loss: 0.1555\n",
            "Epoch [25/200] Batch [372/391] Loss: 0.1967\n",
            "Epoch [25/200] Batch [373/391] Loss: 0.2243\n",
            "Epoch [25/200] Batch [374/391] Loss: 0.1325\n",
            "Epoch [25/200] Batch [375/391] Loss: 0.2054\n",
            "Epoch [25/200] Batch [376/391] Loss: 0.1926\n",
            "Epoch [25/200] Batch [377/391] Loss: 0.1803\n",
            "Epoch [25/200] Batch [378/391] Loss: 0.1819\n",
            "Epoch [25/200] Batch [379/391] Loss: 0.2124\n",
            "Epoch [25/200] Batch [380/391] Loss: 0.2042\n",
            "Epoch [25/200] Batch [381/391] Loss: 0.2868\n",
            "Epoch [25/200] Batch [382/391] Loss: 0.1656\n",
            "Epoch [25/200] Batch [383/391] Loss: 0.1974\n",
            "Epoch [25/200] Batch [384/391] Loss: 0.2152\n",
            "Epoch [25/200] Batch [385/391] Loss: 0.1661\n",
            "Epoch [25/200] Batch [386/391] Loss: 0.3307\n",
            "Epoch [25/200] Batch [387/391] Loss: 0.2143\n",
            "Epoch [25/200] Batch [388/391] Loss: 0.2521\n",
            "Epoch [25/200] Batch [389/391] Loss: 0.3103\n",
            "Epoch [25/200] Batch [390/391] Loss: 0.2181\n",
            "Epoch [25/200] Batch [391/391] Loss: 0.2908\n",
            "Epoch [25/200] - Train Loss: 0.1730 - Test Loss: 0.6221 - Train Acc: 90.67% - Test Acc: 81.71%\n",
            "Saved new best model with test loss: 0.6221\n",
            "Epoch [26/200] Batch [1/391] Loss: 0.2127\n",
            "Epoch [26/200] Batch [2/391] Loss: 0.1388\n",
            "Epoch [26/200] Batch [3/391] Loss: 0.1884\n",
            "Epoch [26/200] Batch [4/391] Loss: 0.1388\n",
            "Epoch [26/200] Batch [5/391] Loss: 0.2832\n",
            "Epoch [26/200] Batch [6/391] Loss: 0.1984\n",
            "Epoch [26/200] Batch [7/391] Loss: 0.1212\n",
            "Epoch [26/200] Batch [8/391] Loss: 0.1728\n",
            "Epoch [26/200] Batch [9/391] Loss: 0.1433\n",
            "Epoch [26/200] Batch [10/391] Loss: 0.2161\n",
            "Epoch [26/200] Batch [11/391] Loss: 0.1157\n",
            "Epoch [26/200] Batch [12/391] Loss: 0.1510\n",
            "Epoch [26/200] Batch [13/391] Loss: 0.1661\n",
            "Epoch [26/200] Batch [14/391] Loss: 0.1655\n",
            "Epoch [26/200] Batch [15/391] Loss: 0.1415\n",
            "Epoch [26/200] Batch [16/391] Loss: 0.1839\n",
            "Epoch [26/200] Batch [17/391] Loss: 0.1605\n",
            "Epoch [26/200] Batch [18/391] Loss: 0.3132\n",
            "Epoch [26/200] Batch [19/391] Loss: 0.2080\n",
            "Epoch [26/200] Batch [20/391] Loss: 0.0948\n",
            "Epoch [26/200] Batch [21/391] Loss: 0.1347\n",
            "Epoch [26/200] Batch [22/391] Loss: 0.1846\n",
            "Epoch [26/200] Batch [23/391] Loss: 0.1264\n",
            "Epoch [26/200] Batch [24/391] Loss: 0.1327\n",
            "Epoch [26/200] Batch [25/391] Loss: 0.2150\n",
            "Epoch [26/200] Batch [26/391] Loss: 0.1429\n",
            "Epoch [26/200] Batch [27/391] Loss: 0.0554\n",
            "Epoch [26/200] Batch [28/391] Loss: 0.2052\n",
            "Epoch [26/200] Batch [29/391] Loss: 0.1530\n",
            "Epoch [26/200] Batch [30/391] Loss: 0.1955\n",
            "Epoch [26/200] Batch [31/391] Loss: 0.1592\n",
            "Epoch [26/200] Batch [32/391] Loss: 0.1221\n",
            "Epoch [26/200] Batch [33/391] Loss: 0.2259\n",
            "Epoch [26/200] Batch [34/391] Loss: 0.1253\n",
            "Epoch [26/200] Batch [35/391] Loss: 0.1450\n",
            "Epoch [26/200] Batch [36/391] Loss: 0.2200\n",
            "Epoch [26/200] Batch [37/391] Loss: 0.1384\n",
            "Epoch [26/200] Batch [38/391] Loss: 0.1260\n",
            "Epoch [26/200] Batch [39/391] Loss: 0.1670\n",
            "Epoch [26/200] Batch [40/391] Loss: 0.1400\n",
            "Epoch [26/200] Batch [41/391] Loss: 0.1379\n",
            "Epoch [26/200] Batch [42/391] Loss: 0.1206\n",
            "Epoch [26/200] Batch [43/391] Loss: 0.1808\n",
            "Epoch [26/200] Batch [44/391] Loss: 0.1169\n",
            "Epoch [26/200] Batch [45/391] Loss: 0.1432\n",
            "Epoch [26/200] Batch [46/391] Loss: 0.1085\n",
            "Epoch [26/200] Batch [47/391] Loss: 0.1572\n",
            "Epoch [26/200] Batch [48/391] Loss: 0.0697\n",
            "Epoch [26/200] Batch [49/391] Loss: 0.1632\n",
            "Epoch [26/200] Batch [50/391] Loss: 0.1884\n",
            "Epoch [26/200] Batch [51/391] Loss: 0.1389\n",
            "Epoch [26/200] Batch [52/391] Loss: 0.0895\n",
            "Epoch [26/200] Batch [53/391] Loss: 0.2384\n",
            "Epoch [26/200] Batch [54/391] Loss: 0.2007\n",
            "Epoch [26/200] Batch [55/391] Loss: 0.1294\n",
            "Epoch [26/200] Batch [56/391] Loss: 0.1484\n",
            "Epoch [26/200] Batch [57/391] Loss: 0.0902\n",
            "Epoch [26/200] Batch [58/391] Loss: 0.1463\n",
            "Epoch [26/200] Batch [59/391] Loss: 0.1547\n",
            "Epoch [26/200] Batch [60/391] Loss: 0.1950\n",
            "Epoch [26/200] Batch [61/391] Loss: 0.1109\n",
            "Epoch [26/200] Batch [62/391] Loss: 0.1100\n",
            "Epoch [26/200] Batch [63/391] Loss: 0.1319\n",
            "Epoch [26/200] Batch [64/391] Loss: 0.2670\n",
            "Epoch [26/200] Batch [65/391] Loss: 0.1734\n",
            "Epoch [26/200] Batch [66/391] Loss: 0.2449\n",
            "Epoch [26/200] Batch [67/391] Loss: 0.2349\n",
            "Epoch [26/200] Batch [68/391] Loss: 0.1413\n",
            "Epoch [26/200] Batch [69/391] Loss: 0.1801\n",
            "Epoch [26/200] Batch [70/391] Loss: 0.1449\n",
            "Epoch [26/200] Batch [71/391] Loss: 0.1206\n",
            "Epoch [26/200] Batch [72/391] Loss: 0.1408\n",
            "Epoch [26/200] Batch [73/391] Loss: 0.1762\n",
            "Epoch [26/200] Batch [74/391] Loss: 0.1220\n",
            "Epoch [26/200] Batch [75/391] Loss: 0.1462\n",
            "Epoch [26/200] Batch [76/391] Loss: 0.1480\n",
            "Epoch [26/200] Batch [77/391] Loss: 0.1309\n",
            "Epoch [26/200] Batch [78/391] Loss: 0.1601\n",
            "Epoch [26/200] Batch [79/391] Loss: 0.1485\n",
            "Epoch [26/200] Batch [80/391] Loss: 0.1284\n",
            "Epoch [26/200] Batch [81/391] Loss: 0.1203\n",
            "Epoch [26/200] Batch [82/391] Loss: 0.1605\n",
            "Epoch [26/200] Batch [83/391] Loss: 0.2221\n",
            "Epoch [26/200] Batch [84/391] Loss: 0.1511\n",
            "Epoch [26/200] Batch [85/391] Loss: 0.1240\n",
            "Epoch [26/200] Batch [86/391] Loss: 0.1192\n",
            "Epoch [26/200] Batch [87/391] Loss: 0.1795\n",
            "Epoch [26/200] Batch [88/391] Loss: 0.2215\n",
            "Epoch [26/200] Batch [89/391] Loss: 0.1501\n",
            "Epoch [26/200] Batch [90/391] Loss: 0.1532\n",
            "Epoch [26/200] Batch [91/391] Loss: 0.1182\n",
            "Epoch [26/200] Batch [92/391] Loss: 0.1695\n",
            "Epoch [26/200] Batch [93/391] Loss: 0.1754\n",
            "Epoch [26/200] Batch [94/391] Loss: 0.1686\n",
            "Epoch [26/200] Batch [95/391] Loss: 0.1588\n",
            "Epoch [26/200] Batch [96/391] Loss: 0.1351\n",
            "Epoch [26/200] Batch [97/391] Loss: 0.1307\n",
            "Epoch [26/200] Batch [98/391] Loss: 0.2566\n",
            "Epoch [26/200] Batch [99/391] Loss: 0.1665\n",
            "Epoch [26/200] Batch [100/391] Loss: 0.1763\n",
            "Epoch [26/200] Batch [101/391] Loss: 0.1979\n",
            "Epoch [26/200] Batch [102/391] Loss: 0.1314\n",
            "Epoch [26/200] Batch [103/391] Loss: 0.1163\n",
            "Epoch [26/200] Batch [104/391] Loss: 0.0710\n",
            "Epoch [26/200] Batch [105/391] Loss: 0.1350\n",
            "Epoch [26/200] Batch [106/391] Loss: 0.1261\n",
            "Epoch [26/200] Batch [107/391] Loss: 0.1260\n",
            "Epoch [26/200] Batch [108/391] Loss: 0.1451\n",
            "Epoch [26/200] Batch [109/391] Loss: 0.1914\n",
            "Epoch [26/200] Batch [110/391] Loss: 0.1218\n",
            "Epoch [26/200] Batch [111/391] Loss: 0.1826\n",
            "Epoch [26/200] Batch [112/391] Loss: 0.1572\n",
            "Epoch [26/200] Batch [113/391] Loss: 0.1986\n",
            "Epoch [26/200] Batch [114/391] Loss: 0.2578\n",
            "Epoch [26/200] Batch [115/391] Loss: 0.1365\n",
            "Epoch [26/200] Batch [116/391] Loss: 0.1176\n",
            "Epoch [26/200] Batch [117/391] Loss: 0.1551\n",
            "Epoch [26/200] Batch [118/391] Loss: 0.2030\n",
            "Epoch [26/200] Batch [119/391] Loss: 0.1522\n",
            "Epoch [26/200] Batch [120/391] Loss: 0.1547\n",
            "Epoch [26/200] Batch [121/391] Loss: 0.1480\n",
            "Epoch [26/200] Batch [122/391] Loss: 0.2002\n",
            "Epoch [26/200] Batch [123/391] Loss: 0.1679\n",
            "Epoch [26/200] Batch [124/391] Loss: 0.1392\n",
            "Epoch [26/200] Batch [125/391] Loss: 0.1639\n",
            "Epoch [26/200] Batch [126/391] Loss: 0.1370\n",
            "Epoch [26/200] Batch [127/391] Loss: 0.1991\n",
            "Epoch [26/200] Batch [128/391] Loss: 0.1625\n",
            "Epoch [26/200] Batch [129/391] Loss: 0.2013\n",
            "Epoch [26/200] Batch [130/391] Loss: 0.1599\n",
            "Epoch [26/200] Batch [131/391] Loss: 0.1879\n",
            "Epoch [26/200] Batch [132/391] Loss: 0.1824\n",
            "Epoch [26/200] Batch [133/391] Loss: 0.3045\n",
            "Epoch [26/200] Batch [134/391] Loss: 0.1830\n",
            "Epoch [26/200] Batch [135/391] Loss: 0.1137\n",
            "Epoch [26/200] Batch [136/391] Loss: 0.0862\n",
            "Epoch [26/200] Batch [137/391] Loss: 0.1264\n",
            "Epoch [26/200] Batch [138/391] Loss: 0.1551\n",
            "Epoch [26/200] Batch [139/391] Loss: 0.1481\n",
            "Epoch [26/200] Batch [140/391] Loss: 0.1690\n",
            "Epoch [26/200] Batch [141/391] Loss: 0.1213\n",
            "Epoch [26/200] Batch [142/391] Loss: 0.1866\n",
            "Epoch [26/200] Batch [143/391] Loss: 0.2047\n",
            "Epoch [26/200] Batch [144/391] Loss: 0.1893\n",
            "Epoch [26/200] Batch [145/391] Loss: 0.1888\n",
            "Epoch [26/200] Batch [146/391] Loss: 0.1305\n",
            "Epoch [26/200] Batch [147/391] Loss: 0.1794\n",
            "Epoch [26/200] Batch [148/391] Loss: 0.1517\n",
            "Epoch [26/200] Batch [149/391] Loss: 0.1193\n",
            "Epoch [26/200] Batch [150/391] Loss: 0.0959\n",
            "Epoch [26/200] Batch [151/391] Loss: 0.1687\n",
            "Epoch [26/200] Batch [152/391] Loss: 0.2464\n",
            "Epoch [26/200] Batch [153/391] Loss: 0.1141\n",
            "Epoch [26/200] Batch [154/391] Loss: 0.1210\n",
            "Epoch [26/200] Batch [155/391] Loss: 0.0761\n",
            "Epoch [26/200] Batch [156/391] Loss: 0.1844\n",
            "Epoch [26/200] Batch [157/391] Loss: 0.2151\n",
            "Epoch [26/200] Batch [158/391] Loss: 0.1244\n",
            "Epoch [26/200] Batch [159/391] Loss: 0.1563\n",
            "Epoch [26/200] Batch [160/391] Loss: 0.1099\n",
            "Epoch [26/200] Batch [161/391] Loss: 0.1744\n",
            "Epoch [26/200] Batch [162/391] Loss: 0.1494\n",
            "Epoch [26/200] Batch [163/391] Loss: 0.1312\n",
            "Epoch [26/200] Batch [164/391] Loss: 0.1128\n",
            "Epoch [26/200] Batch [165/391] Loss: 0.0936\n",
            "Epoch [26/200] Batch [166/391] Loss: 0.1331\n",
            "Epoch [26/200] Batch [167/391] Loss: 0.2573\n",
            "Epoch [26/200] Batch [168/391] Loss: 0.1983\n",
            "Epoch [26/200] Batch [169/391] Loss: 0.2458\n",
            "Epoch [26/200] Batch [170/391] Loss: 0.1919\n",
            "Epoch [26/200] Batch [171/391] Loss: 0.1731\n",
            "Epoch [26/200] Batch [172/391] Loss: 0.1447\n",
            "Epoch [26/200] Batch [173/391] Loss: 0.1628\n",
            "Epoch [26/200] Batch [174/391] Loss: 0.1775\n",
            "Epoch [26/200] Batch [175/391] Loss: 0.2918\n",
            "Epoch [26/200] Batch [176/391] Loss: 0.1782\n",
            "Epoch [26/200] Batch [177/391] Loss: 0.1834\n",
            "Epoch [26/200] Batch [178/391] Loss: 0.1936\n",
            "Epoch [26/200] Batch [179/391] Loss: 0.1572\n",
            "Epoch [26/200] Batch [180/391] Loss: 0.1625\n",
            "Epoch [26/200] Batch [181/391] Loss: 0.1337\n",
            "Epoch [26/200] Batch [182/391] Loss: 0.2307\n",
            "Epoch [26/200] Batch [183/391] Loss: 0.2319\n",
            "Epoch [26/200] Batch [184/391] Loss: 0.1010\n",
            "Epoch [26/200] Batch [185/391] Loss: 0.1853\n",
            "Epoch [26/200] Batch [186/391] Loss: 0.1229\n",
            "Epoch [26/200] Batch [187/391] Loss: 0.1581\n",
            "Epoch [26/200] Batch [188/391] Loss: 0.2810\n",
            "Epoch [26/200] Batch [189/391] Loss: 0.0914\n",
            "Epoch [26/200] Batch [190/391] Loss: 0.1889\n",
            "Epoch [26/200] Batch [191/391] Loss: 0.2109\n",
            "Epoch [26/200] Batch [192/391] Loss: 0.1821\n",
            "Epoch [26/200] Batch [193/391] Loss: 0.1166\n",
            "Epoch [26/200] Batch [194/391] Loss: 0.2124\n",
            "Epoch [26/200] Batch [195/391] Loss: 0.1375\n",
            "Epoch [26/200] Batch [196/391] Loss: 0.1988\n",
            "Epoch [26/200] Batch [197/391] Loss: 0.1587\n",
            "Epoch [26/200] Batch [198/391] Loss: 0.1237\n",
            "Epoch [26/200] Batch [199/391] Loss: 0.2038\n",
            "Epoch [26/200] Batch [200/391] Loss: 0.1410\n",
            "Epoch [26/200] Batch [201/391] Loss: 0.1459\n",
            "Epoch [26/200] Batch [202/391] Loss: 0.1558\n",
            "Epoch [26/200] Batch [203/391] Loss: 0.1694\n",
            "Epoch [26/200] Batch [204/391] Loss: 0.1446\n",
            "Epoch [26/200] Batch [205/391] Loss: 0.2063\n",
            "Epoch [26/200] Batch [206/391] Loss: 0.2081\n",
            "Epoch [26/200] Batch [207/391] Loss: 0.1710\n",
            "Epoch [26/200] Batch [208/391] Loss: 0.1784\n",
            "Epoch [26/200] Batch [209/391] Loss: 0.1821\n",
            "Epoch [26/200] Batch [210/391] Loss: 0.1389\n",
            "Epoch [26/200] Batch [211/391] Loss: 0.1792\n",
            "Epoch [26/200] Batch [212/391] Loss: 0.1063\n",
            "Epoch [26/200] Batch [213/391] Loss: 0.2187\n",
            "Epoch [26/200] Batch [214/391] Loss: 0.1119\n",
            "Epoch [26/200] Batch [215/391] Loss: 0.2569\n",
            "Epoch [26/200] Batch [216/391] Loss: 0.1722\n",
            "Epoch [26/200] Batch [217/391] Loss: 0.1551\n",
            "Epoch [26/200] Batch [218/391] Loss: 0.0680\n",
            "Epoch [26/200] Batch [219/391] Loss: 0.1689\n",
            "Epoch [26/200] Batch [220/391] Loss: 0.2134\n",
            "Epoch [26/200] Batch [221/391] Loss: 0.1846\n",
            "Epoch [26/200] Batch [222/391] Loss: 0.1669\n",
            "Epoch [26/200] Batch [223/391] Loss: 0.0859\n",
            "Epoch [26/200] Batch [224/391] Loss: 0.2525\n",
            "Epoch [26/200] Batch [225/391] Loss: 0.2131\n",
            "Epoch [26/200] Batch [226/391] Loss: 0.1498\n",
            "Epoch [26/200] Batch [227/391] Loss: 0.1123\n",
            "Epoch [26/200] Batch [228/391] Loss: 0.1346\n",
            "Epoch [26/200] Batch [229/391] Loss: 0.1201\n",
            "Epoch [26/200] Batch [230/391] Loss: 0.2097\n",
            "Epoch [26/200] Batch [231/391] Loss: 0.0857\n",
            "Epoch [26/200] Batch [232/391] Loss: 0.1766\n",
            "Epoch [26/200] Batch [233/391] Loss: 0.1617\n",
            "Epoch [26/200] Batch [234/391] Loss: 0.1194\n",
            "Epoch [26/200] Batch [235/391] Loss: 0.2522\n",
            "Epoch [26/200] Batch [236/391] Loss: 0.1930\n",
            "Epoch [26/200] Batch [237/391] Loss: 0.1365\n",
            "Epoch [26/200] Batch [238/391] Loss: 0.1843\n",
            "Epoch [26/200] Batch [239/391] Loss: 0.1445\n",
            "Epoch [26/200] Batch [240/391] Loss: 0.1953\n",
            "Epoch [26/200] Batch [241/391] Loss: 0.1861\n",
            "Epoch [26/200] Batch [242/391] Loss: 0.0956\n",
            "Epoch [26/200] Batch [243/391] Loss: 0.1417\n",
            "Epoch [26/200] Batch [244/391] Loss: 0.1674\n",
            "Epoch [26/200] Batch [245/391] Loss: 0.1399\n",
            "Epoch [26/200] Batch [246/391] Loss: 0.1350\n",
            "Epoch [26/200] Batch [247/391] Loss: 0.2677\n",
            "Epoch [26/200] Batch [248/391] Loss: 0.1891\n",
            "Epoch [26/200] Batch [249/391] Loss: 0.2323\n",
            "Epoch [26/200] Batch [250/391] Loss: 0.1745\n",
            "Epoch [26/200] Batch [251/391] Loss: 0.0778\n",
            "Epoch [26/200] Batch [252/391] Loss: 0.2923\n",
            "Epoch [26/200] Batch [253/391] Loss: 0.1358\n",
            "Epoch [26/200] Batch [254/391] Loss: 0.1567\n",
            "Epoch [26/200] Batch [255/391] Loss: 0.1185\n",
            "Epoch [26/200] Batch [256/391] Loss: 0.3478\n",
            "Epoch [26/200] Batch [257/391] Loss: 0.1730\n",
            "Epoch [26/200] Batch [258/391] Loss: 0.1604\n",
            "Epoch [26/200] Batch [259/391] Loss: 0.1287\n",
            "Epoch [26/200] Batch [260/391] Loss: 0.2270\n",
            "Epoch [26/200] Batch [261/391] Loss: 0.2510\n",
            "Epoch [26/200] Batch [262/391] Loss: 0.2259\n",
            "Epoch [26/200] Batch [263/391] Loss: 0.1553\n",
            "Epoch [26/200] Batch [264/391] Loss: 0.1475\n",
            "Epoch [26/200] Batch [265/391] Loss: 0.1370\n",
            "Epoch [26/200] Batch [266/391] Loss: 0.1055\n",
            "Epoch [26/200] Batch [267/391] Loss: 0.2632\n",
            "Epoch [26/200] Batch [268/391] Loss: 0.2747\n",
            "Epoch [26/200] Batch [269/391] Loss: 0.2051\n",
            "Epoch [26/200] Batch [270/391] Loss: 0.1207\n",
            "Epoch [26/200] Batch [271/391] Loss: 0.2004\n",
            "Epoch [26/200] Batch [272/391] Loss: 0.1870\n",
            "Epoch [26/200] Batch [273/391] Loss: 0.2627\n",
            "Epoch [26/200] Batch [274/391] Loss: 0.2961\n",
            "Epoch [26/200] Batch [275/391] Loss: 0.2871\n",
            "Epoch [26/200] Batch [276/391] Loss: 0.1735\n",
            "Epoch [26/200] Batch [277/391] Loss: 0.1412\n",
            "Epoch [26/200] Batch [278/391] Loss: 0.1410\n",
            "Epoch [26/200] Batch [279/391] Loss: 0.1877\n",
            "Epoch [26/200] Batch [280/391] Loss: 0.2425\n",
            "Epoch [26/200] Batch [281/391] Loss: 0.1138\n",
            "Epoch [26/200] Batch [282/391] Loss: 0.2320\n",
            "Epoch [26/200] Batch [283/391] Loss: 0.0993\n",
            "Epoch [26/200] Batch [284/391] Loss: 0.1824\n",
            "Epoch [26/200] Batch [285/391] Loss: 0.2286\n",
            "Epoch [26/200] Batch [286/391] Loss: 0.2056\n",
            "Epoch [26/200] Batch [287/391] Loss: 0.2745\n",
            "Epoch [26/200] Batch [288/391] Loss: 0.1857\n",
            "Epoch [26/200] Batch [289/391] Loss: 0.1788\n",
            "Epoch [26/200] Batch [290/391] Loss: 0.1682\n",
            "Epoch [26/200] Batch [291/391] Loss: 0.2047\n",
            "Epoch [26/200] Batch [292/391] Loss: 0.1179\n",
            "Epoch [26/200] Batch [293/391] Loss: 0.1602\n",
            "Epoch [26/200] Batch [294/391] Loss: 0.1271\n",
            "Epoch [26/200] Batch [295/391] Loss: 0.2088\n",
            "Epoch [26/200] Batch [296/391] Loss: 0.1871\n",
            "Epoch [26/200] Batch [297/391] Loss: 0.1818\n",
            "Epoch [26/200] Batch [298/391] Loss: 0.2189\n",
            "Epoch [26/200] Batch [299/391] Loss: 0.1505\n",
            "Epoch [26/200] Batch [300/391] Loss: 0.2348\n",
            "Epoch [26/200] Batch [301/391] Loss: 0.2757\n",
            "Epoch [26/200] Batch [302/391] Loss: 0.1877\n",
            "Epoch [26/200] Batch [303/391] Loss: 0.1954\n",
            "Epoch [26/200] Batch [304/391] Loss: 0.2159\n",
            "Epoch [26/200] Batch [305/391] Loss: 0.1517\n",
            "Epoch [26/200] Batch [306/391] Loss: 0.1553\n",
            "Epoch [26/200] Batch [307/391] Loss: 0.2102\n",
            "Epoch [26/200] Batch [308/391] Loss: 0.1345\n",
            "Epoch [26/200] Batch [309/391] Loss: 0.1572\n",
            "Epoch [26/200] Batch [310/391] Loss: 0.2648\n",
            "Epoch [26/200] Batch [311/391] Loss: 0.1515\n",
            "Epoch [26/200] Batch [312/391] Loss: 0.3260\n",
            "Epoch [26/200] Batch [313/391] Loss: 0.1457\n",
            "Epoch [26/200] Batch [314/391] Loss: 0.2685\n",
            "Epoch [26/200] Batch [315/391] Loss: 0.1463\n",
            "Epoch [26/200] Batch [316/391] Loss: 0.2879\n",
            "Epoch [26/200] Batch [317/391] Loss: 0.1655\n",
            "Epoch [26/200] Batch [318/391] Loss: 0.1607\n",
            "Epoch [26/200] Batch [319/391] Loss: 0.1687\n",
            "Epoch [26/200] Batch [320/391] Loss: 0.2488\n",
            "Epoch [26/200] Batch [321/391] Loss: 0.1735\n",
            "Epoch [26/200] Batch [322/391] Loss: 0.2229\n",
            "Epoch [26/200] Batch [323/391] Loss: 0.1601\n",
            "Epoch [26/200] Batch [324/391] Loss: 0.2003\n",
            "Epoch [26/200] Batch [325/391] Loss: 0.1579\n",
            "Epoch [26/200] Batch [326/391] Loss: 0.2652\n",
            "Epoch [26/200] Batch [327/391] Loss: 0.2091\n",
            "Epoch [26/200] Batch [328/391] Loss: 0.1277\n",
            "Epoch [26/200] Batch [329/391] Loss: 0.2818\n",
            "Epoch [26/200] Batch [330/391] Loss: 0.2188\n",
            "Epoch [26/200] Batch [331/391] Loss: 0.2839\n",
            "Epoch [26/200] Batch [332/391] Loss: 0.1910\n",
            "Epoch [26/200] Batch [333/391] Loss: 0.1207\n",
            "Epoch [26/200] Batch [334/391] Loss: 0.1613\n",
            "Epoch [26/200] Batch [335/391] Loss: 0.1627\n",
            "Epoch [26/200] Batch [336/391] Loss: 0.1958\n",
            "Epoch [26/200] Batch [337/391] Loss: 0.1454\n",
            "Epoch [26/200] Batch [338/391] Loss: 0.1831\n",
            "Epoch [26/200] Batch [339/391] Loss: 0.1055\n",
            "Epoch [26/200] Batch [340/391] Loss: 0.1764\n",
            "Epoch [26/200] Batch [341/391] Loss: 0.1795\n",
            "Epoch [26/200] Batch [342/391] Loss: 0.1832\n",
            "Epoch [26/200] Batch [343/391] Loss: 0.1673\n",
            "Epoch [26/200] Batch [344/391] Loss: 0.1395\n",
            "Epoch [26/200] Batch [345/391] Loss: 0.1530\n",
            "Epoch [26/200] Batch [346/391] Loss: 0.3550\n",
            "Epoch [26/200] Batch [347/391] Loss: 0.2397\n",
            "Epoch [26/200] Batch [348/391] Loss: 0.1623\n",
            "Epoch [26/200] Batch [349/391] Loss: 0.2437\n",
            "Epoch [26/200] Batch [350/391] Loss: 0.1241\n",
            "Epoch [26/200] Batch [351/391] Loss: 0.1733\n",
            "Epoch [26/200] Batch [352/391] Loss: 0.2198\n",
            "Epoch [26/200] Batch [353/391] Loss: 0.1115\n",
            "Epoch [26/200] Batch [354/391] Loss: 0.1643\n",
            "Epoch [26/200] Batch [355/391] Loss: 0.1476\n",
            "Epoch [26/200] Batch [356/391] Loss: 0.2688\n",
            "Epoch [26/200] Batch [357/391] Loss: 0.1939\n",
            "Epoch [26/200] Batch [358/391] Loss: 0.2873\n",
            "Epoch [26/200] Batch [359/391] Loss: 0.1802\n",
            "Epoch [26/200] Batch [360/391] Loss: 0.2066\n",
            "Epoch [26/200] Batch [361/391] Loss: 0.1933\n",
            "Epoch [26/200] Batch [362/391] Loss: 0.2230\n",
            "Epoch [26/200] Batch [363/391] Loss: 0.1381\n",
            "Epoch [26/200] Batch [364/391] Loss: 0.1340\n",
            "Epoch [26/200] Batch [365/391] Loss: 0.1116\n",
            "Epoch [26/200] Batch [366/391] Loss: 0.2123\n",
            "Epoch [26/200] Batch [367/391] Loss: 0.1760\n",
            "Epoch [26/200] Batch [368/391] Loss: 0.2133\n",
            "Epoch [26/200] Batch [369/391] Loss: 0.3219\n",
            "Epoch [26/200] Batch [370/391] Loss: 0.1570\n",
            "Epoch [26/200] Batch [371/391] Loss: 0.1199\n",
            "Epoch [26/200] Batch [372/391] Loss: 0.2217\n",
            "Epoch [26/200] Batch [373/391] Loss: 0.2153\n",
            "Epoch [26/200] Batch [374/391] Loss: 0.1317\n",
            "Epoch [26/200] Batch [375/391] Loss: 0.1921\n",
            "Epoch [26/200] Batch [376/391] Loss: 0.1410\n",
            "Epoch [26/200] Batch [377/391] Loss: 0.2860\n",
            "Epoch [26/200] Batch [378/391] Loss: 0.1090\n",
            "Epoch [26/200] Batch [379/391] Loss: 0.2767\n",
            "Epoch [26/200] Batch [380/391] Loss: 0.1673\n",
            "Epoch [26/200] Batch [381/391] Loss: 0.1582\n",
            "Epoch [26/200] Batch [382/391] Loss: 0.2795\n",
            "Epoch [26/200] Batch [383/391] Loss: 0.0874\n",
            "Epoch [26/200] Batch [384/391] Loss: 0.1516\n",
            "Epoch [26/200] Batch [385/391] Loss: 0.2485\n",
            "Epoch [26/200] Batch [386/391] Loss: 0.1078\n",
            "Epoch [26/200] Batch [387/391] Loss: 0.1979\n",
            "Epoch [26/200] Batch [388/391] Loss: 0.2166\n",
            "Epoch [26/200] Batch [389/391] Loss: 0.1243\n",
            "Epoch [26/200] Batch [390/391] Loss: 0.1368\n",
            "Epoch [26/200] Batch [391/391] Loss: 0.2334\n",
            "Epoch [26/200] - Train Loss: 0.1728 - Test Loss: 1.5162 - Train Acc: 73.02% - Test Acc: 66.66%\n",
            "Epoch [27/200] Batch [1/391] Loss: 0.1096\n",
            "Epoch [27/200] Batch [2/391] Loss: 0.1462\n",
            "Epoch [27/200] Batch [3/391] Loss: 0.1028\n",
            "Epoch [27/200] Batch [4/391] Loss: 0.1589\n",
            "Epoch [27/200] Batch [5/391] Loss: 0.1312\n",
            "Epoch [27/200] Batch [6/391] Loss: 0.1090\n",
            "Epoch [27/200] Batch [7/391] Loss: 0.1439\n",
            "Epoch [27/200] Batch [8/391] Loss: 0.1372\n",
            "Epoch [27/200] Batch [9/391] Loss: 0.1263\n",
            "Epoch [27/200] Batch [10/391] Loss: 0.1289\n",
            "Epoch [27/200] Batch [11/391] Loss: 0.1070\n",
            "Epoch [27/200] Batch [12/391] Loss: 0.1549\n",
            "Epoch [27/200] Batch [13/391] Loss: 0.0908\n",
            "Epoch [27/200] Batch [14/391] Loss: 0.1036\n",
            "Epoch [27/200] Batch [15/391] Loss: 0.1441\n",
            "Epoch [27/200] Batch [16/391] Loss: 0.1852\n",
            "Epoch [27/200] Batch [17/391] Loss: 0.1147\n",
            "Epoch [27/200] Batch [18/391] Loss: 0.0839\n",
            "Epoch [27/200] Batch [19/391] Loss: 0.3264\n",
            "Epoch [27/200] Batch [20/391] Loss: 0.1139\n",
            "Epoch [27/200] Batch [21/391] Loss: 0.1498\n",
            "Epoch [27/200] Batch [22/391] Loss: 0.0786\n",
            "Epoch [27/200] Batch [23/391] Loss: 0.1536\n",
            "Epoch [27/200] Batch [24/391] Loss: 0.1292\n",
            "Epoch [27/200] Batch [25/391] Loss: 0.1386\n",
            "Epoch [27/200] Batch [26/391] Loss: 0.1243\n",
            "Epoch [27/200] Batch [27/391] Loss: 0.1107\n",
            "Epoch [27/200] Batch [28/391] Loss: 0.0923\n",
            "Epoch [27/200] Batch [29/391] Loss: 0.2010\n",
            "Epoch [27/200] Batch [30/391] Loss: 0.2088\n",
            "Epoch [27/200] Batch [31/391] Loss: 0.1626\n",
            "Epoch [27/200] Batch [32/391] Loss: 0.1921\n",
            "Epoch [27/200] Batch [33/391] Loss: 0.1480\n",
            "Epoch [27/200] Batch [34/391] Loss: 0.1107\n",
            "Epoch [27/200] Batch [35/391] Loss: 0.1307\n",
            "Epoch [27/200] Batch [36/391] Loss: 0.0504\n",
            "Epoch [27/200] Batch [37/391] Loss: 0.0910\n",
            "Epoch [27/200] Batch [38/391] Loss: 0.1392\n",
            "Epoch [27/200] Batch [39/391] Loss: 0.0563\n",
            "Epoch [27/200] Batch [40/391] Loss: 0.1008\n",
            "Epoch [27/200] Batch [41/391] Loss: 0.1280\n",
            "Epoch [27/200] Batch [42/391] Loss: 0.1258\n",
            "Epoch [27/200] Batch [43/391] Loss: 0.0690\n",
            "Epoch [27/200] Batch [44/391] Loss: 0.1246\n",
            "Epoch [27/200] Batch [45/391] Loss: 0.1952\n",
            "Epoch [27/200] Batch [46/391] Loss: 0.1687\n",
            "Epoch [27/200] Batch [47/391] Loss: 0.1138\n",
            "Epoch [27/200] Batch [48/391] Loss: 0.0761\n",
            "Epoch [27/200] Batch [49/391] Loss: 0.1140\n",
            "Epoch [27/200] Batch [50/391] Loss: 0.0994\n",
            "Epoch [27/200] Batch [51/391] Loss: 0.2265\n",
            "Epoch [27/200] Batch [52/391] Loss: 0.1362\n",
            "Epoch [27/200] Batch [53/391] Loss: 0.1034\n",
            "Epoch [27/200] Batch [54/391] Loss: 0.1806\n",
            "Epoch [27/200] Batch [55/391] Loss: 0.1737\n",
            "Epoch [27/200] Batch [56/391] Loss: 0.1631\n",
            "Epoch [27/200] Batch [57/391] Loss: 0.0884\n",
            "Epoch [27/200] Batch [58/391] Loss: 0.0865\n",
            "Epoch [27/200] Batch [59/391] Loss: 0.1043\n",
            "Epoch [27/200] Batch [60/391] Loss: 0.2845\n",
            "Epoch [27/200] Batch [61/391] Loss: 0.0876\n",
            "Epoch [27/200] Batch [62/391] Loss: 0.1801\n",
            "Epoch [27/200] Batch [63/391] Loss: 0.1079\n",
            "Epoch [27/200] Batch [64/391] Loss: 0.1505\n",
            "Epoch [27/200] Batch [65/391] Loss: 0.1569\n",
            "Epoch [27/200] Batch [66/391] Loss: 0.1249\n",
            "Epoch [27/200] Batch [67/391] Loss: 0.0994\n",
            "Epoch [27/200] Batch [68/391] Loss: 0.0585\n",
            "Epoch [27/200] Batch [69/391] Loss: 0.1040\n",
            "Epoch [27/200] Batch [70/391] Loss: 0.1619\n",
            "Epoch [27/200] Batch [71/391] Loss: 0.1650\n",
            "Epoch [27/200] Batch [72/391] Loss: 0.1358\n",
            "Epoch [27/200] Batch [73/391] Loss: 0.0986\n",
            "Epoch [27/200] Batch [74/391] Loss: 0.1139\n",
            "Epoch [27/200] Batch [75/391] Loss: 0.1207\n",
            "Epoch [27/200] Batch [76/391] Loss: 0.0934\n",
            "Epoch [27/200] Batch [77/391] Loss: 0.1013\n",
            "Epoch [27/200] Batch [78/391] Loss: 0.0790\n",
            "Epoch [27/200] Batch [79/391] Loss: 0.1091\n",
            "Epoch [27/200] Batch [80/391] Loss: 0.1596\n",
            "Epoch [27/200] Batch [81/391] Loss: 0.1454\n",
            "Epoch [27/200] Batch [82/391] Loss: 0.1031\n",
            "Epoch [27/200] Batch [83/391] Loss: 0.0918\n",
            "Epoch [27/200] Batch [84/391] Loss: 0.1936\n",
            "Epoch [27/200] Batch [85/391] Loss: 0.1691\n",
            "Epoch [27/200] Batch [86/391] Loss: 0.0692\n",
            "Epoch [27/200] Batch [87/391] Loss: 0.0714\n",
            "Epoch [27/200] Batch [88/391] Loss: 0.0847\n",
            "Epoch [27/200] Batch [89/391] Loss: 0.0752\n",
            "Epoch [27/200] Batch [90/391] Loss: 0.1079\n",
            "Epoch [27/200] Batch [91/391] Loss: 0.1475\n",
            "Epoch [27/200] Batch [92/391] Loss: 0.1169\n",
            "Epoch [27/200] Batch [93/391] Loss: 0.1739\n",
            "Epoch [27/200] Batch [94/391] Loss: 0.0828\n",
            "Epoch [27/200] Batch [95/391] Loss: 0.1450\n",
            "Epoch [27/200] Batch [96/391] Loss: 0.1360\n",
            "Epoch [27/200] Batch [97/391] Loss: 0.0853\n",
            "Epoch [27/200] Batch [98/391] Loss: 0.1376\n",
            "Epoch [27/200] Batch [99/391] Loss: 0.1128\n",
            "Epoch [27/200] Batch [100/391] Loss: 0.2448\n",
            "Epoch [27/200] Batch [101/391] Loss: 0.1430\n",
            "Epoch [27/200] Batch [102/391] Loss: 0.1623\n",
            "Epoch [27/200] Batch [103/391] Loss: 0.1072\n",
            "Epoch [27/200] Batch [104/391] Loss: 0.0999\n",
            "Epoch [27/200] Batch [105/391] Loss: 0.0648\n",
            "Epoch [27/200] Batch [106/391] Loss: 0.0798\n",
            "Epoch [27/200] Batch [107/391] Loss: 0.1338\n",
            "Epoch [27/200] Batch [108/391] Loss: 0.1609\n",
            "Epoch [27/200] Batch [109/391] Loss: 0.1364\n",
            "Epoch [27/200] Batch [110/391] Loss: 0.0857\n",
            "Epoch [27/200] Batch [111/391] Loss: 0.1769\n",
            "Epoch [27/200] Batch [112/391] Loss: 0.1091\n",
            "Epoch [27/200] Batch [113/391] Loss: 0.1233\n",
            "Epoch [27/200] Batch [114/391] Loss: 0.1927\n",
            "Epoch [27/200] Batch [115/391] Loss: 0.1095\n",
            "Epoch [27/200] Batch [116/391] Loss: 0.2076\n",
            "Epoch [27/200] Batch [117/391] Loss: 0.1849\n",
            "Epoch [27/200] Batch [118/391] Loss: 0.1681\n",
            "Epoch [27/200] Batch [119/391] Loss: 0.0795\n",
            "Epoch [27/200] Batch [120/391] Loss: 0.0897\n",
            "Epoch [27/200] Batch [121/391] Loss: 0.1549\n",
            "Epoch [27/200] Batch [122/391] Loss: 0.0734\n",
            "Epoch [27/200] Batch [123/391] Loss: 0.1340\n",
            "Epoch [27/200] Batch [124/391] Loss: 0.1207\n",
            "Epoch [27/200] Batch [125/391] Loss: 0.1145\n",
            "Epoch [27/200] Batch [126/391] Loss: 0.1124\n",
            "Epoch [27/200] Batch [127/391] Loss: 0.2098\n",
            "Epoch [27/200] Batch [128/391] Loss: 0.0936\n",
            "Epoch [27/200] Batch [129/391] Loss: 0.0970\n",
            "Epoch [27/200] Batch [130/391] Loss: 0.1914\n",
            "Epoch [27/200] Batch [131/391] Loss: 0.1258\n",
            "Epoch [27/200] Batch [132/391] Loss: 0.1847\n",
            "Epoch [27/200] Batch [133/391] Loss: 0.1300\n",
            "Epoch [27/200] Batch [134/391] Loss: 0.1266\n",
            "Epoch [27/200] Batch [135/391] Loss: 0.1163\n",
            "Epoch [27/200] Batch [136/391] Loss: 0.1968\n",
            "Epoch [27/200] Batch [137/391] Loss: 0.1173\n",
            "Epoch [27/200] Batch [138/391] Loss: 0.0754\n",
            "Epoch [27/200] Batch [139/391] Loss: 0.1062\n",
            "Epoch [27/200] Batch [140/391] Loss: 0.1344\n",
            "Epoch [27/200] Batch [141/391] Loss: 0.1993\n",
            "Epoch [27/200] Batch [142/391] Loss: 0.1682\n",
            "Epoch [27/200] Batch [143/391] Loss: 0.0796\n",
            "Epoch [27/200] Batch [144/391] Loss: 0.1432\n",
            "Epoch [27/200] Batch [145/391] Loss: 0.1431\n",
            "Epoch [27/200] Batch [146/391] Loss: 0.1618\n",
            "Epoch [27/200] Batch [147/391] Loss: 0.1173\n",
            "Epoch [27/200] Batch [148/391] Loss: 0.0843\n",
            "Epoch [27/200] Batch [149/391] Loss: 0.1190\n",
            "Epoch [27/200] Batch [150/391] Loss: 0.1410\n",
            "Epoch [27/200] Batch [151/391] Loss: 0.2211\n",
            "Epoch [27/200] Batch [152/391] Loss: 0.1172\n",
            "Epoch [27/200] Batch [153/391] Loss: 0.1306\n",
            "Epoch [27/200] Batch [154/391] Loss: 0.1542\n",
            "Epoch [27/200] Batch [155/391] Loss: 0.1379\n",
            "Epoch [27/200] Batch [156/391] Loss: 0.2119\n",
            "Epoch [27/200] Batch [157/391] Loss: 0.1412\n",
            "Epoch [27/200] Batch [158/391] Loss: 0.0703\n",
            "Epoch [27/200] Batch [159/391] Loss: 0.2224\n",
            "Epoch [27/200] Batch [160/391] Loss: 0.1048\n",
            "Epoch [27/200] Batch [161/391] Loss: 0.1524\n",
            "Epoch [27/200] Batch [162/391] Loss: 0.1641\n",
            "Epoch [27/200] Batch [163/391] Loss: 0.1300\n",
            "Epoch [27/200] Batch [164/391] Loss: 0.1477\n",
            "Epoch [27/200] Batch [165/391] Loss: 0.1740\n",
            "Epoch [27/200] Batch [166/391] Loss: 0.1245\n",
            "Epoch [27/200] Batch [167/391] Loss: 0.1271\n",
            "Epoch [27/200] Batch [168/391] Loss: 0.1811\n",
            "Epoch [27/200] Batch [169/391] Loss: 0.1408\n",
            "Epoch [27/200] Batch [170/391] Loss: 0.0776\n",
            "Epoch [27/200] Batch [171/391] Loss: 0.0910\n",
            "Epoch [27/200] Batch [172/391] Loss: 0.1610\n",
            "Epoch [27/200] Batch [173/391] Loss: 0.1378\n",
            "Epoch [27/200] Batch [174/391] Loss: 0.1217\n",
            "Epoch [27/200] Batch [175/391] Loss: 0.0794\n",
            "Epoch [27/200] Batch [176/391] Loss: 0.1588\n",
            "Epoch [27/200] Batch [177/391] Loss: 0.1145\n",
            "Epoch [27/200] Batch [178/391] Loss: 0.1089\n",
            "Epoch [27/200] Batch [179/391] Loss: 0.1541\n",
            "Epoch [27/200] Batch [180/391] Loss: 0.1075\n",
            "Epoch [27/200] Batch [181/391] Loss: 0.1121\n",
            "Epoch [27/200] Batch [182/391] Loss: 0.1859\n",
            "Epoch [27/200] Batch [183/391] Loss: 0.0835\n",
            "Epoch [27/200] Batch [184/391] Loss: 0.1185\n",
            "Epoch [27/200] Batch [185/391] Loss: 0.1447\n",
            "Epoch [27/200] Batch [186/391] Loss: 0.1750\n",
            "Epoch [27/200] Batch [187/391] Loss: 0.2586\n",
            "Epoch [27/200] Batch [188/391] Loss: 0.1808\n",
            "Epoch [27/200] Batch [189/391] Loss: 0.0392\n",
            "Epoch [27/200] Batch [190/391] Loss: 0.1315\n",
            "Epoch [27/200] Batch [191/391] Loss: 0.1782\n",
            "Epoch [27/200] Batch [192/391] Loss: 0.0755\n",
            "Epoch [27/200] Batch [193/391] Loss: 0.1486\n",
            "Epoch [27/200] Batch [194/391] Loss: 0.0842\n",
            "Epoch [27/200] Batch [195/391] Loss: 0.1826\n",
            "Epoch [27/200] Batch [196/391] Loss: 0.1481\n",
            "Epoch [27/200] Batch [197/391] Loss: 0.0915\n",
            "Epoch [27/200] Batch [198/391] Loss: 0.1206\n",
            "Epoch [27/200] Batch [199/391] Loss: 0.1755\n",
            "Epoch [27/200] Batch [200/391] Loss: 0.1703\n",
            "Epoch [27/200] Batch [201/391] Loss: 0.2415\n",
            "Epoch [27/200] Batch [202/391] Loss: 0.1299\n",
            "Epoch [27/200] Batch [203/391] Loss: 0.1266\n",
            "Epoch [27/200] Batch [204/391] Loss: 0.1484\n",
            "Epoch [27/200] Batch [205/391] Loss: 0.1052\n",
            "Epoch [27/200] Batch [206/391] Loss: 0.2420\n",
            "Epoch [27/200] Batch [207/391] Loss: 0.1662\n",
            "Epoch [27/200] Batch [208/391] Loss: 0.1788\n",
            "Epoch [27/200] Batch [209/391] Loss: 0.1480\n",
            "Epoch [27/200] Batch [210/391] Loss: 0.1252\n",
            "Epoch [27/200] Batch [211/391] Loss: 0.2199\n",
            "Epoch [27/200] Batch [212/391] Loss: 0.1855\n",
            "Epoch [27/200] Batch [213/391] Loss: 0.1065\n",
            "Epoch [27/200] Batch [214/391] Loss: 0.1991\n",
            "Epoch [27/200] Batch [215/391] Loss: 0.1079\n",
            "Epoch [27/200] Batch [216/391] Loss: 0.1856\n",
            "Epoch [27/200] Batch [217/391] Loss: 0.1685\n",
            "Epoch [27/200] Batch [218/391] Loss: 0.1047\n",
            "Epoch [27/200] Batch [219/391] Loss: 0.1823\n",
            "Epoch [27/200] Batch [220/391] Loss: 0.2853\n",
            "Epoch [27/200] Batch [221/391] Loss: 0.1573\n",
            "Epoch [27/200] Batch [222/391] Loss: 0.1637\n",
            "Epoch [27/200] Batch [223/391] Loss: 0.1037\n",
            "Epoch [27/200] Batch [224/391] Loss: 0.1709\n",
            "Epoch [27/200] Batch [225/391] Loss: 0.2005\n",
            "Epoch [27/200] Batch [226/391] Loss: 0.1468\n",
            "Epoch [27/200] Batch [227/391] Loss: 0.0761\n",
            "Epoch [27/200] Batch [228/391] Loss: 0.1131\n",
            "Epoch [27/200] Batch [229/391] Loss: 0.1326\n",
            "Epoch [27/200] Batch [230/391] Loss: 0.2427\n",
            "Epoch [27/200] Batch [231/391] Loss: 0.1640\n",
            "Epoch [27/200] Batch [232/391] Loss: 0.1469\n",
            "Epoch [27/200] Batch [233/391] Loss: 0.1452\n",
            "Epoch [27/200] Batch [234/391] Loss: 0.1291\n",
            "Epoch [27/200] Batch [235/391] Loss: 0.1581\n",
            "Epoch [27/200] Batch [236/391] Loss: 0.1708\n",
            "Epoch [27/200] Batch [237/391] Loss: 0.1784\n",
            "Epoch [27/200] Batch [238/391] Loss: 0.0943\n",
            "Epoch [27/200] Batch [239/391] Loss: 0.0671\n",
            "Epoch [27/200] Batch [240/391] Loss: 0.2385\n",
            "Epoch [27/200] Batch [241/391] Loss: 0.1855\n",
            "Epoch [27/200] Batch [242/391] Loss: 0.1775\n",
            "Epoch [27/200] Batch [243/391] Loss: 0.1591\n",
            "Epoch [27/200] Batch [244/391] Loss: 0.1497\n",
            "Epoch [27/200] Batch [245/391] Loss: 0.1945\n",
            "Epoch [27/200] Batch [246/391] Loss: 0.2203\n",
            "Epoch [27/200] Batch [247/391] Loss: 0.1546\n",
            "Epoch [27/200] Batch [248/391] Loss: 0.1925\n",
            "Epoch [27/200] Batch [249/391] Loss: 0.1639\n",
            "Epoch [27/200] Batch [250/391] Loss: 0.1891\n",
            "Epoch [27/200] Batch [251/391] Loss: 0.0737\n",
            "Epoch [27/200] Batch [252/391] Loss: 0.2028\n",
            "Epoch [27/200] Batch [253/391] Loss: 0.2148\n",
            "Epoch [27/200] Batch [254/391] Loss: 0.1702\n",
            "Epoch [27/200] Batch [255/391] Loss: 0.1655\n",
            "Epoch [27/200] Batch [256/391] Loss: 0.1476\n",
            "Epoch [27/200] Batch [257/391] Loss: 0.1142\n",
            "Epoch [27/200] Batch [258/391] Loss: 0.1789\n",
            "Epoch [27/200] Batch [259/391] Loss: 0.2228\n",
            "Epoch [27/200] Batch [260/391] Loss: 0.1675\n",
            "Epoch [27/200] Batch [261/391] Loss: 0.1228\n",
            "Epoch [27/200] Batch [262/391] Loss: 0.1562\n",
            "Epoch [27/200] Batch [263/391] Loss: 0.1548\n",
            "Epoch [27/200] Batch [264/391] Loss: 0.2435\n",
            "Epoch [27/200] Batch [265/391] Loss: 0.2557\n",
            "Epoch [27/200] Batch [266/391] Loss: 0.2047\n",
            "Epoch [27/200] Batch [267/391] Loss: 0.1003\n",
            "Epoch [27/200] Batch [268/391] Loss: 0.1750\n",
            "Epoch [27/200] Batch [269/391] Loss: 0.2325\n",
            "Epoch [27/200] Batch [270/391] Loss: 0.2068\n",
            "Epoch [27/200] Batch [271/391] Loss: 0.1048\n",
            "Epoch [27/200] Batch [272/391] Loss: 0.1092\n",
            "Epoch [27/200] Batch [273/391] Loss: 0.1605\n",
            "Epoch [27/200] Batch [274/391] Loss: 0.1146\n",
            "Epoch [27/200] Batch [275/391] Loss: 0.1424\n",
            "Epoch [27/200] Batch [276/391] Loss: 0.1437\n",
            "Epoch [27/200] Batch [277/391] Loss: 0.1033\n",
            "Epoch [27/200] Batch [278/391] Loss: 0.1501\n",
            "Epoch [27/200] Batch [279/391] Loss: 0.2280\n",
            "Epoch [27/200] Batch [280/391] Loss: 0.1508\n",
            "Epoch [27/200] Batch [281/391] Loss: 0.1354\n",
            "Epoch [27/200] Batch [282/391] Loss: 0.1710\n",
            "Epoch [27/200] Batch [283/391] Loss: 0.1509\n",
            "Epoch [27/200] Batch [284/391] Loss: 0.1139\n",
            "Epoch [27/200] Batch [285/391] Loss: 0.2717\n",
            "Epoch [27/200] Batch [286/391] Loss: 0.2291\n",
            "Epoch [27/200] Batch [287/391] Loss: 0.1450\n",
            "Epoch [27/200] Batch [288/391] Loss: 0.1325\n",
            "Epoch [27/200] Batch [289/391] Loss: 0.0990\n",
            "Epoch [27/200] Batch [290/391] Loss: 0.1902\n",
            "Epoch [27/200] Batch [291/391] Loss: 0.1723\n",
            "Epoch [27/200] Batch [292/391] Loss: 0.0600\n",
            "Epoch [27/200] Batch [293/391] Loss: 0.2874\n",
            "Epoch [27/200] Batch [294/391] Loss: 0.1849\n",
            "Epoch [27/200] Batch [295/391] Loss: 0.1567\n",
            "Epoch [27/200] Batch [296/391] Loss: 0.1500\n",
            "Epoch [27/200] Batch [297/391] Loss: 0.1613\n",
            "Epoch [27/200] Batch [298/391] Loss: 0.1456\n",
            "Epoch [27/200] Batch [299/391] Loss: 0.2979\n",
            "Epoch [27/200] Batch [300/391] Loss: 0.1815\n",
            "Epoch [27/200] Batch [301/391] Loss: 0.1743\n",
            "Epoch [27/200] Batch [302/391] Loss: 0.1461\n",
            "Epoch [27/200] Batch [303/391] Loss: 0.1755\n",
            "Epoch [27/200] Batch [304/391] Loss: 0.2472\n",
            "Epoch [27/200] Batch [305/391] Loss: 0.0963\n",
            "Epoch [27/200] Batch [306/391] Loss: 0.1679\n",
            "Epoch [27/200] Batch [307/391] Loss: 0.1633\n",
            "Epoch [27/200] Batch [308/391] Loss: 0.1577\n",
            "Epoch [27/200] Batch [309/391] Loss: 0.2603\n",
            "Epoch [27/200] Batch [310/391] Loss: 0.1659\n",
            "Epoch [27/200] Batch [311/391] Loss: 0.2150\n",
            "Epoch [27/200] Batch [312/391] Loss: 0.1893\n",
            "Epoch [27/200] Batch [313/391] Loss: 0.1778\n",
            "Epoch [27/200] Batch [314/391] Loss: 0.1722\n",
            "Epoch [27/200] Batch [315/391] Loss: 0.0902\n",
            "Epoch [27/200] Batch [316/391] Loss: 0.2140\n",
            "Epoch [27/200] Batch [317/391] Loss: 0.1111\n",
            "Epoch [27/200] Batch [318/391] Loss: 0.1994\n",
            "Epoch [27/200] Batch [319/391] Loss: 0.1813\n",
            "Epoch [27/200] Batch [320/391] Loss: 0.1656\n",
            "Epoch [27/200] Batch [321/391] Loss: 0.1207\n",
            "Epoch [27/200] Batch [322/391] Loss: 0.1311\n",
            "Epoch [27/200] Batch [323/391] Loss: 0.1363\n",
            "Epoch [27/200] Batch [324/391] Loss: 0.2814\n",
            "Epoch [27/200] Batch [325/391] Loss: 0.1842\n",
            "Epoch [27/200] Batch [326/391] Loss: 0.2322\n",
            "Epoch [27/200] Batch [327/391] Loss: 0.1151\n",
            "Epoch [27/200] Batch [328/391] Loss: 0.1339\n",
            "Epoch [27/200] Batch [329/391] Loss: 0.2408\n",
            "Epoch [27/200] Batch [330/391] Loss: 0.1454\n",
            "Epoch [27/200] Batch [331/391] Loss: 0.1536\n",
            "Epoch [27/200] Batch [332/391] Loss: 0.2193\n",
            "Epoch [27/200] Batch [333/391] Loss: 0.2412\n",
            "Epoch [27/200] Batch [334/391] Loss: 0.1288\n",
            "Epoch [27/200] Batch [335/391] Loss: 0.2133\n",
            "Epoch [27/200] Batch [336/391] Loss: 0.1372\n",
            "Epoch [27/200] Batch [337/391] Loss: 0.1562\n",
            "Epoch [27/200] Batch [338/391] Loss: 0.1434\n",
            "Epoch [27/200] Batch [339/391] Loss: 0.1650\n",
            "Epoch [27/200] Batch [340/391] Loss: 0.1704\n",
            "Epoch [27/200] Batch [341/391] Loss: 0.1818\n",
            "Epoch [27/200] Batch [342/391] Loss: 0.1005\n",
            "Epoch [27/200] Batch [343/391] Loss: 0.2709\n",
            "Epoch [27/200] Batch [344/391] Loss: 0.3607\n",
            "Epoch [27/200] Batch [345/391] Loss: 0.3900\n",
            "Epoch [27/200] Batch [346/391] Loss: 0.1895\n",
            "Epoch [27/200] Batch [347/391] Loss: 0.1372\n",
            "Epoch [27/200] Batch [348/391] Loss: 0.1183\n",
            "Epoch [27/200] Batch [349/391] Loss: 0.2118\n",
            "Epoch [27/200] Batch [350/391] Loss: 0.1783\n",
            "Epoch [27/200] Batch [351/391] Loss: 0.2669\n",
            "Epoch [27/200] Batch [352/391] Loss: 0.1083\n",
            "Epoch [27/200] Batch [353/391] Loss: 0.3203\n",
            "Epoch [27/200] Batch [354/391] Loss: 0.1347\n",
            "Epoch [27/200] Batch [355/391] Loss: 0.3069\n",
            "Epoch [27/200] Batch [356/391] Loss: 0.2203\n",
            "Epoch [27/200] Batch [357/391] Loss: 0.1542\n",
            "Epoch [27/200] Batch [358/391] Loss: 0.1986\n",
            "Epoch [27/200] Batch [359/391] Loss: 0.2087\n",
            "Epoch [27/200] Batch [360/391] Loss: 0.1764\n",
            "Epoch [27/200] Batch [361/391] Loss: 0.1437\n",
            "Epoch [27/200] Batch [362/391] Loss: 0.2351\n",
            "Epoch [27/200] Batch [363/391] Loss: 0.1359\n",
            "Epoch [27/200] Batch [364/391] Loss: 0.2005\n",
            "Epoch [27/200] Batch [365/391] Loss: 0.1152\n",
            "Epoch [27/200] Batch [366/391] Loss: 0.3320\n",
            "Epoch [27/200] Batch [367/391] Loss: 0.1623\n",
            "Epoch [27/200] Batch [368/391] Loss: 0.1766\n",
            "Epoch [27/200] Batch [369/391] Loss: 0.1969\n",
            "Epoch [27/200] Batch [370/391] Loss: 0.2887\n",
            "Epoch [27/200] Batch [371/391] Loss: 0.2165\n",
            "Epoch [27/200] Batch [372/391] Loss: 0.2416\n",
            "Epoch [27/200] Batch [373/391] Loss: 0.1193\n",
            "Epoch [27/200] Batch [374/391] Loss: 0.1682\n",
            "Epoch [27/200] Batch [375/391] Loss: 0.1756\n",
            "Epoch [27/200] Batch [376/391] Loss: 0.1456\n",
            "Epoch [27/200] Batch [377/391] Loss: 0.1515\n",
            "Epoch [27/200] Batch [378/391] Loss: 0.1882\n",
            "Epoch [27/200] Batch [379/391] Loss: 0.1432\n",
            "Epoch [27/200] Batch [380/391] Loss: 0.2003\n",
            "Epoch [27/200] Batch [381/391] Loss: 0.1304\n",
            "Epoch [27/200] Batch [382/391] Loss: 0.2295\n",
            "Epoch [27/200] Batch [383/391] Loss: 0.2468\n",
            "Epoch [27/200] Batch [384/391] Loss: 0.2400\n",
            "Epoch [27/200] Batch [385/391] Loss: 0.1869\n",
            "Epoch [27/200] Batch [386/391] Loss: 0.2286\n",
            "Epoch [27/200] Batch [387/391] Loss: 0.2521\n",
            "Epoch [27/200] Batch [388/391] Loss: 0.2721\n",
            "Epoch [27/200] Batch [389/391] Loss: 0.2783\n",
            "Epoch [27/200] Batch [390/391] Loss: 0.0839\n",
            "Epoch [27/200] Batch [391/391] Loss: 0.4793\n",
            "Epoch [27/200] - Train Loss: 0.1548 - Test Loss: 1.3991 - Train Acc: 76.16% - Test Acc: 70.74%\n",
            "Epoch [28/200] Batch [1/391] Loss: 0.1466\n",
            "Epoch [28/200] Batch [2/391] Loss: 0.1117\n",
            "Epoch [28/200] Batch [3/391] Loss: 0.1179\n",
            "Epoch [28/200] Batch [4/391] Loss: 0.1487\n",
            "Epoch [28/200] Batch [5/391] Loss: 0.1813\n",
            "Epoch [28/200] Batch [6/391] Loss: 0.1815\n",
            "Epoch [28/200] Batch [7/391] Loss: 0.1759\n",
            "Epoch [28/200] Batch [8/391] Loss: 0.2227\n",
            "Epoch [28/200] Batch [9/391] Loss: 0.2112\n",
            "Epoch [28/200] Batch [10/391] Loss: 0.0986\n",
            "Epoch [28/200] Batch [11/391] Loss: 0.0678\n",
            "Epoch [28/200] Batch [12/391] Loss: 0.1509\n",
            "Epoch [28/200] Batch [13/391] Loss: 0.1819\n",
            "Epoch [28/200] Batch [14/391] Loss: 0.1307\n",
            "Epoch [28/200] Batch [15/391] Loss: 0.1486\n",
            "Epoch [28/200] Batch [16/391] Loss: 0.1348\n",
            "Epoch [28/200] Batch [17/391] Loss: 0.0930\n",
            "Epoch [28/200] Batch [18/391] Loss: 0.1446\n",
            "Epoch [28/200] Batch [19/391] Loss: 0.1335\n",
            "Epoch [28/200] Batch [20/391] Loss: 0.1262\n",
            "Epoch [28/200] Batch [21/391] Loss: 0.1420\n",
            "Epoch [28/200] Batch [22/391] Loss: 0.1153\n",
            "Epoch [28/200] Batch [23/391] Loss: 0.1201\n",
            "Epoch [28/200] Batch [24/391] Loss: 0.1133\n",
            "Epoch [28/200] Batch [25/391] Loss: 0.1446\n",
            "Epoch [28/200] Batch [26/391] Loss: 0.1286\n",
            "Epoch [28/200] Batch [27/391] Loss: 0.1249\n",
            "Epoch [28/200] Batch [28/391] Loss: 0.1956\n",
            "Epoch [28/200] Batch [29/391] Loss: 0.1762\n",
            "Epoch [28/200] Batch [30/391] Loss: 0.1087\n",
            "Epoch [28/200] Batch [31/391] Loss: 0.1092\n",
            "Epoch [28/200] Batch [32/391] Loss: 0.1032\n",
            "Epoch [28/200] Batch [33/391] Loss: 0.1692\n",
            "Epoch [28/200] Batch [34/391] Loss: 0.1496\n",
            "Epoch [28/200] Batch [35/391] Loss: 0.1145\n",
            "Epoch [28/200] Batch [36/391] Loss: 0.0785\n",
            "Epoch [28/200] Batch [37/391] Loss: 0.2118\n",
            "Epoch [28/200] Batch [38/391] Loss: 0.1127\n",
            "Epoch [28/200] Batch [39/391] Loss: 0.1961\n",
            "Epoch [28/200] Batch [40/391] Loss: 0.1385\n",
            "Epoch [28/200] Batch [41/391] Loss: 0.2004\n",
            "Epoch [28/200] Batch [42/391] Loss: 0.1892\n",
            "Epoch [28/200] Batch [43/391] Loss: 0.1367\n",
            "Epoch [28/200] Batch [44/391] Loss: 0.2162\n",
            "Epoch [28/200] Batch [45/391] Loss: 0.0651\n",
            "Epoch [28/200] Batch [46/391] Loss: 0.0803\n",
            "Epoch [28/200] Batch [47/391] Loss: 0.1307\n",
            "Epoch [28/200] Batch [48/391] Loss: 0.1132\n",
            "Epoch [28/200] Batch [49/391] Loss: 0.0960\n",
            "Epoch [28/200] Batch [50/391] Loss: 0.1261\n",
            "Epoch [28/200] Batch [51/391] Loss: 0.2124\n",
            "Epoch [28/200] Batch [52/391] Loss: 0.1468\n",
            "Epoch [28/200] Batch [53/391] Loss: 0.1316\n",
            "Epoch [28/200] Batch [54/391] Loss: 0.0898\n",
            "Epoch [28/200] Batch [55/391] Loss: 0.1246\n",
            "Epoch [28/200] Batch [56/391] Loss: 0.1315\n",
            "Epoch [28/200] Batch [57/391] Loss: 0.2529\n",
            "Epoch [28/200] Batch [58/391] Loss: 0.1741\n",
            "Epoch [28/200] Batch [59/391] Loss: 0.1611\n",
            "Epoch [28/200] Batch [60/391] Loss: 0.1389\n",
            "Epoch [28/200] Batch [61/391] Loss: 0.0783\n",
            "Epoch [28/200] Batch [62/391] Loss: 0.1097\n",
            "Epoch [28/200] Batch [63/391] Loss: 0.1159\n",
            "Epoch [28/200] Batch [64/391] Loss: 0.1150\n",
            "Epoch [28/200] Batch [65/391] Loss: 0.0470\n",
            "Epoch [28/200] Batch [66/391] Loss: 0.1363\n",
            "Epoch [28/200] Batch [67/391] Loss: 0.1129\n",
            "Epoch [28/200] Batch [68/391] Loss: 0.0589\n",
            "Epoch [28/200] Batch [69/391] Loss: 0.0946\n",
            "Epoch [28/200] Batch [70/391] Loss: 0.1333\n",
            "Epoch [28/200] Batch [71/391] Loss: 0.2010\n",
            "Epoch [28/200] Batch [72/391] Loss: 0.1510\n",
            "Epoch [28/200] Batch [73/391] Loss: 0.0821\n",
            "Epoch [28/200] Batch [74/391] Loss: 0.1486\n",
            "Epoch [28/200] Batch [75/391] Loss: 0.1026\n",
            "Epoch [28/200] Batch [76/391] Loss: 0.1228\n",
            "Epoch [28/200] Batch [77/391] Loss: 0.1259\n",
            "Epoch [28/200] Batch [78/391] Loss: 0.1054\n",
            "Epoch [28/200] Batch [79/391] Loss: 0.1668\n",
            "Epoch [28/200] Batch [80/391] Loss: 0.1861\n",
            "Epoch [28/200] Batch [81/391] Loss: 0.0950\n",
            "Epoch [28/200] Batch [82/391] Loss: 0.1861\n",
            "Epoch [28/200] Batch [83/391] Loss: 0.1507\n",
            "Epoch [28/200] Batch [84/391] Loss: 0.1263\n",
            "Epoch [28/200] Batch [85/391] Loss: 0.1844\n",
            "Epoch [28/200] Batch [86/391] Loss: 0.1173\n",
            "Epoch [28/200] Batch [87/391] Loss: 0.0839\n",
            "Epoch [28/200] Batch [88/391] Loss: 0.1550\n",
            "Epoch [28/200] Batch [89/391] Loss: 0.1156\n",
            "Epoch [28/200] Batch [90/391] Loss: 0.1026\n",
            "Epoch [28/200] Batch [91/391] Loss: 0.0987\n",
            "Epoch [28/200] Batch [92/391] Loss: 0.1396\n",
            "Epoch [28/200] Batch [93/391] Loss: 0.1624\n",
            "Epoch [28/200] Batch [94/391] Loss: 0.0878\n",
            "Epoch [28/200] Batch [95/391] Loss: 0.0941\n",
            "Epoch [28/200] Batch [96/391] Loss: 0.0748\n",
            "Epoch [28/200] Batch [97/391] Loss: 0.1777\n",
            "Epoch [28/200] Batch [98/391] Loss: 0.1263\n",
            "Epoch [28/200] Batch [99/391] Loss: 0.1952\n",
            "Epoch [28/200] Batch [100/391] Loss: 0.0571\n",
            "Epoch [28/200] Batch [101/391] Loss: 0.1921\n",
            "Epoch [28/200] Batch [102/391] Loss: 0.1655\n",
            "Epoch [28/200] Batch [103/391] Loss: 0.1466\n",
            "Epoch [28/200] Batch [104/391] Loss: 0.1569\n",
            "Epoch [28/200] Batch [105/391] Loss: 0.1882\n",
            "Epoch [28/200] Batch [106/391] Loss: 0.1406\n",
            "Epoch [28/200] Batch [107/391] Loss: 0.1463\n",
            "Epoch [28/200] Batch [108/391] Loss: 0.1695\n",
            "Epoch [28/200] Batch [109/391] Loss: 0.2296\n",
            "Epoch [28/200] Batch [110/391] Loss: 0.1574\n",
            "Epoch [28/200] Batch [111/391] Loss: 0.1522\n",
            "Epoch [28/200] Batch [112/391] Loss: 0.1235\n",
            "Epoch [28/200] Batch [113/391] Loss: 0.0646\n",
            "Epoch [28/200] Batch [114/391] Loss: 0.0978\n",
            "Epoch [28/200] Batch [115/391] Loss: 0.1566\n",
            "Epoch [28/200] Batch [116/391] Loss: 0.1004\n",
            "Epoch [28/200] Batch [117/391] Loss: 0.1034\n",
            "Epoch [28/200] Batch [118/391] Loss: 0.1753\n",
            "Epoch [28/200] Batch [119/391] Loss: 0.1409\n",
            "Epoch [28/200] Batch [120/391] Loss: 0.1961\n",
            "Epoch [28/200] Batch [121/391] Loss: 0.1635\n",
            "Epoch [28/200] Batch [122/391] Loss: 0.0621\n",
            "Epoch [28/200] Batch [123/391] Loss: 0.0860\n",
            "Epoch [28/200] Batch [124/391] Loss: 0.2054\n",
            "Epoch [28/200] Batch [125/391] Loss: 0.1970\n",
            "Epoch [28/200] Batch [126/391] Loss: 0.1193\n",
            "Epoch [28/200] Batch [127/391] Loss: 0.1599\n",
            "Epoch [28/200] Batch [128/391] Loss: 0.1384\n",
            "Epoch [28/200] Batch [129/391] Loss: 0.1804\n",
            "Epoch [28/200] Batch [130/391] Loss: 0.0765\n",
            "Epoch [28/200] Batch [131/391] Loss: 0.1154\n",
            "Epoch [28/200] Batch [132/391] Loss: 0.1205\n",
            "Epoch [28/200] Batch [133/391] Loss: 0.1128\n",
            "Epoch [28/200] Batch [134/391] Loss: 0.1649\n",
            "Epoch [28/200] Batch [135/391] Loss: 0.1637\n",
            "Epoch [28/200] Batch [136/391] Loss: 0.1837\n",
            "Epoch [28/200] Batch [137/391] Loss: 0.1601\n",
            "Epoch [28/200] Batch [138/391] Loss: 0.1584\n",
            "Epoch [28/200] Batch [139/391] Loss: 0.0986\n",
            "Epoch [28/200] Batch [140/391] Loss: 0.2021\n",
            "Epoch [28/200] Batch [141/391] Loss: 0.2123\n",
            "Epoch [28/200] Batch [142/391] Loss: 0.1266\n",
            "Epoch [28/200] Batch [143/391] Loss: 0.1905\n",
            "Epoch [28/200] Batch [144/391] Loss: 0.1104\n",
            "Epoch [28/200] Batch [145/391] Loss: 0.1389\n",
            "Epoch [28/200] Batch [146/391] Loss: 0.1006\n",
            "Epoch [28/200] Batch [147/391] Loss: 0.2270\n",
            "Epoch [28/200] Batch [148/391] Loss: 0.1357\n",
            "Epoch [28/200] Batch [149/391] Loss: 0.1182\n",
            "Epoch [28/200] Batch [150/391] Loss: 0.1429\n",
            "Epoch [28/200] Batch [151/391] Loss: 0.0832\n",
            "Epoch [28/200] Batch [152/391] Loss: 0.0846\n",
            "Epoch [28/200] Batch [153/391] Loss: 0.1154\n",
            "Epoch [28/200] Batch [154/391] Loss: 0.0717\n",
            "Epoch [28/200] Batch [155/391] Loss: 0.0909\n",
            "Epoch [28/200] Batch [156/391] Loss: 0.1255\n",
            "Epoch [28/200] Batch [157/391] Loss: 0.1958\n",
            "Epoch [28/200] Batch [158/391] Loss: 0.1588\n",
            "Epoch [28/200] Batch [159/391] Loss: 0.0923\n",
            "Epoch [28/200] Batch [160/391] Loss: 0.0791\n",
            "Epoch [28/200] Batch [161/391] Loss: 0.1177\n",
            "Epoch [28/200] Batch [162/391] Loss: 0.1045\n",
            "Epoch [28/200] Batch [163/391] Loss: 0.2342\n",
            "Epoch [28/200] Batch [164/391] Loss: 0.1504\n",
            "Epoch [28/200] Batch [165/391] Loss: 0.1545\n",
            "Epoch [28/200] Batch [166/391] Loss: 0.0880\n",
            "Epoch [28/200] Batch [167/391] Loss: 0.1930\n",
            "Epoch [28/200] Batch [168/391] Loss: 0.1594\n",
            "Epoch [28/200] Batch [169/391] Loss: 0.1338\n",
            "Epoch [28/200] Batch [170/391] Loss: 0.1283\n",
            "Epoch [28/200] Batch [171/391] Loss: 0.1835\n",
            "Epoch [28/200] Batch [172/391] Loss: 0.1087\n",
            "Epoch [28/200] Batch [173/391] Loss: 0.1390\n",
            "Epoch [28/200] Batch [174/391] Loss: 0.0878\n",
            "Epoch [28/200] Batch [175/391] Loss: 0.1547\n",
            "Epoch [28/200] Batch [176/391] Loss: 0.1865\n",
            "Epoch [28/200] Batch [177/391] Loss: 0.1826\n",
            "Epoch [28/200] Batch [178/391] Loss: 0.1231\n",
            "Epoch [28/200] Batch [179/391] Loss: 0.1221\n",
            "Epoch [28/200] Batch [180/391] Loss: 0.1768\n",
            "Epoch [28/200] Batch [181/391] Loss: 0.1567\n",
            "Epoch [28/200] Batch [182/391] Loss: 0.1635\n",
            "Epoch [28/200] Batch [183/391] Loss: 0.1418\n",
            "Epoch [28/200] Batch [184/391] Loss: 0.1527\n",
            "Epoch [28/200] Batch [185/391] Loss: 0.1357\n",
            "Epoch [28/200] Batch [186/391] Loss: 0.1612\n",
            "Epoch [28/200] Batch [187/391] Loss: 0.1985\n",
            "Epoch [28/200] Batch [188/391] Loss: 0.1186\n",
            "Epoch [28/200] Batch [189/391] Loss: 0.1161\n",
            "Epoch [28/200] Batch [190/391] Loss: 0.1182\n",
            "Epoch [28/200] Batch [191/391] Loss: 0.1693\n",
            "Epoch [28/200] Batch [192/391] Loss: 0.0839\n",
            "Epoch [28/200] Batch [193/391] Loss: 0.0834\n",
            "Epoch [28/200] Batch [194/391] Loss: 0.1108\n",
            "Epoch [28/200] Batch [195/391] Loss: 0.1224\n",
            "Epoch [28/200] Batch [196/391] Loss: 0.1187\n",
            "Epoch [28/200] Batch [197/391] Loss: 0.1456\n",
            "Epoch [28/200] Batch [198/391] Loss: 0.1965\n",
            "Epoch [28/200] Batch [199/391] Loss: 0.1593\n",
            "Epoch [28/200] Batch [200/391] Loss: 0.1248\n",
            "Epoch [28/200] Batch [201/391] Loss: 0.0924\n",
            "Epoch [28/200] Batch [202/391] Loss: 0.0738\n",
            "Epoch [28/200] Batch [203/391] Loss: 0.1577\n",
            "Epoch [28/200] Batch [204/391] Loss: 0.0761\n",
            "Epoch [28/200] Batch [205/391] Loss: 0.1589\n",
            "Epoch [28/200] Batch [206/391] Loss: 0.1289\n",
            "Epoch [28/200] Batch [207/391] Loss: 0.1101\n",
            "Epoch [28/200] Batch [208/391] Loss: 0.0950\n",
            "Epoch [28/200] Batch [209/391] Loss: 0.1081\n",
            "Epoch [28/200] Batch [210/391] Loss: 0.1726\n",
            "Epoch [28/200] Batch [211/391] Loss: 0.2635\n",
            "Epoch [28/200] Batch [212/391] Loss: 0.1749\n",
            "Epoch [28/200] Batch [213/391] Loss: 0.0940\n",
            "Epoch [28/200] Batch [214/391] Loss: 0.1254\n",
            "Epoch [28/200] Batch [215/391] Loss: 0.1361\n",
            "Epoch [28/200] Batch [216/391] Loss: 0.2639\n",
            "Epoch [28/200] Batch [217/391] Loss: 0.1173\n",
            "Epoch [28/200] Batch [218/391] Loss: 0.1724\n",
            "Epoch [28/200] Batch [219/391] Loss: 0.1519\n",
            "Epoch [28/200] Batch [220/391] Loss: 0.1349\n",
            "Epoch [28/200] Batch [221/391] Loss: 0.1669\n",
            "Epoch [28/200] Batch [222/391] Loss: 0.1599\n",
            "Epoch [28/200] Batch [223/391] Loss: 0.1543\n",
            "Epoch [28/200] Batch [224/391] Loss: 0.1368\n",
            "Epoch [28/200] Batch [225/391] Loss: 0.2577\n",
            "Epoch [28/200] Batch [226/391] Loss: 0.1200\n",
            "Epoch [28/200] Batch [227/391] Loss: 0.1304\n",
            "Epoch [28/200] Batch [228/391] Loss: 0.0796\n",
            "Epoch [28/200] Batch [229/391] Loss: 0.1496\n",
            "Epoch [28/200] Batch [230/391] Loss: 0.1196\n",
            "Epoch [28/200] Batch [231/391] Loss: 0.1062\n",
            "Epoch [28/200] Batch [232/391] Loss: 0.1731\n",
            "Epoch [28/200] Batch [233/391] Loss: 0.1657\n",
            "Epoch [28/200] Batch [234/391] Loss: 0.1651\n",
            "Epoch [28/200] Batch [235/391] Loss: 0.2036\n",
            "Epoch [28/200] Batch [236/391] Loss: 0.0514\n",
            "Epoch [28/200] Batch [237/391] Loss: 0.1656\n",
            "Epoch [28/200] Batch [238/391] Loss: 0.2316\n",
            "Epoch [28/200] Batch [239/391] Loss: 0.1039\n",
            "Epoch [28/200] Batch [240/391] Loss: 0.1141\n",
            "Epoch [28/200] Batch [241/391] Loss: 0.1152\n",
            "Epoch [28/200] Batch [242/391] Loss: 0.0869\n",
            "Epoch [28/200] Batch [243/391] Loss: 0.0821\n",
            "Epoch [28/200] Batch [244/391] Loss: 0.1424\n",
            "Epoch [28/200] Batch [245/391] Loss: 0.2017\n",
            "Epoch [28/200] Batch [246/391] Loss: 0.1514\n",
            "Epoch [28/200] Batch [247/391] Loss: 0.1087\n",
            "Epoch [28/200] Batch [248/391] Loss: 0.0872\n",
            "Epoch [28/200] Batch [249/391] Loss: 0.1313\n",
            "Epoch [28/200] Batch [250/391] Loss: 0.1511\n",
            "Epoch [28/200] Batch [251/391] Loss: 0.1009\n",
            "Epoch [28/200] Batch [252/391] Loss: 0.1577\n",
            "Epoch [28/200] Batch [253/391] Loss: 0.0677\n",
            "Epoch [28/200] Batch [254/391] Loss: 0.1326\n",
            "Epoch [28/200] Batch [255/391] Loss: 0.1064\n",
            "Epoch [28/200] Batch [256/391] Loss: 0.1698\n",
            "Epoch [28/200] Batch [257/391] Loss: 0.1673\n",
            "Epoch [28/200] Batch [258/391] Loss: 0.1763\n",
            "Epoch [28/200] Batch [259/391] Loss: 0.1601\n",
            "Epoch [28/200] Batch [260/391] Loss: 0.1307\n",
            "Epoch [28/200] Batch [261/391] Loss: 0.0931\n",
            "Epoch [28/200] Batch [262/391] Loss: 0.1833\n",
            "Epoch [28/200] Batch [263/391] Loss: 0.0810\n",
            "Epoch [28/200] Batch [264/391] Loss: 0.2124\n",
            "Epoch [28/200] Batch [265/391] Loss: 0.1382\n",
            "Epoch [28/200] Batch [266/391] Loss: 0.1396\n",
            "Epoch [28/200] Batch [267/391] Loss: 0.1280\n",
            "Epoch [28/200] Batch [268/391] Loss: 0.1831\n",
            "Epoch [28/200] Batch [269/391] Loss: 0.1080\n",
            "Epoch [28/200] Batch [270/391] Loss: 0.1296\n",
            "Epoch [28/200] Batch [271/391] Loss: 0.1403\n",
            "Epoch [28/200] Batch [272/391] Loss: 0.0984\n",
            "Epoch [28/200] Batch [273/391] Loss: 0.0973\n",
            "Epoch [28/200] Batch [274/391] Loss: 0.2312\n",
            "Epoch [28/200] Batch [275/391] Loss: 0.1675\n",
            "Epoch [28/200] Batch [276/391] Loss: 0.0992\n",
            "Epoch [28/200] Batch [277/391] Loss: 0.1407\n",
            "Epoch [28/200] Batch [278/391] Loss: 0.1662\n",
            "Epoch [28/200] Batch [279/391] Loss: 0.1833\n",
            "Epoch [28/200] Batch [280/391] Loss: 0.1579\n",
            "Epoch [28/200] Batch [281/391] Loss: 0.1174\n",
            "Epoch [28/200] Batch [282/391] Loss: 0.1297\n",
            "Epoch [28/200] Batch [283/391] Loss: 0.1617\n",
            "Epoch [28/200] Batch [284/391] Loss: 0.1568\n",
            "Epoch [28/200] Batch [285/391] Loss: 0.1358\n",
            "Epoch [28/200] Batch [286/391] Loss: 0.1939\n",
            "Epoch [28/200] Batch [287/391] Loss: 0.0842\n",
            "Epoch [28/200] Batch [288/391] Loss: 0.2301\n",
            "Epoch [28/200] Batch [289/391] Loss: 0.1931\n",
            "Epoch [28/200] Batch [290/391] Loss: 0.2029\n",
            "Epoch [28/200] Batch [291/391] Loss: 0.1820\n",
            "Epoch [28/200] Batch [292/391] Loss: 0.1456\n",
            "Epoch [28/200] Batch [293/391] Loss: 0.2453\n",
            "Epoch [28/200] Batch [294/391] Loss: 0.2797\n",
            "Epoch [28/200] Batch [295/391] Loss: 0.1484\n",
            "Epoch [28/200] Batch [296/391] Loss: 0.1374\n",
            "Epoch [28/200] Batch [297/391] Loss: 0.1582\n",
            "Epoch [28/200] Batch [298/391] Loss: 0.1549\n",
            "Epoch [28/200] Batch [299/391] Loss: 0.2179\n",
            "Epoch [28/200] Batch [300/391] Loss: 0.1837\n",
            "Epoch [28/200] Batch [301/391] Loss: 0.2428\n",
            "Epoch [28/200] Batch [302/391] Loss: 0.2102\n",
            "Epoch [28/200] Batch [303/391] Loss: 0.1506\n",
            "Epoch [28/200] Batch [304/391] Loss: 0.1536\n",
            "Epoch [28/200] Batch [305/391] Loss: 0.1252\n",
            "Epoch [28/200] Batch [306/391] Loss: 0.1497\n",
            "Epoch [28/200] Batch [307/391] Loss: 0.1056\n",
            "Epoch [28/200] Batch [308/391] Loss: 0.1821\n",
            "Epoch [28/200] Batch [309/391] Loss: 0.1581\n",
            "Epoch [28/200] Batch [310/391] Loss: 0.2285\n",
            "Epoch [28/200] Batch [311/391] Loss: 0.1379\n",
            "Epoch [28/200] Batch [312/391] Loss: 0.1904\n",
            "Epoch [28/200] Batch [313/391] Loss: 0.2376\n",
            "Epoch [28/200] Batch [314/391] Loss: 0.0695\n",
            "Epoch [28/200] Batch [315/391] Loss: 0.1339\n",
            "Epoch [28/200] Batch [316/391] Loss: 0.1967\n",
            "Epoch [28/200] Batch [317/391] Loss: 0.1560\n",
            "Epoch [28/200] Batch [318/391] Loss: 0.1524\n",
            "Epoch [28/200] Batch [319/391] Loss: 0.2678\n",
            "Epoch [28/200] Batch [320/391] Loss: 0.2043\n",
            "Epoch [28/200] Batch [321/391] Loss: 0.2615\n",
            "Epoch [28/200] Batch [322/391] Loss: 0.1939\n",
            "Epoch [28/200] Batch [323/391] Loss: 0.1213\n",
            "Epoch [28/200] Batch [324/391] Loss: 0.2818\n",
            "Epoch [28/200] Batch [325/391] Loss: 0.1915\n",
            "Epoch [28/200] Batch [326/391] Loss: 0.1499\n",
            "Epoch [28/200] Batch [327/391] Loss: 0.1099\n",
            "Epoch [28/200] Batch [328/391] Loss: 0.1599\n",
            "Epoch [28/200] Batch [329/391] Loss: 0.2307\n",
            "Epoch [28/200] Batch [330/391] Loss: 0.1454\n",
            "Epoch [28/200] Batch [331/391] Loss: 0.1612\n",
            "Epoch [28/200] Batch [332/391] Loss: 0.1910\n",
            "Epoch [28/200] Batch [333/391] Loss: 0.2449\n",
            "Epoch [28/200] Batch [334/391] Loss: 0.2339\n",
            "Epoch [28/200] Batch [335/391] Loss: 0.1353\n",
            "Epoch [28/200] Batch [336/391] Loss: 0.2847\n",
            "Epoch [28/200] Batch [337/391] Loss: 0.1227\n",
            "Epoch [28/200] Batch [338/391] Loss: 0.1795\n",
            "Epoch [28/200] Batch [339/391] Loss: 0.1456\n",
            "Epoch [28/200] Batch [340/391] Loss: 0.1704\n",
            "Epoch [28/200] Batch [341/391] Loss: 0.1711\n",
            "Epoch [28/200] Batch [342/391] Loss: 0.2599\n",
            "Epoch [28/200] Batch [343/391] Loss: 0.1627\n",
            "Epoch [28/200] Batch [344/391] Loss: 0.1909\n",
            "Epoch [28/200] Batch [345/391] Loss: 0.1249\n",
            "Epoch [28/200] Batch [346/391] Loss: 0.2999\n",
            "Epoch [28/200] Batch [347/391] Loss: 0.1547\n",
            "Epoch [28/200] Batch [348/391] Loss: 0.1357\n",
            "Epoch [28/200] Batch [349/391] Loss: 0.1855\n",
            "Epoch [28/200] Batch [350/391] Loss: 0.1794\n",
            "Epoch [28/200] Batch [351/391] Loss: 0.0911\n",
            "Epoch [28/200] Batch [352/391] Loss: 0.1948\n",
            "Epoch [28/200] Batch [353/391] Loss: 0.2119\n",
            "Epoch [28/200] Batch [354/391] Loss: 0.2227\n",
            "Epoch [28/200] Batch [355/391] Loss: 0.0731\n",
            "Epoch [28/200] Batch [356/391] Loss: 0.1423\n",
            "Epoch [28/200] Batch [357/391] Loss: 0.0991\n",
            "Epoch [28/200] Batch [358/391] Loss: 0.2384\n",
            "Epoch [28/200] Batch [359/391] Loss: 0.2399\n",
            "Epoch [28/200] Batch [360/391] Loss: 0.2360\n",
            "Epoch [28/200] Batch [361/391] Loss: 0.2354\n",
            "Epoch [28/200] Batch [362/391] Loss: 0.2514\n",
            "Epoch [28/200] Batch [363/391] Loss: 0.2018\n",
            "Epoch [28/200] Batch [364/391] Loss: 0.1950\n",
            "Epoch [28/200] Batch [365/391] Loss: 0.1953\n",
            "Epoch [28/200] Batch [366/391] Loss: 0.1021\n",
            "Epoch [28/200] Batch [367/391] Loss: 0.1162\n",
            "Epoch [28/200] Batch [368/391] Loss: 0.2007\n",
            "Epoch [28/200] Batch [369/391] Loss: 0.2457\n",
            "Epoch [28/200] Batch [370/391] Loss: 0.3043\n",
            "Epoch [28/200] Batch [371/391] Loss: 0.1586\n",
            "Epoch [28/200] Batch [372/391] Loss: 0.1317\n",
            "Epoch [28/200] Batch [373/391] Loss: 0.1907\n",
            "Epoch [28/200] Batch [374/391] Loss: 0.2324\n",
            "Epoch [28/200] Batch [375/391] Loss: 0.1117\n",
            "Epoch [28/200] Batch [376/391] Loss: 0.1687\n",
            "Epoch [28/200] Batch [377/391] Loss: 0.2337\n",
            "Epoch [28/200] Batch [378/391] Loss: 0.1334\n",
            "Epoch [28/200] Batch [379/391] Loss: 0.1258\n",
            "Epoch [28/200] Batch [380/391] Loss: 0.1719\n",
            "Epoch [28/200] Batch [381/391] Loss: 0.2488\n",
            "Epoch [28/200] Batch [382/391] Loss: 0.1808\n",
            "Epoch [28/200] Batch [383/391] Loss: 0.1397\n",
            "Epoch [28/200] Batch [384/391] Loss: 0.1800\n",
            "Epoch [28/200] Batch [385/391] Loss: 0.3805\n",
            "Epoch [28/200] Batch [386/391] Loss: 0.1462\n",
            "Epoch [28/200] Batch [387/391] Loss: 0.1724\n",
            "Epoch [28/200] Batch [388/391] Loss: 0.2073\n",
            "Epoch [28/200] Batch [389/391] Loss: 0.1831\n",
            "Epoch [28/200] Batch [390/391] Loss: 0.1137\n",
            "Epoch [28/200] Batch [391/391] Loss: 0.2155\n",
            "Epoch [28/200] - Train Loss: 0.1511 - Test Loss: 0.9121 - Train Acc: 85.61% - Test Acc: 77.60%\n",
            "Epoch [29/200] Batch [1/391] Loss: 0.1741\n",
            "Epoch [29/200] Batch [2/391] Loss: 0.2393\n",
            "Epoch [29/200] Batch [3/391] Loss: 0.1607\n",
            "Epoch [29/200] Batch [4/391] Loss: 0.1502\n",
            "Epoch [29/200] Batch [5/391] Loss: 0.1858\n",
            "Epoch [29/200] Batch [6/391] Loss: 0.1275\n",
            "Epoch [29/200] Batch [7/391] Loss: 0.1074\n",
            "Epoch [29/200] Batch [8/391] Loss: 0.1648\n",
            "Epoch [29/200] Batch [9/391] Loss: 0.1251\n",
            "Epoch [29/200] Batch [10/391] Loss: 0.1405\n",
            "Epoch [29/200] Batch [11/391] Loss: 0.3575\n",
            "Epoch [29/200] Batch [12/391] Loss: 0.1937\n",
            "Epoch [29/200] Batch [13/391] Loss: 0.1847\n",
            "Epoch [29/200] Batch [14/391] Loss: 0.2533\n",
            "Epoch [29/200] Batch [15/391] Loss: 0.0901\n",
            "Epoch [29/200] Batch [16/391] Loss: 0.0739\n",
            "Epoch [29/200] Batch [17/391] Loss: 0.1390\n",
            "Epoch [29/200] Batch [18/391] Loss: 0.1647\n",
            "Epoch [29/200] Batch [19/391] Loss: 0.1415\n",
            "Epoch [29/200] Batch [20/391] Loss: 0.1168\n",
            "Epoch [29/200] Batch [21/391] Loss: 0.1058\n",
            "Epoch [29/200] Batch [22/391] Loss: 0.1194\n",
            "Epoch [29/200] Batch [23/391] Loss: 0.1790\n",
            "Epoch [29/200] Batch [24/391] Loss: 0.1398\n",
            "Epoch [29/200] Batch [25/391] Loss: 0.1195\n",
            "Epoch [29/200] Batch [26/391] Loss: 0.1266\n",
            "Epoch [29/200] Batch [27/391] Loss: 0.1710\n",
            "Epoch [29/200] Batch [28/391] Loss: 0.1016\n",
            "Epoch [29/200] Batch [29/391] Loss: 0.1274\n",
            "Epoch [29/200] Batch [30/391] Loss: 0.1472\n",
            "Epoch [29/200] Batch [31/391] Loss: 0.1945\n",
            "Epoch [29/200] Batch [32/391] Loss: 0.0939\n",
            "Epoch [29/200] Batch [33/391] Loss: 0.1657\n",
            "Epoch [29/200] Batch [34/391] Loss: 0.1291\n",
            "Epoch [29/200] Batch [35/391] Loss: 0.0933\n",
            "Epoch [29/200] Batch [36/391] Loss: 0.0816\n",
            "Epoch [29/200] Batch [37/391] Loss: 0.1303\n",
            "Epoch [29/200] Batch [38/391] Loss: 0.1414\n",
            "Epoch [29/200] Batch [39/391] Loss: 0.0815\n",
            "Epoch [29/200] Batch [40/391] Loss: 0.1072\n",
            "Epoch [29/200] Batch [41/391] Loss: 0.1362\n",
            "Epoch [29/200] Batch [42/391] Loss: 0.1166\n",
            "Epoch [29/200] Batch [43/391] Loss: 0.0959\n",
            "Epoch [29/200] Batch [44/391] Loss: 0.0920\n",
            "Epoch [29/200] Batch [45/391] Loss: 0.1347\n",
            "Epoch [29/200] Batch [46/391] Loss: 0.1072\n",
            "Epoch [29/200] Batch [47/391] Loss: 0.0793\n",
            "Epoch [29/200] Batch [48/391] Loss: 0.1241\n",
            "Epoch [29/200] Batch [49/391] Loss: 0.0877\n",
            "Epoch [29/200] Batch [50/391] Loss: 0.1815\n",
            "Epoch [29/200] Batch [51/391] Loss: 0.1011\n",
            "Epoch [29/200] Batch [52/391] Loss: 0.1791\n",
            "Epoch [29/200] Batch [53/391] Loss: 0.1153\n",
            "Epoch [29/200] Batch [54/391] Loss: 0.0955\n",
            "Epoch [29/200] Batch [55/391] Loss: 0.1492\n",
            "Epoch [29/200] Batch [56/391] Loss: 0.0939\n",
            "Epoch [29/200] Batch [57/391] Loss: 0.1004\n",
            "Epoch [29/200] Batch [58/391] Loss: 0.1210\n",
            "Epoch [29/200] Batch [59/391] Loss: 0.1331\n",
            "Epoch [29/200] Batch [60/391] Loss: 0.0721\n",
            "Epoch [29/200] Batch [61/391] Loss: 0.1014\n",
            "Epoch [29/200] Batch [62/391] Loss: 0.0936\n",
            "Epoch [29/200] Batch [63/391] Loss: 0.1181\n",
            "Epoch [29/200] Batch [64/391] Loss: 0.0809\n",
            "Epoch [29/200] Batch [65/391] Loss: 0.0823\n",
            "Epoch [29/200] Batch [66/391] Loss: 0.1240\n",
            "Epoch [29/200] Batch [67/391] Loss: 0.0837\n",
            "Epoch [29/200] Batch [68/391] Loss: 0.0800\n",
            "Epoch [29/200] Batch [69/391] Loss: 0.0899\n",
            "Epoch [29/200] Batch [70/391] Loss: 0.0963\n",
            "Epoch [29/200] Batch [71/391] Loss: 0.0669\n",
            "Epoch [29/200] Batch [72/391] Loss: 0.1208\n",
            "Epoch [29/200] Batch [73/391] Loss: 0.1545\n",
            "Epoch [29/200] Batch [74/391] Loss: 0.0730\n",
            "Epoch [29/200] Batch [75/391] Loss: 0.1619\n",
            "Epoch [29/200] Batch [76/391] Loss: 0.1334\n",
            "Epoch [29/200] Batch [77/391] Loss: 0.2571\n",
            "Epoch [29/200] Batch [78/391] Loss: 0.1117\n",
            "Epoch [29/200] Batch [79/391] Loss: 0.1568\n",
            "Epoch [29/200] Batch [80/391] Loss: 0.0905\n",
            "Epoch [29/200] Batch [81/391] Loss: 0.0632\n",
            "Epoch [29/200] Batch [82/391] Loss: 0.1206\n",
            "Epoch [29/200] Batch [83/391] Loss: 0.0960\n",
            "Epoch [29/200] Batch [84/391] Loss: 0.0696\n",
            "Epoch [29/200] Batch [85/391] Loss: 0.1719\n",
            "Epoch [29/200] Batch [86/391] Loss: 0.1205\n",
            "Epoch [29/200] Batch [87/391] Loss: 0.1376\n",
            "Epoch [29/200] Batch [88/391] Loss: 0.1199\n",
            "Epoch [29/200] Batch [89/391] Loss: 0.1283\n",
            "Epoch [29/200] Batch [90/391] Loss: 0.1354\n",
            "Epoch [29/200] Batch [91/391] Loss: 0.1445\n",
            "Epoch [29/200] Batch [92/391] Loss: 0.0927\n",
            "Epoch [29/200] Batch [93/391] Loss: 0.1911\n",
            "Epoch [29/200] Batch [94/391] Loss: 0.0463\n",
            "Epoch [29/200] Batch [95/391] Loss: 0.2014\n",
            "Epoch [29/200] Batch [96/391] Loss: 0.0955\n",
            "Epoch [29/200] Batch [97/391] Loss: 0.1496\n",
            "Epoch [29/200] Batch [98/391] Loss: 0.1283\n",
            "Epoch [29/200] Batch [99/391] Loss: 0.1401\n",
            "Epoch [29/200] Batch [100/391] Loss: 0.1555\n",
            "Epoch [29/200] Batch [101/391] Loss: 0.1514\n",
            "Epoch [29/200] Batch [102/391] Loss: 0.1414\n",
            "Epoch [29/200] Batch [103/391] Loss: 0.0691\n",
            "Epoch [29/200] Batch [104/391] Loss: 0.1972\n",
            "Epoch [29/200] Batch [105/391] Loss: 0.1910\n",
            "Epoch [29/200] Batch [106/391] Loss: 0.1972\n",
            "Epoch [29/200] Batch [107/391] Loss: 0.1714\n",
            "Epoch [29/200] Batch [108/391] Loss: 0.0953\n",
            "Epoch [29/200] Batch [109/391] Loss: 0.1334\n",
            "Epoch [29/200] Batch [110/391] Loss: 0.1579\n",
            "Epoch [29/200] Batch [111/391] Loss: 0.1324\n",
            "Epoch [29/200] Batch [112/391] Loss: 0.1136\n",
            "Epoch [29/200] Batch [113/391] Loss: 0.0988\n",
            "Epoch [29/200] Batch [114/391] Loss: 0.1679\n",
            "Epoch [29/200] Batch [115/391] Loss: 0.1090\n",
            "Epoch [29/200] Batch [116/391] Loss: 0.2211\n",
            "Epoch [29/200] Batch [117/391] Loss: 0.0501\n",
            "Epoch [29/200] Batch [118/391] Loss: 0.4078\n",
            "Epoch [29/200] Batch [119/391] Loss: 0.2218\n",
            "Epoch [29/200] Batch [120/391] Loss: 0.1741\n",
            "Epoch [29/200] Batch [121/391] Loss: 0.1066\n",
            "Epoch [29/200] Batch [122/391] Loss: 0.1093\n",
            "Epoch [29/200] Batch [123/391] Loss: 0.1637\n",
            "Epoch [29/200] Batch [124/391] Loss: 0.1187\n",
            "Epoch [29/200] Batch [125/391] Loss: 0.1478\n",
            "Epoch [29/200] Batch [126/391] Loss: 0.0695\n",
            "Epoch [29/200] Batch [127/391] Loss: 0.0761\n",
            "Epoch [29/200] Batch [128/391] Loss: 0.1471\n",
            "Epoch [29/200] Batch [129/391] Loss: 0.2153\n",
            "Epoch [29/200] Batch [130/391] Loss: 0.1294\n",
            "Epoch [29/200] Batch [131/391] Loss: 0.1251\n",
            "Epoch [29/200] Batch [132/391] Loss: 0.1280\n",
            "Epoch [29/200] Batch [133/391] Loss: 0.1588\n",
            "Epoch [29/200] Batch [134/391] Loss: 0.1230\n",
            "Epoch [29/200] Batch [135/391] Loss: 0.0804\n",
            "Epoch [29/200] Batch [136/391] Loss: 0.1598\n",
            "Epoch [29/200] Batch [137/391] Loss: 0.1491\n",
            "Epoch [29/200] Batch [138/391] Loss: 0.2671\n",
            "Epoch [29/200] Batch [139/391] Loss: 0.1976\n",
            "Epoch [29/200] Batch [140/391] Loss: 0.1452\n",
            "Epoch [29/200] Batch [141/391] Loss: 0.1557\n",
            "Epoch [29/200] Batch [142/391] Loss: 0.0757\n",
            "Epoch [29/200] Batch [143/391] Loss: 0.1479\n",
            "Epoch [29/200] Batch [144/391] Loss: 0.1289\n",
            "Epoch [29/200] Batch [145/391] Loss: 0.1240\n",
            "Epoch [29/200] Batch [146/391] Loss: 0.1325\n",
            "Epoch [29/200] Batch [147/391] Loss: 0.0771\n",
            "Epoch [29/200] Batch [148/391] Loss: 0.1729\n",
            "Epoch [29/200] Batch [149/391] Loss: 0.1452\n",
            "Epoch [29/200] Batch [150/391] Loss: 0.1133\n",
            "Epoch [29/200] Batch [151/391] Loss: 0.1501\n",
            "Epoch [29/200] Batch [152/391] Loss: 0.1030\n",
            "Epoch [29/200] Batch [153/391] Loss: 0.1614\n",
            "Epoch [29/200] Batch [154/391] Loss: 0.1190\n",
            "Epoch [29/200] Batch [155/391] Loss: 0.0787\n",
            "Epoch [29/200] Batch [156/391] Loss: 0.1641\n",
            "Epoch [29/200] Batch [157/391] Loss: 0.1106\n",
            "Epoch [29/200] Batch [158/391] Loss: 0.1374\n",
            "Epoch [29/200] Batch [159/391] Loss: 0.1789\n",
            "Epoch [29/200] Batch [160/391] Loss: 0.0711\n",
            "Epoch [29/200] Batch [161/391] Loss: 0.1183\n",
            "Epoch [29/200] Batch [162/391] Loss: 0.0870\n",
            "Epoch [29/200] Batch [163/391] Loss: 0.1088\n",
            "Epoch [29/200] Batch [164/391] Loss: 0.1611\n",
            "Epoch [29/200] Batch [165/391] Loss: 0.1871\n",
            "Epoch [29/200] Batch [166/391] Loss: 0.1050\n",
            "Epoch [29/200] Batch [167/391] Loss: 0.1623\n",
            "Epoch [29/200] Batch [168/391] Loss: 0.1752\n",
            "Epoch [29/200] Batch [169/391] Loss: 0.1034\n",
            "Epoch [29/200] Batch [170/391] Loss: 0.0523\n",
            "Epoch [29/200] Batch [171/391] Loss: 0.0770\n",
            "Epoch [29/200] Batch [172/391] Loss: 0.0834\n",
            "Epoch [29/200] Batch [173/391] Loss: 0.1457\n",
            "Epoch [29/200] Batch [174/391] Loss: 0.1791\n",
            "Epoch [29/200] Batch [175/391] Loss: 0.1423\n",
            "Epoch [29/200] Batch [176/391] Loss: 0.0978\n",
            "Epoch [29/200] Batch [177/391] Loss: 0.1268\n",
            "Epoch [29/200] Batch [178/391] Loss: 0.0583\n",
            "Epoch [29/200] Batch [179/391] Loss: 0.1567\n",
            "Epoch [29/200] Batch [180/391] Loss: 0.0964\n",
            "Epoch [29/200] Batch [181/391] Loss: 0.1788\n",
            "Epoch [29/200] Batch [182/391] Loss: 0.0984\n",
            "Epoch [29/200] Batch [183/391] Loss: 0.0816\n",
            "Epoch [29/200] Batch [184/391] Loss: 0.1181\n",
            "Epoch [29/200] Batch [185/391] Loss: 0.2367\n",
            "Epoch [29/200] Batch [186/391] Loss: 0.1053\n",
            "Epoch [29/200] Batch [187/391] Loss: 0.1278\n",
            "Epoch [29/200] Batch [188/391] Loss: 0.0555\n",
            "Epoch [29/200] Batch [189/391] Loss: 0.1169\n",
            "Epoch [29/200] Batch [190/391] Loss: 0.1359\n",
            "Epoch [29/200] Batch [191/391] Loss: 0.1566\n",
            "Epoch [29/200] Batch [192/391] Loss: 0.0985\n",
            "Epoch [29/200] Batch [193/391] Loss: 0.0990\n",
            "Epoch [29/200] Batch [194/391] Loss: 0.1863\n",
            "Epoch [29/200] Batch [195/391] Loss: 0.0834\n",
            "Epoch [29/200] Batch [196/391] Loss: 0.1020\n",
            "Epoch [29/200] Batch [197/391] Loss: 0.2071\n",
            "Epoch [29/200] Batch [198/391] Loss: 0.1961\n",
            "Epoch [29/200] Batch [199/391] Loss: 0.0411\n",
            "Epoch [29/200] Batch [200/391] Loss: 0.1583\n",
            "Epoch [29/200] Batch [201/391] Loss: 0.1752\n",
            "Epoch [29/200] Batch [202/391] Loss: 0.1542\n",
            "Epoch [29/200] Batch [203/391] Loss: 0.1685\n",
            "Epoch [29/200] Batch [204/391] Loss: 0.1634\n",
            "Epoch [29/200] Batch [205/391] Loss: 0.1075\n",
            "Epoch [29/200] Batch [206/391] Loss: 0.1257\n",
            "Epoch [29/200] Batch [207/391] Loss: 0.0907\n",
            "Epoch [29/200] Batch [208/391] Loss: 0.1223\n",
            "Epoch [29/200] Batch [209/391] Loss: 0.1935\n",
            "Epoch [29/200] Batch [210/391] Loss: 0.1585\n",
            "Epoch [29/200] Batch [211/391] Loss: 0.1549\n",
            "Epoch [29/200] Batch [212/391] Loss: 0.1115\n",
            "Epoch [29/200] Batch [213/391] Loss: 0.1317\n",
            "Epoch [29/200] Batch [214/391] Loss: 0.1327\n",
            "Epoch [29/200] Batch [215/391] Loss: 0.1016\n",
            "Epoch [29/200] Batch [216/391] Loss: 0.2214\n",
            "Epoch [29/200] Batch [217/391] Loss: 0.1689\n",
            "Epoch [29/200] Batch [218/391] Loss: 0.1418\n",
            "Epoch [29/200] Batch [219/391] Loss: 0.0759\n",
            "Epoch [29/200] Batch [220/391] Loss: 0.2278\n",
            "Epoch [29/200] Batch [221/391] Loss: 0.1590\n",
            "Epoch [29/200] Batch [222/391] Loss: 0.1853\n",
            "Epoch [29/200] Batch [223/391] Loss: 0.1357\n",
            "Epoch [29/200] Batch [224/391] Loss: 0.1290\n",
            "Epoch [29/200] Batch [225/391] Loss: 0.1052\n",
            "Epoch [29/200] Batch [226/391] Loss: 0.0973\n",
            "Epoch [29/200] Batch [227/391] Loss: 0.1796\n",
            "Epoch [29/200] Batch [228/391] Loss: 0.1199\n",
            "Epoch [29/200] Batch [229/391] Loss: 0.1860\n",
            "Epoch [29/200] Batch [230/391] Loss: 0.2019\n",
            "Epoch [29/200] Batch [231/391] Loss: 0.1728\n",
            "Epoch [29/200] Batch [232/391] Loss: 0.1467\n",
            "Epoch [29/200] Batch [233/391] Loss: 0.2022\n",
            "Epoch [29/200] Batch [234/391] Loss: 0.0689\n",
            "Epoch [29/200] Batch [235/391] Loss: 0.1877\n",
            "Epoch [29/200] Batch [236/391] Loss: 0.1118\n",
            "Epoch [29/200] Batch [237/391] Loss: 0.2094\n",
            "Epoch [29/200] Batch [238/391] Loss: 0.1717\n",
            "Epoch [29/200] Batch [239/391] Loss: 0.2655\n",
            "Epoch [29/200] Batch [240/391] Loss: 0.1102\n",
            "Epoch [29/200] Batch [241/391] Loss: 0.1015\n",
            "Epoch [29/200] Batch [242/391] Loss: 0.1864\n",
            "Epoch [29/200] Batch [243/391] Loss: 0.1013\n",
            "Epoch [29/200] Batch [244/391] Loss: 0.1988\n",
            "Epoch [29/200] Batch [245/391] Loss: 0.1892\n",
            "Epoch [29/200] Batch [246/391] Loss: 0.2150\n",
            "Epoch [29/200] Batch [247/391] Loss: 0.1043\n",
            "Epoch [29/200] Batch [248/391] Loss: 0.1170\n",
            "Epoch [29/200] Batch [249/391] Loss: 0.1737\n",
            "Epoch [29/200] Batch [250/391] Loss: 0.1232\n",
            "Epoch [29/200] Batch [251/391] Loss: 0.1385\n",
            "Epoch [29/200] Batch [252/391] Loss: 0.2005\n",
            "Epoch [29/200] Batch [253/391] Loss: 0.1401\n",
            "Epoch [29/200] Batch [254/391] Loss: 0.1327\n",
            "Epoch [29/200] Batch [255/391] Loss: 0.1081\n",
            "Epoch [29/200] Batch [256/391] Loss: 0.1100\n",
            "Epoch [29/200] Batch [257/391] Loss: 0.1636\n",
            "Epoch [29/200] Batch [258/391] Loss: 0.1921\n",
            "Epoch [29/200] Batch [259/391] Loss: 0.0504\n",
            "Epoch [29/200] Batch [260/391] Loss: 0.1826\n",
            "Epoch [29/200] Batch [261/391] Loss: 0.1325\n",
            "Epoch [29/200] Batch [262/391] Loss: 0.1522\n",
            "Epoch [29/200] Batch [263/391] Loss: 0.0853\n",
            "Epoch [29/200] Batch [264/391] Loss: 0.0949\n",
            "Epoch [29/200] Batch [265/391] Loss: 0.1300\n",
            "Epoch [29/200] Batch [266/391] Loss: 0.0791\n",
            "Epoch [29/200] Batch [267/391] Loss: 0.1103\n",
            "Epoch [29/200] Batch [268/391] Loss: 0.2345\n",
            "Epoch [29/200] Batch [269/391] Loss: 0.2132\n",
            "Epoch [29/200] Batch [270/391] Loss: 0.2685\n",
            "Epoch [29/200] Batch [271/391] Loss: 0.2603\n",
            "Epoch [29/200] Batch [272/391] Loss: 0.1364\n",
            "Epoch [29/200] Batch [273/391] Loss: 0.1638\n",
            "Epoch [29/200] Batch [274/391] Loss: 0.1187\n",
            "Epoch [29/200] Batch [275/391] Loss: 0.0711\n",
            "Epoch [29/200] Batch [276/391] Loss: 0.1448\n",
            "Epoch [29/200] Batch [277/391] Loss: 0.1443\n",
            "Epoch [29/200] Batch [278/391] Loss: 0.1129\n",
            "Epoch [29/200] Batch [279/391] Loss: 0.1974\n",
            "Epoch [29/200] Batch [280/391] Loss: 0.1142\n",
            "Epoch [29/200] Batch [281/391] Loss: 0.2549\n",
            "Epoch [29/200] Batch [282/391] Loss: 0.1303\n",
            "Epoch [29/200] Batch [283/391] Loss: 0.2261\n",
            "Epoch [29/200] Batch [284/391] Loss: 0.1635\n",
            "Epoch [29/200] Batch [285/391] Loss: 0.1605\n",
            "Epoch [29/200] Batch [286/391] Loss: 0.1479\n",
            "Epoch [29/200] Batch [287/391] Loss: 0.0936\n",
            "Epoch [29/200] Batch [288/391] Loss: 0.1669\n",
            "Epoch [29/200] Batch [289/391] Loss: 0.1369\n",
            "Epoch [29/200] Batch [290/391] Loss: 0.1373\n",
            "Epoch [29/200] Batch [291/391] Loss: 0.1234\n",
            "Epoch [29/200] Batch [292/391] Loss: 0.1531\n",
            "Epoch [29/200] Batch [293/391] Loss: 0.2168\n",
            "Epoch [29/200] Batch [294/391] Loss: 0.1400\n",
            "Epoch [29/200] Batch [295/391] Loss: 0.2171\n",
            "Epoch [29/200] Batch [296/391] Loss: 0.1082\n",
            "Epoch [29/200] Batch [297/391] Loss: 0.1430\n",
            "Epoch [29/200] Batch [298/391] Loss: 0.1635\n",
            "Epoch [29/200] Batch [299/391] Loss: 0.1021\n",
            "Epoch [29/200] Batch [300/391] Loss: 0.1675\n",
            "Epoch [29/200] Batch [301/391] Loss: 0.2061\n",
            "Epoch [29/200] Batch [302/391] Loss: 0.0904\n",
            "Epoch [29/200] Batch [303/391] Loss: 0.2050\n",
            "Epoch [29/200] Batch [304/391] Loss: 0.1981\n",
            "Epoch [29/200] Batch [305/391] Loss: 0.1460\n",
            "Epoch [29/200] Batch [306/391] Loss: 0.2355\n",
            "Epoch [29/200] Batch [307/391] Loss: 0.0787\n",
            "Epoch [29/200] Batch [308/391] Loss: 0.2327\n",
            "Epoch [29/200] Batch [309/391] Loss: 0.2467\n",
            "Epoch [29/200] Batch [310/391] Loss: 0.1126\n",
            "Epoch [29/200] Batch [311/391] Loss: 0.1751\n",
            "Epoch [29/200] Batch [312/391] Loss: 0.1292\n",
            "Epoch [29/200] Batch [313/391] Loss: 0.2585\n",
            "Epoch [29/200] Batch [314/391] Loss: 0.2326\n",
            "Epoch [29/200] Batch [315/391] Loss: 0.1559\n",
            "Epoch [29/200] Batch [316/391] Loss: 0.1527\n",
            "Epoch [29/200] Batch [317/391] Loss: 0.1527\n",
            "Epoch [29/200] Batch [318/391] Loss: 0.2484\n",
            "Epoch [29/200] Batch [319/391] Loss: 0.1570\n",
            "Epoch [29/200] Batch [320/391] Loss: 0.1033\n",
            "Epoch [29/200] Batch [321/391] Loss: 0.1173\n",
            "Epoch [29/200] Batch [322/391] Loss: 0.1590\n",
            "Epoch [29/200] Batch [323/391] Loss: 0.1204\n",
            "Epoch [29/200] Batch [324/391] Loss: 0.1389\n",
            "Epoch [29/200] Batch [325/391] Loss: 0.1115\n",
            "Epoch [29/200] Batch [326/391] Loss: 0.1274\n",
            "Epoch [29/200] Batch [327/391] Loss: 0.1369\n",
            "Epoch [29/200] Batch [328/391] Loss: 0.2128\n",
            "Epoch [29/200] Batch [329/391] Loss: 0.1778\n",
            "Epoch [29/200] Batch [330/391] Loss: 0.0990\n",
            "Epoch [29/200] Batch [331/391] Loss: 0.1326\n",
            "Epoch [29/200] Batch [332/391] Loss: 0.1508\n",
            "Epoch [29/200] Batch [333/391] Loss: 0.1208\n",
            "Epoch [29/200] Batch [334/391] Loss: 0.1734\n",
            "Epoch [29/200] Batch [335/391] Loss: 0.1635\n",
            "Epoch [29/200] Batch [336/391] Loss: 0.1105\n",
            "Epoch [29/200] Batch [337/391] Loss: 0.1922\n",
            "Epoch [29/200] Batch [338/391] Loss: 0.1162\n",
            "Epoch [29/200] Batch [339/391] Loss: 0.2355\n",
            "Epoch [29/200] Batch [340/391] Loss: 0.2217\n",
            "Epoch [29/200] Batch [341/391] Loss: 0.1186\n",
            "Epoch [29/200] Batch [342/391] Loss: 0.2032\n",
            "Epoch [29/200] Batch [343/391] Loss: 0.1627\n",
            "Epoch [29/200] Batch [344/391] Loss: 0.1812\n",
            "Epoch [29/200] Batch [345/391] Loss: 0.1728\n",
            "Epoch [29/200] Batch [346/391] Loss: 0.0669\n",
            "Epoch [29/200] Batch [347/391] Loss: 0.1397\n",
            "Epoch [29/200] Batch [348/391] Loss: 0.1911\n",
            "Epoch [29/200] Batch [349/391] Loss: 0.2551\n",
            "Epoch [29/200] Batch [350/391] Loss: 0.1768\n",
            "Epoch [29/200] Batch [351/391] Loss: 0.1018\n",
            "Epoch [29/200] Batch [352/391] Loss: 0.1174\n",
            "Epoch [29/200] Batch [353/391] Loss: 0.1904\n",
            "Epoch [29/200] Batch [354/391] Loss: 0.2847\n",
            "Epoch [29/200] Batch [355/391] Loss: 0.1253\n",
            "Epoch [29/200] Batch [356/391] Loss: 0.1676\n",
            "Epoch [29/200] Batch [357/391] Loss: 0.1377\n",
            "Epoch [29/200] Batch [358/391] Loss: 0.1893\n",
            "Epoch [29/200] Batch [359/391] Loss: 0.2541\n",
            "Epoch [29/200] Batch [360/391] Loss: 0.0792\n",
            "Epoch [29/200] Batch [361/391] Loss: 0.1917\n",
            "Epoch [29/200] Batch [362/391] Loss: 0.2143\n",
            "Epoch [29/200] Batch [363/391] Loss: 0.1098\n",
            "Epoch [29/200] Batch [364/391] Loss: 0.2175\n",
            "Epoch [29/200] Batch [365/391] Loss: 0.2266\n",
            "Epoch [29/200] Batch [366/391] Loss: 0.1833\n",
            "Epoch [29/200] Batch [367/391] Loss: 0.1639\n",
            "Epoch [29/200] Batch [368/391] Loss: 0.2005\n",
            "Epoch [29/200] Batch [369/391] Loss: 0.1602\n",
            "Epoch [29/200] Batch [370/391] Loss: 0.1465\n",
            "Epoch [29/200] Batch [371/391] Loss: 0.1322\n",
            "Epoch [29/200] Batch [372/391] Loss: 0.1631\n",
            "Epoch [29/200] Batch [373/391] Loss: 0.1206\n",
            "Epoch [29/200] Batch [374/391] Loss: 0.0928\n",
            "Epoch [29/200] Batch [375/391] Loss: 0.2050\n",
            "Epoch [29/200] Batch [376/391] Loss: 0.1165\n",
            "Epoch [29/200] Batch [377/391] Loss: 0.1234\n",
            "Epoch [29/200] Batch [378/391] Loss: 0.0974\n",
            "Epoch [29/200] Batch [379/391] Loss: 0.1280\n",
            "Epoch [29/200] Batch [380/391] Loss: 0.1285\n",
            "Epoch [29/200] Batch [381/391] Loss: 0.2361\n",
            "Epoch [29/200] Batch [382/391] Loss: 0.1607\n",
            "Epoch [29/200] Batch [383/391] Loss: 0.1298\n",
            "Epoch [29/200] Batch [384/391] Loss: 0.1020\n",
            "Epoch [29/200] Batch [385/391] Loss: 0.1836\n",
            "Epoch [29/200] Batch [386/391] Loss: 0.1797\n",
            "Epoch [29/200] Batch [387/391] Loss: 0.1350\n",
            "Epoch [29/200] Batch [388/391] Loss: 0.1703\n",
            "Epoch [29/200] Batch [389/391] Loss: 0.1509\n",
            "Epoch [29/200] Batch [390/391] Loss: 0.0878\n",
            "Epoch [29/200] Batch [391/391] Loss: 0.2078\n",
            "Epoch [29/200] - Train Loss: 0.1441 - Test Loss: 0.9590 - Train Acc: 85.29% - Test Acc: 76.90%\n",
            "Epoch [30/200] Batch [1/391] Loss: 0.1611\n",
            "Epoch [30/200] Batch [2/391] Loss: 0.0757\n",
            "Epoch [30/200] Batch [3/391] Loss: 0.0877\n",
            "Epoch [30/200] Batch [4/391] Loss: 0.1898\n",
            "Epoch [30/200] Batch [5/391] Loss: 0.1723\n",
            "Epoch [30/200] Batch [6/391] Loss: 0.1184\n",
            "Epoch [30/200] Batch [7/391] Loss: 0.1751\n",
            "Epoch [30/200] Batch [8/391] Loss: 0.1508\n",
            "Epoch [30/200] Batch [9/391] Loss: 0.1155\n",
            "Epoch [30/200] Batch [10/391] Loss: 0.1137\n",
            "Epoch [30/200] Batch [11/391] Loss: 0.1070\n",
            "Epoch [30/200] Batch [12/391] Loss: 0.1254\n",
            "Epoch [30/200] Batch [13/391] Loss: 0.1054\n",
            "Epoch [30/200] Batch [14/391] Loss: 0.1063\n",
            "Epoch [30/200] Batch [15/391] Loss: 0.1222\n",
            "Epoch [30/200] Batch [16/391] Loss: 0.1308\n",
            "Epoch [30/200] Batch [17/391] Loss: 0.1227\n",
            "Epoch [30/200] Batch [18/391] Loss: 0.1609\n",
            "Epoch [30/200] Batch [19/391] Loss: 0.0927\n",
            "Epoch [30/200] Batch [20/391] Loss: 0.1079\n",
            "Epoch [30/200] Batch [21/391] Loss: 0.1150\n",
            "Epoch [30/200] Batch [22/391] Loss: 0.1372\n",
            "Epoch [30/200] Batch [23/391] Loss: 0.1049\n",
            "Epoch [30/200] Batch [24/391] Loss: 0.0806\n",
            "Epoch [30/200] Batch [25/391] Loss: 0.1296\n",
            "Epoch [30/200] Batch [26/391] Loss: 0.0775\n",
            "Epoch [30/200] Batch [27/391] Loss: 0.1432\n",
            "Epoch [30/200] Batch [28/391] Loss: 0.1393\n",
            "Epoch [30/200] Batch [29/391] Loss: 0.1435\n",
            "Epoch [30/200] Batch [30/391] Loss: 0.0687\n",
            "Epoch [30/200] Batch [31/391] Loss: 0.0633\n",
            "Epoch [30/200] Batch [32/391] Loss: 0.0436\n",
            "Epoch [30/200] Batch [33/391] Loss: 0.0602\n",
            "Epoch [30/200] Batch [34/391] Loss: 0.1642\n",
            "Epoch [30/200] Batch [35/391] Loss: 0.0994\n",
            "Epoch [30/200] Batch [36/391] Loss: 0.1380\n",
            "Epoch [30/200] Batch [37/391] Loss: 0.0726\n",
            "Epoch [30/200] Batch [38/391] Loss: 0.1646\n",
            "Epoch [30/200] Batch [39/391] Loss: 0.1264\n",
            "Epoch [30/200] Batch [40/391] Loss: 0.0805\n",
            "Epoch [30/200] Batch [41/391] Loss: 0.0562\n",
            "Epoch [30/200] Batch [42/391] Loss: 0.0840\n",
            "Epoch [30/200] Batch [43/391] Loss: 0.1005\n",
            "Epoch [30/200] Batch [44/391] Loss: 0.1200\n",
            "Epoch [30/200] Batch [45/391] Loss: 0.0755\n",
            "Epoch [30/200] Batch [46/391] Loss: 0.1093\n",
            "Epoch [30/200] Batch [47/391] Loss: 0.0469\n",
            "Epoch [30/200] Batch [48/391] Loss: 0.0905\n",
            "Epoch [30/200] Batch [49/391] Loss: 0.1378\n",
            "Epoch [30/200] Batch [50/391] Loss: 0.1097\n",
            "Epoch [30/200] Batch [51/391] Loss: 0.0711\n",
            "Epoch [30/200] Batch [52/391] Loss: 0.1155\n",
            "Epoch [30/200] Batch [53/391] Loss: 0.1931\n",
            "Epoch [30/200] Batch [54/391] Loss: 0.1206\n",
            "Epoch [30/200] Batch [55/391] Loss: 0.1173\n",
            "Epoch [30/200] Batch [56/391] Loss: 0.1643\n",
            "Epoch [30/200] Batch [57/391] Loss: 0.0814\n",
            "Epoch [30/200] Batch [58/391] Loss: 0.1424\n",
            "Epoch [30/200] Batch [59/391] Loss: 0.0767\n",
            "Epoch [30/200] Batch [60/391] Loss: 0.1006\n",
            "Epoch [30/200] Batch [61/391] Loss: 0.0594\n",
            "Epoch [30/200] Batch [62/391] Loss: 0.0980\n",
            "Epoch [30/200] Batch [63/391] Loss: 0.0882\n",
            "Epoch [30/200] Batch [64/391] Loss: 0.1261\n",
            "Epoch [30/200] Batch [65/391] Loss: 0.1550\n",
            "Epoch [30/200] Batch [66/391] Loss: 0.1126\n",
            "Epoch [30/200] Batch [67/391] Loss: 0.0788\n",
            "Epoch [30/200] Batch [68/391] Loss: 0.0759\n",
            "Epoch [30/200] Batch [69/391] Loss: 0.1019\n",
            "Epoch [30/200] Batch [70/391] Loss: 0.1242\n",
            "Epoch [30/200] Batch [71/391] Loss: 0.1096\n",
            "Epoch [30/200] Batch [72/391] Loss: 0.1529\n",
            "Epoch [30/200] Batch [73/391] Loss: 0.1067\n",
            "Epoch [30/200] Batch [74/391] Loss: 0.1388\n",
            "Epoch [30/200] Batch [75/391] Loss: 0.1010\n",
            "Epoch [30/200] Batch [76/391] Loss: 0.1104\n",
            "Epoch [30/200] Batch [77/391] Loss: 0.1228\n",
            "Epoch [30/200] Batch [78/391] Loss: 0.0577\n",
            "Epoch [30/200] Batch [79/391] Loss: 0.2095\n",
            "Epoch [30/200] Batch [80/391] Loss: 0.1263\n",
            "Epoch [30/200] Batch [81/391] Loss: 0.0583\n",
            "Epoch [30/200] Batch [82/391] Loss: 0.1152\n",
            "Epoch [30/200] Batch [83/391] Loss: 0.0695\n",
            "Epoch [30/200] Batch [84/391] Loss: 0.0771\n",
            "Epoch [30/200] Batch [85/391] Loss: 0.1110\n",
            "Epoch [30/200] Batch [86/391] Loss: 0.1439\n",
            "Epoch [30/200] Batch [87/391] Loss: 0.1277\n",
            "Epoch [30/200] Batch [88/391] Loss: 0.1227\n",
            "Epoch [30/200] Batch [89/391] Loss: 0.0489\n",
            "Epoch [30/200] Batch [90/391] Loss: 0.1251\n",
            "Epoch [30/200] Batch [91/391] Loss: 0.1550\n",
            "Epoch [30/200] Batch [92/391] Loss: 0.1250\n",
            "Epoch [30/200] Batch [93/391] Loss: 0.0994\n",
            "Epoch [30/200] Batch [94/391] Loss: 0.0434\n",
            "Epoch [30/200] Batch [95/391] Loss: 0.0614\n",
            "Epoch [30/200] Batch [96/391] Loss: 0.1612\n",
            "Epoch [30/200] Batch [97/391] Loss: 0.1497\n",
            "Epoch [30/200] Batch [98/391] Loss: 0.1205\n",
            "Epoch [30/200] Batch [99/391] Loss: 0.0809\n",
            "Epoch [30/200] Batch [100/391] Loss: 0.1478\n",
            "Epoch [30/200] Batch [101/391] Loss: 0.0833\n",
            "Epoch [30/200] Batch [102/391] Loss: 0.1446\n",
            "Epoch [30/200] Batch [103/391] Loss: 0.0613\n",
            "Epoch [30/200] Batch [104/391] Loss: 0.1114\n",
            "Epoch [30/200] Batch [105/391] Loss: 0.1021\n",
            "Epoch [30/200] Batch [106/391] Loss: 0.1141\n",
            "Epoch [30/200] Batch [107/391] Loss: 0.0852\n",
            "Epoch [30/200] Batch [108/391] Loss: 0.1344\n",
            "Epoch [30/200] Batch [109/391] Loss: 0.0975\n",
            "Epoch [30/200] Batch [110/391] Loss: 0.1018\n",
            "Epoch [30/200] Batch [111/391] Loss: 0.0956\n",
            "Epoch [30/200] Batch [112/391] Loss: 0.0987\n",
            "Epoch [30/200] Batch [113/391] Loss: 0.0799\n",
            "Epoch [30/200] Batch [114/391] Loss: 0.0863\n",
            "Epoch [30/200] Batch [115/391] Loss: 0.0872\n",
            "Epoch [30/200] Batch [116/391] Loss: 0.0904\n",
            "Epoch [30/200] Batch [117/391] Loss: 0.0678\n",
            "Epoch [30/200] Batch [118/391] Loss: 0.1099\n",
            "Epoch [30/200] Batch [119/391] Loss: 0.1033\n",
            "Epoch [30/200] Batch [120/391] Loss: 0.0701\n",
            "Epoch [30/200] Batch [121/391] Loss: 0.1115\n",
            "Epoch [30/200] Batch [122/391] Loss: 0.0858\n",
            "Epoch [30/200] Batch [123/391] Loss: 0.1130\n",
            "Epoch [30/200] Batch [124/391] Loss: 0.1764\n",
            "Epoch [30/200] Batch [125/391] Loss: 0.1034\n",
            "Epoch [30/200] Batch [126/391] Loss: 0.1800\n",
            "Epoch [30/200] Batch [127/391] Loss: 0.0709\n",
            "Epoch [30/200] Batch [128/391] Loss: 0.1188\n",
            "Epoch [30/200] Batch [129/391] Loss: 0.1224\n",
            "Epoch [30/200] Batch [130/391] Loss: 0.1584\n",
            "Epoch [30/200] Batch [131/391] Loss: 0.1396\n",
            "Epoch [30/200] Batch [132/391] Loss: 0.1039\n",
            "Epoch [30/200] Batch [133/391] Loss: 0.0837\n",
            "Epoch [30/200] Batch [134/391] Loss: 0.0653\n",
            "Epoch [30/200] Batch [135/391] Loss: 0.2010\n",
            "Epoch [30/200] Batch [136/391] Loss: 0.1287\n",
            "Epoch [30/200] Batch [137/391] Loss: 0.0485\n",
            "Epoch [30/200] Batch [138/391] Loss: 0.1087\n",
            "Epoch [30/200] Batch [139/391] Loss: 0.1175\n",
            "Epoch [30/200] Batch [140/391] Loss: 0.1452\n",
            "Epoch [30/200] Batch [141/391] Loss: 0.1353\n",
            "Epoch [30/200] Batch [142/391] Loss: 0.1109\n",
            "Epoch [30/200] Batch [143/391] Loss: 0.0848\n",
            "Epoch [30/200] Batch [144/391] Loss: 0.0724\n",
            "Epoch [30/200] Batch [145/391] Loss: 0.1912\n",
            "Epoch [30/200] Batch [146/391] Loss: 0.0539\n",
            "Epoch [30/200] Batch [147/391] Loss: 0.1254\n",
            "Epoch [30/200] Batch [148/391] Loss: 0.0882\n",
            "Epoch [30/200] Batch [149/391] Loss: 0.1128\n",
            "Epoch [30/200] Batch [150/391] Loss: 0.1253\n",
            "Epoch [30/200] Batch [151/391] Loss: 0.0964\n",
            "Epoch [30/200] Batch [152/391] Loss: 0.0783\n",
            "Epoch [30/200] Batch [153/391] Loss: 0.1056\n",
            "Epoch [30/200] Batch [154/391] Loss: 0.0498\n",
            "Epoch [30/200] Batch [155/391] Loss: 0.1412\n",
            "Epoch [30/200] Batch [156/391] Loss: 0.1427\n",
            "Epoch [30/200] Batch [157/391] Loss: 0.0553\n",
            "Epoch [30/200] Batch [158/391] Loss: 0.1352\n",
            "Epoch [30/200] Batch [159/391] Loss: 0.1502\n",
            "Epoch [30/200] Batch [160/391] Loss: 0.1445\n",
            "Epoch [30/200] Batch [161/391] Loss: 0.1352\n",
            "Epoch [30/200] Batch [162/391] Loss: 0.1463\n",
            "Epoch [30/200] Batch [163/391] Loss: 0.0925\n",
            "Epoch [30/200] Batch [164/391] Loss: 0.1069\n",
            "Epoch [30/200] Batch [165/391] Loss: 0.1383\n",
            "Epoch [30/200] Batch [166/391] Loss: 0.1458\n",
            "Epoch [30/200] Batch [167/391] Loss: 0.2093\n",
            "Epoch [30/200] Batch [168/391] Loss: 0.1332\n",
            "Epoch [30/200] Batch [169/391] Loss: 0.1168\n",
            "Epoch [30/200] Batch [170/391] Loss: 0.0357\n",
            "Epoch [30/200] Batch [171/391] Loss: 0.1604\n",
            "Epoch [30/200] Batch [172/391] Loss: 0.1558\n",
            "Epoch [30/200] Batch [173/391] Loss: 0.2226\n",
            "Epoch [30/200] Batch [174/391] Loss: 0.1833\n",
            "Epoch [30/200] Batch [175/391] Loss: 0.1770\n",
            "Epoch [30/200] Batch [176/391] Loss: 0.1081\n",
            "Epoch [30/200] Batch [177/391] Loss: 0.1167\n",
            "Epoch [30/200] Batch [178/391] Loss: 0.1572\n",
            "Epoch [30/200] Batch [179/391] Loss: 0.1015\n",
            "Epoch [30/200] Batch [180/391] Loss: 0.1772\n",
            "Epoch [30/200] Batch [181/391] Loss: 0.1354\n",
            "Epoch [30/200] Batch [182/391] Loss: 0.1301\n",
            "Epoch [30/200] Batch [183/391] Loss: 0.1492\n",
            "Epoch [30/200] Batch [184/391] Loss: 0.1110\n",
            "Epoch [30/200] Batch [185/391] Loss: 0.0988\n",
            "Epoch [30/200] Batch [186/391] Loss: 0.1523\n",
            "Epoch [30/200] Batch [187/391] Loss: 0.2234\n",
            "Epoch [30/200] Batch [188/391] Loss: 0.2291\n",
            "Epoch [30/200] Batch [189/391] Loss: 0.1472\n",
            "Epoch [30/200] Batch [190/391] Loss: 0.1600\n",
            "Epoch [30/200] Batch [191/391] Loss: 0.0952\n",
            "Epoch [30/200] Batch [192/391] Loss: 0.1248\n",
            "Epoch [30/200] Batch [193/391] Loss: 0.1583\n",
            "Epoch [30/200] Batch [194/391] Loss: 0.0944\n",
            "Epoch [30/200] Batch [195/391] Loss: 0.1416\n",
            "Epoch [30/200] Batch [196/391] Loss: 0.1874\n",
            "Epoch [30/200] Batch [197/391] Loss: 0.2370\n",
            "Epoch [30/200] Batch [198/391] Loss: 0.1509\n",
            "Epoch [30/200] Batch [199/391] Loss: 0.0887\n",
            "Epoch [30/200] Batch [200/391] Loss: 0.1520\n",
            "Epoch [30/200] Batch [201/391] Loss: 0.0967\n",
            "Epoch [30/200] Batch [202/391] Loss: 0.1954\n",
            "Epoch [30/200] Batch [203/391] Loss: 0.1141\n",
            "Epoch [30/200] Batch [204/391] Loss: 0.1275\n",
            "Epoch [30/200] Batch [205/391] Loss: 0.1854\n",
            "Epoch [30/200] Batch [206/391] Loss: 0.1094\n",
            "Epoch [30/200] Batch [207/391] Loss: 0.1584\n",
            "Epoch [30/200] Batch [208/391] Loss: 0.1788\n",
            "Epoch [30/200] Batch [209/391] Loss: 0.1371\n",
            "Epoch [30/200] Batch [210/391] Loss: 0.0795\n",
            "Epoch [30/200] Batch [211/391] Loss: 0.2887\n",
            "Epoch [30/200] Batch [212/391] Loss: 0.1206\n",
            "Epoch [30/200] Batch [213/391] Loss: 0.1198\n",
            "Epoch [30/200] Batch [214/391] Loss: 0.1647\n",
            "Epoch [30/200] Batch [215/391] Loss: 0.1601\n",
            "Epoch [30/200] Batch [216/391] Loss: 0.1639\n",
            "Epoch [30/200] Batch [217/391] Loss: 0.1353\n",
            "Epoch [30/200] Batch [218/391] Loss: 0.1465\n",
            "Epoch [30/200] Batch [219/391] Loss: 0.1295\n",
            "Epoch [30/200] Batch [220/391] Loss: 0.1498\n",
            "Epoch [30/200] Batch [221/391] Loss: 0.0931\n",
            "Epoch [30/200] Batch [222/391] Loss: 0.1575\n",
            "Epoch [30/200] Batch [223/391] Loss: 0.0818\n",
            "Epoch [30/200] Batch [224/391] Loss: 0.1270\n",
            "Epoch [30/200] Batch [225/391] Loss: 0.1124\n",
            "Epoch [30/200] Batch [226/391] Loss: 0.1333\n",
            "Epoch [30/200] Batch [227/391] Loss: 0.0845\n",
            "Epoch [30/200] Batch [228/391] Loss: 0.2529\n",
            "Epoch [30/200] Batch [229/391] Loss: 0.1919\n",
            "Epoch [30/200] Batch [230/391] Loss: 0.0777\n",
            "Epoch [30/200] Batch [231/391] Loss: 0.0908\n",
            "Epoch [30/200] Batch [232/391] Loss: 0.0542\n",
            "Epoch [30/200] Batch [233/391] Loss: 0.1983\n",
            "Epoch [30/200] Batch [234/391] Loss: 0.1665\n",
            "Epoch [30/200] Batch [235/391] Loss: 0.0862\n",
            "Epoch [30/200] Batch [236/391] Loss: 0.1562\n",
            "Epoch [30/200] Batch [237/391] Loss: 0.1205\n",
            "Epoch [30/200] Batch [238/391] Loss: 0.1078\n",
            "Epoch [30/200] Batch [239/391] Loss: 0.1342\n",
            "Epoch [30/200] Batch [240/391] Loss: 0.0598\n",
            "Epoch [30/200] Batch [241/391] Loss: 0.1213\n",
            "Epoch [30/200] Batch [242/391] Loss: 0.2135\n",
            "Epoch [30/200] Batch [243/391] Loss: 0.0857\n",
            "Epoch [30/200] Batch [244/391] Loss: 0.1755\n",
            "Epoch [30/200] Batch [245/391] Loss: 0.2144\n",
            "Epoch [30/200] Batch [246/391] Loss: 0.2525\n",
            "Epoch [30/200] Batch [247/391] Loss: 0.1618\n",
            "Epoch [30/200] Batch [248/391] Loss: 0.1288\n",
            "Epoch [30/200] Batch [249/391] Loss: 0.1429\n",
            "Epoch [30/200] Batch [250/391] Loss: 0.1482\n",
            "Epoch [30/200] Batch [251/391] Loss: 0.1522\n",
            "Epoch [30/200] Batch [252/391] Loss: 0.1641\n",
            "Epoch [30/200] Batch [253/391] Loss: 0.1238\n",
            "Epoch [30/200] Batch [254/391] Loss: 0.2134\n",
            "Epoch [30/200] Batch [255/391] Loss: 0.1541\n",
            "Epoch [30/200] Batch [256/391] Loss: 0.2363\n",
            "Epoch [30/200] Batch [257/391] Loss: 0.1741\n",
            "Epoch [30/200] Batch [258/391] Loss: 0.2541\n",
            "Epoch [30/200] Batch [259/391] Loss: 0.1944\n",
            "Epoch [30/200] Batch [260/391] Loss: 0.2451\n",
            "Epoch [30/200] Batch [261/391] Loss: 0.2737\n",
            "Epoch [30/200] Batch [262/391] Loss: 0.2043\n",
            "Epoch [30/200] Batch [263/391] Loss: 0.1120\n",
            "Epoch [30/200] Batch [264/391] Loss: 0.1502\n",
            "Epoch [30/200] Batch [265/391] Loss: 0.1155\n",
            "Epoch [30/200] Batch [266/391] Loss: 0.1077\n",
            "Epoch [30/200] Batch [267/391] Loss: 0.1218\n",
            "Epoch [30/200] Batch [268/391] Loss: 0.2181\n",
            "Epoch [30/200] Batch [269/391] Loss: 0.1968\n",
            "Epoch [30/200] Batch [270/391] Loss: 0.1673\n",
            "Epoch [30/200] Batch [271/391] Loss: 0.1925\n",
            "Epoch [30/200] Batch [272/391] Loss: 0.2312\n",
            "Epoch [30/200] Batch [273/391] Loss: 0.1368\n",
            "Epoch [30/200] Batch [274/391] Loss: 0.1853\n",
            "Epoch [30/200] Batch [275/391] Loss: 0.2255\n",
            "Epoch [30/200] Batch [276/391] Loss: 0.1309\n",
            "Epoch [30/200] Batch [277/391] Loss: 0.1703\n",
            "Epoch [30/200] Batch [278/391] Loss: 0.0891\n",
            "Epoch [30/200] Batch [279/391] Loss: 0.2336\n",
            "Epoch [30/200] Batch [280/391] Loss: 0.1452\n",
            "Epoch [30/200] Batch [281/391] Loss: 0.0858\n",
            "Epoch [30/200] Batch [282/391] Loss: 0.1367\n",
            "Epoch [30/200] Batch [283/391] Loss: 0.0663\n",
            "Epoch [30/200] Batch [284/391] Loss: 0.1531\n",
            "Epoch [30/200] Batch [285/391] Loss: 0.1471\n",
            "Epoch [30/200] Batch [286/391] Loss: 0.1877\n",
            "Epoch [30/200] Batch [287/391] Loss: 0.2031\n",
            "Epoch [30/200] Batch [288/391] Loss: 0.1760\n",
            "Epoch [30/200] Batch [289/391] Loss: 0.0862\n",
            "Epoch [30/200] Batch [290/391] Loss: 0.2045\n",
            "Epoch [30/200] Batch [291/391] Loss: 0.1104\n",
            "Epoch [30/200] Batch [292/391] Loss: 0.0915\n",
            "Epoch [30/200] Batch [293/391] Loss: 0.1065\n",
            "Epoch [30/200] Batch [294/391] Loss: 0.1369\n",
            "Epoch [30/200] Batch [295/391] Loss: 0.2022\n",
            "Epoch [30/200] Batch [296/391] Loss: 0.1566\n",
            "Epoch [30/200] Batch [297/391] Loss: 0.1692\n",
            "Epoch [30/200] Batch [298/391] Loss: 0.1427\n",
            "Epoch [30/200] Batch [299/391] Loss: 0.1549\n",
            "Epoch [30/200] Batch [300/391] Loss: 0.1300\n",
            "Epoch [30/200] Batch [301/391] Loss: 0.2987\n",
            "Epoch [30/200] Batch [302/391] Loss: 0.1746\n",
            "Epoch [30/200] Batch [303/391] Loss: 0.1697\n",
            "Epoch [30/200] Batch [304/391] Loss: 0.2376\n",
            "Epoch [30/200] Batch [305/391] Loss: 0.1134\n",
            "Epoch [30/200] Batch [306/391] Loss: 0.1506\n",
            "Epoch [30/200] Batch [307/391] Loss: 0.2390\n",
            "Epoch [30/200] Batch [308/391] Loss: 0.1618\n",
            "Epoch [30/200] Batch [309/391] Loss: 0.1550\n",
            "Epoch [30/200] Batch [310/391] Loss: 0.1441\n",
            "Epoch [30/200] Batch [311/391] Loss: 0.1402\n",
            "Epoch [30/200] Batch [312/391] Loss: 0.1287\n",
            "Epoch [30/200] Batch [313/391] Loss: 0.1026\n",
            "Epoch [30/200] Batch [314/391] Loss: 0.0898\n",
            "Epoch [30/200] Batch [315/391] Loss: 0.1138\n",
            "Epoch [30/200] Batch [316/391] Loss: 0.1963\n",
            "Epoch [30/200] Batch [317/391] Loss: 0.1098\n",
            "Epoch [30/200] Batch [318/391] Loss: 0.2278\n",
            "Epoch [30/200] Batch [319/391] Loss: 0.1567\n",
            "Epoch [30/200] Batch [320/391] Loss: 0.1949\n",
            "Epoch [30/200] Batch [321/391] Loss: 0.1198\n",
            "Epoch [30/200] Batch [322/391] Loss: 0.1466\n",
            "Epoch [30/200] Batch [323/391] Loss: 0.2797\n",
            "Epoch [30/200] Batch [324/391] Loss: 0.1365\n",
            "Epoch [30/200] Batch [325/391] Loss: 0.1537\n",
            "Epoch [30/200] Batch [326/391] Loss: 0.1698\n",
            "Epoch [30/200] Batch [327/391] Loss: 0.2384\n",
            "Epoch [30/200] Batch [328/391] Loss: 0.1337\n",
            "Epoch [30/200] Batch [329/391] Loss: 0.1533\n",
            "Epoch [30/200] Batch [330/391] Loss: 0.1497\n",
            "Epoch [30/200] Batch [331/391] Loss: 0.1546\n",
            "Epoch [30/200] Batch [332/391] Loss: 0.1830\n",
            "Epoch [30/200] Batch [333/391] Loss: 0.1730\n",
            "Epoch [30/200] Batch [334/391] Loss: 0.1920\n",
            "Epoch [30/200] Batch [335/391] Loss: 0.1775\n",
            "Epoch [30/200] Batch [336/391] Loss: 0.1712\n",
            "Epoch [30/200] Batch [337/391] Loss: 0.1805\n",
            "Epoch [30/200] Batch [338/391] Loss: 0.1476\n",
            "Epoch [30/200] Batch [339/391] Loss: 0.1057\n",
            "Epoch [30/200] Batch [340/391] Loss: 0.1980\n",
            "Epoch [30/200] Batch [341/391] Loss: 0.1256\n",
            "Epoch [30/200] Batch [342/391] Loss: 0.1441\n",
            "Epoch [30/200] Batch [343/391] Loss: 0.2738\n",
            "Epoch [30/200] Batch [344/391] Loss: 0.1838\n",
            "Epoch [30/200] Batch [345/391] Loss: 0.2306\n",
            "Epoch [30/200] Batch [346/391] Loss: 0.1227\n",
            "Epoch [30/200] Batch [347/391] Loss: 0.1573\n",
            "Epoch [30/200] Batch [348/391] Loss: 0.1554\n",
            "Epoch [30/200] Batch [349/391] Loss: 0.0853\n",
            "Epoch [30/200] Batch [350/391] Loss: 0.1696\n",
            "Epoch [30/200] Batch [351/391] Loss: 0.1441\n",
            "Epoch [30/200] Batch [352/391] Loss: 0.1906\n",
            "Epoch [30/200] Batch [353/391] Loss: 0.1614\n",
            "Epoch [30/200] Batch [354/391] Loss: 0.1733\n",
            "Epoch [30/200] Batch [355/391] Loss: 0.2324\n",
            "Epoch [30/200] Batch [356/391] Loss: 0.1650\n",
            "Epoch [30/200] Batch [357/391] Loss: 0.2812\n",
            "Epoch [30/200] Batch [358/391] Loss: 0.1417\n",
            "Epoch [30/200] Batch [359/391] Loss: 0.1342\n",
            "Epoch [30/200] Batch [360/391] Loss: 0.2230\n",
            "Epoch [30/200] Batch [361/391] Loss: 0.1152\n",
            "Epoch [30/200] Batch [362/391] Loss: 0.0659\n",
            "Epoch [30/200] Batch [363/391] Loss: 0.1913\n",
            "Epoch [30/200] Batch [364/391] Loss: 0.2266\n",
            "Epoch [30/200] Batch [365/391] Loss: 0.1946\n",
            "Epoch [30/200] Batch [366/391] Loss: 0.2457\n",
            "Epoch [30/200] Batch [367/391] Loss: 0.2242\n",
            "Epoch [30/200] Batch [368/391] Loss: 0.1116\n",
            "Epoch [30/200] Batch [369/391] Loss: 0.1997\n",
            "Epoch [30/200] Batch [370/391] Loss: 0.2651\n",
            "Epoch [30/200] Batch [371/391] Loss: 0.1063\n",
            "Epoch [30/200] Batch [372/391] Loss: 0.3214\n",
            "Epoch [30/200] Batch [373/391] Loss: 0.0860\n",
            "Epoch [30/200] Batch [374/391] Loss: 0.2316\n",
            "Epoch [30/200] Batch [375/391] Loss: 0.1848\n",
            "Epoch [30/200] Batch [376/391] Loss: 0.1441\n",
            "Epoch [30/200] Batch [377/391] Loss: 0.1787\n",
            "Epoch [30/200] Batch [378/391] Loss: 0.3254\n",
            "Epoch [30/200] Batch [379/391] Loss: 0.1676\n",
            "Epoch [30/200] Batch [380/391] Loss: 0.1592\n",
            "Epoch [30/200] Batch [381/391] Loss: 0.1565\n",
            "Epoch [30/200] Batch [382/391] Loss: 0.1720\n",
            "Epoch [30/200] Batch [383/391] Loss: 0.1527\n",
            "Epoch [30/200] Batch [384/391] Loss: 0.1194\n",
            "Epoch [30/200] Batch [385/391] Loss: 0.1365\n",
            "Epoch [30/200] Batch [386/391] Loss: 0.1167\n",
            "Epoch [30/200] Batch [387/391] Loss: 0.1590\n",
            "Epoch [30/200] Batch [388/391] Loss: 0.2038\n",
            "Epoch [30/200] Batch [389/391] Loss: 0.2653\n",
            "Epoch [30/200] Batch [390/391] Loss: 0.3058\n",
            "Epoch [30/200] Batch [391/391] Loss: 0.1266\n",
            "Epoch [30/200] - Train Loss: 0.1396 - Test Loss: 1.7408 - Train Acc: 70.18% - Test Acc: 64.11%\n",
            "Epoch [31/200] Batch [1/391] Loss: 0.1841\n",
            "Epoch [31/200] Batch [2/391] Loss: 0.1630\n",
            "Epoch [31/200] Batch [3/391] Loss: 0.1118\n",
            "Epoch [31/200] Batch [4/391] Loss: 0.1026\n",
            "Epoch [31/200] Batch [5/391] Loss: 0.1553\n",
            "Epoch [31/200] Batch [6/391] Loss: 0.0904\n",
            "Epoch [31/200] Batch [7/391] Loss: 0.2151\n",
            "Epoch [31/200] Batch [8/391] Loss: 0.1739\n",
            "Epoch [31/200] Batch [9/391] Loss: 0.1454\n",
            "Epoch [31/200] Batch [10/391] Loss: 0.1034\n",
            "Epoch [31/200] Batch [11/391] Loss: 0.1041\n",
            "Epoch [31/200] Batch [12/391] Loss: 0.1655\n",
            "Epoch [31/200] Batch [13/391] Loss: 0.1732\n",
            "Epoch [31/200] Batch [14/391] Loss: 0.1618\n",
            "Epoch [31/200] Batch [15/391] Loss: 0.1546\n",
            "Epoch [31/200] Batch [16/391] Loss: 0.1008\n",
            "Epoch [31/200] Batch [17/391] Loss: 0.1366\n",
            "Epoch [31/200] Batch [18/391] Loss: 0.1199\n",
            "Epoch [31/200] Batch [19/391] Loss: 0.1012\n",
            "Epoch [31/200] Batch [20/391] Loss: 0.1559\n",
            "Epoch [31/200] Batch [21/391] Loss: 0.1378\n",
            "Epoch [31/200] Batch [22/391] Loss: 0.0871\n",
            "Epoch [31/200] Batch [23/391] Loss: 0.1277\n",
            "Epoch [31/200] Batch [24/391] Loss: 0.2254\n",
            "Epoch [31/200] Batch [25/391] Loss: 0.0836\n",
            "Epoch [31/200] Batch [26/391] Loss: 0.1413\n",
            "Epoch [31/200] Batch [27/391] Loss: 0.0835\n",
            "Epoch [31/200] Batch [28/391] Loss: 0.2079\n",
            "Epoch [31/200] Batch [29/391] Loss: 0.0789\n",
            "Epoch [31/200] Batch [30/391] Loss: 0.0862\n",
            "Epoch [31/200] Batch [31/391] Loss: 0.0973\n",
            "Epoch [31/200] Batch [32/391] Loss: 0.1818\n",
            "Epoch [31/200] Batch [33/391] Loss: 0.1376\n",
            "Epoch [31/200] Batch [34/391] Loss: 0.1285\n",
            "Epoch [31/200] Batch [35/391] Loss: 0.1006\n",
            "Epoch [31/200] Batch [36/391] Loss: 0.1189\n",
            "Epoch [31/200] Batch [37/391] Loss: 0.1785\n",
            "Epoch [31/200] Batch [38/391] Loss: 0.0934\n",
            "Epoch [31/200] Batch [39/391] Loss: 0.0861\n",
            "Epoch [31/200] Batch [40/391] Loss: 0.1904\n",
            "Epoch [31/200] Batch [41/391] Loss: 0.1032\n",
            "Epoch [31/200] Batch [42/391] Loss: 0.0487\n",
            "Epoch [31/200] Batch [43/391] Loss: 0.1028\n",
            "Epoch [31/200] Batch [44/391] Loss: 0.1255\n",
            "Epoch [31/200] Batch [45/391] Loss: 0.1173\n",
            "Epoch [31/200] Batch [46/391] Loss: 0.0960\n",
            "Epoch [31/200] Batch [47/391] Loss: 0.0649\n",
            "Epoch [31/200] Batch [48/391] Loss: 0.0953\n",
            "Epoch [31/200] Batch [49/391] Loss: 0.1331\n",
            "Epoch [31/200] Batch [50/391] Loss: 0.1512\n",
            "Epoch [31/200] Batch [51/391] Loss: 0.0704\n",
            "Epoch [31/200] Batch [52/391] Loss: 0.2164\n",
            "Epoch [31/200] Batch [53/391] Loss: 0.0784\n",
            "Epoch [31/200] Batch [54/391] Loss: 0.1008\n",
            "Epoch [31/200] Batch [55/391] Loss: 0.1389\n",
            "Epoch [31/200] Batch [56/391] Loss: 0.0792\n",
            "Epoch [31/200] Batch [57/391] Loss: 0.0824\n",
            "Epoch [31/200] Batch [58/391] Loss: 0.1312\n",
            "Epoch [31/200] Batch [59/391] Loss: 0.0677\n",
            "Epoch [31/200] Batch [60/391] Loss: 0.0579\n",
            "Epoch [31/200] Batch [61/391] Loss: 0.0441\n",
            "Epoch [31/200] Batch [62/391] Loss: 0.0822\n",
            "Epoch [31/200] Batch [63/391] Loss: 0.1196\n",
            "Epoch [31/200] Batch [64/391] Loss: 0.0963\n",
            "Epoch [31/200] Batch [65/391] Loss: 0.0961\n",
            "Epoch [31/200] Batch [66/391] Loss: 0.0549\n",
            "Epoch [31/200] Batch [67/391] Loss: 0.1324\n",
            "Epoch [31/200] Batch [68/391] Loss: 0.1512\n",
            "Epoch [31/200] Batch [69/391] Loss: 0.1128\n",
            "Epoch [31/200] Batch [70/391] Loss: 0.0861\n",
            "Epoch [31/200] Batch [71/391] Loss: 0.1267\n",
            "Epoch [31/200] Batch [72/391] Loss: 0.0738\n",
            "Epoch [31/200] Batch [73/391] Loss: 0.0903\n",
            "Epoch [31/200] Batch [74/391] Loss: 0.1496\n",
            "Epoch [31/200] Batch [75/391] Loss: 0.0842\n",
            "Epoch [31/200] Batch [76/391] Loss: 0.1215\n",
            "Epoch [31/200] Batch [77/391] Loss: 0.0974\n",
            "Epoch [31/200] Batch [78/391] Loss: 0.0783\n",
            "Epoch [31/200] Batch [79/391] Loss: 0.0555\n",
            "Epoch [31/200] Batch [80/391] Loss: 0.0793\n",
            "Epoch [31/200] Batch [81/391] Loss: 0.1586\n",
            "Epoch [31/200] Batch [82/391] Loss: 0.0699\n",
            "Epoch [31/200] Batch [83/391] Loss: 0.1136\n",
            "Epoch [31/200] Batch [84/391] Loss: 0.0633\n",
            "Epoch [31/200] Batch [85/391] Loss: 0.1090\n",
            "Epoch [31/200] Batch [86/391] Loss: 0.0894\n",
            "Epoch [31/200] Batch [87/391] Loss: 0.0780\n",
            "Epoch [31/200] Batch [88/391] Loss: 0.1124\n",
            "Epoch [31/200] Batch [89/391] Loss: 0.1037\n",
            "Epoch [31/200] Batch [90/391] Loss: 0.0870\n",
            "Epoch [31/200] Batch [91/391] Loss: 0.0497\n",
            "Epoch [31/200] Batch [92/391] Loss: 0.1345\n",
            "Epoch [31/200] Batch [93/391] Loss: 0.1325\n",
            "Epoch [31/200] Batch [94/391] Loss: 0.0492\n",
            "Epoch [31/200] Batch [95/391] Loss: 0.0820\n",
            "Epoch [31/200] Batch [96/391] Loss: 0.1065\n",
            "Epoch [31/200] Batch [97/391] Loss: 0.1538\n",
            "Epoch [31/200] Batch [98/391] Loss: 0.1267\n",
            "Epoch [31/200] Batch [99/391] Loss: 0.0715\n",
            "Epoch [31/200] Batch [100/391] Loss: 0.1136\n",
            "Epoch [31/200] Batch [101/391] Loss: 0.1606\n",
            "Epoch [31/200] Batch [102/391] Loss: 0.0543\n",
            "Epoch [31/200] Batch [103/391] Loss: 0.1231\n",
            "Epoch [31/200] Batch [104/391] Loss: 0.0866\n",
            "Epoch [31/200] Batch [105/391] Loss: 0.0856\n",
            "Epoch [31/200] Batch [106/391] Loss: 0.1086\n",
            "Epoch [31/200] Batch [107/391] Loss: 0.0607\n",
            "Epoch [31/200] Batch [108/391] Loss: 0.1047\n",
            "Epoch [31/200] Batch [109/391] Loss: 0.1085\n",
            "Epoch [31/200] Batch [110/391] Loss: 0.1058\n",
            "Epoch [31/200] Batch [111/391] Loss: 0.1190\n",
            "Epoch [31/200] Batch [112/391] Loss: 0.0926\n",
            "Epoch [31/200] Batch [113/391] Loss: 0.0815\n",
            "Epoch [31/200] Batch [114/391] Loss: 0.1361\n",
            "Epoch [31/200] Batch [115/391] Loss: 0.1305\n",
            "Epoch [31/200] Batch [116/391] Loss: 0.0722\n",
            "Epoch [31/200] Batch [117/391] Loss: 0.1112\n",
            "Epoch [31/200] Batch [118/391] Loss: 0.0535\n",
            "Epoch [31/200] Batch [119/391] Loss: 0.0738\n",
            "Epoch [31/200] Batch [120/391] Loss: 0.0380\n",
            "Epoch [31/200] Batch [121/391] Loss: 0.0668\n",
            "Epoch [31/200] Batch [122/391] Loss: 0.1358\n",
            "Epoch [31/200] Batch [123/391] Loss: 0.1290\n",
            "Epoch [31/200] Batch [124/391] Loss: 0.0819\n",
            "Epoch [31/200] Batch [125/391] Loss: 0.1140\n",
            "Epoch [31/200] Batch [126/391] Loss: 0.1466\n",
            "Epoch [31/200] Batch [127/391] Loss: 0.1203\n",
            "Epoch [31/200] Batch [128/391] Loss: 0.2215\n",
            "Epoch [31/200] Batch [129/391] Loss: 0.1099\n",
            "Epoch [31/200] Batch [130/391] Loss: 0.1075\n",
            "Epoch [31/200] Batch [131/391] Loss: 0.0955\n",
            "Epoch [31/200] Batch [132/391] Loss: 0.0363\n",
            "Epoch [31/200] Batch [133/391] Loss: 0.0956\n",
            "Epoch [31/200] Batch [134/391] Loss: 0.0712\n",
            "Epoch [31/200] Batch [135/391] Loss: 0.1194\n",
            "Epoch [31/200] Batch [136/391] Loss: 0.0673\n",
            "Epoch [31/200] Batch [137/391] Loss: 0.1517\n",
            "Epoch [31/200] Batch [138/391] Loss: 0.1256\n",
            "Epoch [31/200] Batch [139/391] Loss: 0.1735\n",
            "Epoch [31/200] Batch [140/391] Loss: 0.2182\n",
            "Epoch [31/200] Batch [141/391] Loss: 0.1602\n",
            "Epoch [31/200] Batch [142/391] Loss: 0.1109\n",
            "Epoch [31/200] Batch [143/391] Loss: 0.1324\n",
            "Epoch [31/200] Batch [144/391] Loss: 0.2128\n",
            "Epoch [31/200] Batch [145/391] Loss: 0.1109\n",
            "Epoch [31/200] Batch [146/391] Loss: 0.1312\n",
            "Epoch [31/200] Batch [147/391] Loss: 0.1016\n",
            "Epoch [31/200] Batch [148/391] Loss: 0.1850\n",
            "Epoch [31/200] Batch [149/391] Loss: 0.0934\n",
            "Epoch [31/200] Batch [150/391] Loss: 0.0692\n",
            "Epoch [31/200] Batch [151/391] Loss: 0.1096\n",
            "Epoch [31/200] Batch [152/391] Loss: 0.0830\n",
            "Epoch [31/200] Batch [153/391] Loss: 0.1934\n",
            "Epoch [31/200] Batch [154/391] Loss: 0.0599\n",
            "Epoch [31/200] Batch [155/391] Loss: 0.0940\n",
            "Epoch [31/200] Batch [156/391] Loss: 0.2007\n",
            "Epoch [31/200] Batch [157/391] Loss: 0.1571\n",
            "Epoch [31/200] Batch [158/391] Loss: 0.1946\n",
            "Epoch [31/200] Batch [159/391] Loss: 0.2053\n",
            "Epoch [31/200] Batch [160/391] Loss: 0.1003\n",
            "Epoch [31/200] Batch [161/391] Loss: 0.1238\n",
            "Epoch [31/200] Batch [162/391] Loss: 0.1390\n",
            "Epoch [31/200] Batch [163/391] Loss: 0.1397\n",
            "Epoch [31/200] Batch [164/391] Loss: 0.0833\n",
            "Epoch [31/200] Batch [165/391] Loss: 0.1918\n",
            "Epoch [31/200] Batch [166/391] Loss: 0.1905\n",
            "Epoch [31/200] Batch [167/391] Loss: 0.1108\n",
            "Epoch [31/200] Batch [168/391] Loss: 0.1893\n",
            "Epoch [31/200] Batch [169/391] Loss: 0.1240\n",
            "Epoch [31/200] Batch [170/391] Loss: 0.2594\n",
            "Epoch [31/200] Batch [171/391] Loss: 0.1770\n",
            "Epoch [31/200] Batch [172/391] Loss: 0.1000\n",
            "Epoch [31/200] Batch [173/391] Loss: 0.0862\n",
            "Epoch [31/200] Batch [174/391] Loss: 0.1319\n",
            "Epoch [31/200] Batch [175/391] Loss: 0.0842\n",
            "Epoch [31/200] Batch [176/391] Loss: 0.1628\n",
            "Epoch [31/200] Batch [177/391] Loss: 0.0996\n",
            "Epoch [31/200] Batch [178/391] Loss: 0.2098\n",
            "Epoch [31/200] Batch [179/391] Loss: 0.1135\n",
            "Epoch [31/200] Batch [180/391] Loss: 0.1456\n",
            "Epoch [31/200] Batch [181/391] Loss: 0.1129\n",
            "Epoch [31/200] Batch [182/391] Loss: 0.1027\n",
            "Epoch [31/200] Batch [183/391] Loss: 0.1459\n",
            "Epoch [31/200] Batch [184/391] Loss: 0.1373\n",
            "Epoch [31/200] Batch [185/391] Loss: 0.0963\n",
            "Epoch [31/200] Batch [186/391] Loss: 0.1380\n",
            "Epoch [31/200] Batch [187/391] Loss: 0.1641\n",
            "Epoch [31/200] Batch [188/391] Loss: 0.1449\n",
            "Epoch [31/200] Batch [189/391] Loss: 0.2001\n",
            "Epoch [31/200] Batch [190/391] Loss: 0.1101\n",
            "Epoch [31/200] Batch [191/391] Loss: 0.2012\n",
            "Epoch [31/200] Batch [192/391] Loss: 0.0912\n",
            "Epoch [31/200] Batch [193/391] Loss: 0.1936\n",
            "Epoch [31/200] Batch [194/391] Loss: 0.1789\n",
            "Epoch [31/200] Batch [195/391] Loss: 0.1798\n",
            "Epoch [31/200] Batch [196/391] Loss: 0.1167\n",
            "Epoch [31/200] Batch [197/391] Loss: 0.1556\n",
            "Epoch [31/200] Batch [198/391] Loss: 0.0962\n",
            "Epoch [31/200] Batch [199/391] Loss: 0.1792\n",
            "Epoch [31/200] Batch [200/391] Loss: 0.1392\n",
            "Epoch [31/200] Batch [201/391] Loss: 0.0974\n",
            "Epoch [31/200] Batch [202/391] Loss: 0.1314\n",
            "Epoch [31/200] Batch [203/391] Loss: 0.1408\n",
            "Epoch [31/200] Batch [204/391] Loss: 0.0978\n",
            "Epoch [31/200] Batch [205/391] Loss: 0.1374\n",
            "Epoch [31/200] Batch [206/391] Loss: 0.1072\n",
            "Epoch [31/200] Batch [207/391] Loss: 0.1616\n",
            "Epoch [31/200] Batch [208/391] Loss: 0.0821\n",
            "Epoch [31/200] Batch [209/391] Loss: 0.1343\n",
            "Epoch [31/200] Batch [210/391] Loss: 0.1079\n",
            "Epoch [31/200] Batch [211/391] Loss: 0.1681\n",
            "Epoch [31/200] Batch [212/391] Loss: 0.1053\n",
            "Epoch [31/200] Batch [213/391] Loss: 0.2670\n",
            "Epoch [31/200] Batch [214/391] Loss: 0.1787\n",
            "Epoch [31/200] Batch [215/391] Loss: 0.1278\n",
            "Epoch [31/200] Batch [216/391] Loss: 0.1476\n",
            "Epoch [31/200] Batch [217/391] Loss: 0.1075\n",
            "Epoch [31/200] Batch [218/391] Loss: 0.1330\n",
            "Epoch [31/200] Batch [219/391] Loss: 0.1124\n",
            "Epoch [31/200] Batch [220/391] Loss: 0.1673\n",
            "Epoch [31/200] Batch [221/391] Loss: 0.0929\n",
            "Epoch [31/200] Batch [222/391] Loss: 0.1866\n",
            "Epoch [31/200] Batch [223/391] Loss: 0.0957\n",
            "Epoch [31/200] Batch [224/391] Loss: 0.1332\n",
            "Epoch [31/200] Batch [225/391] Loss: 0.2478\n",
            "Epoch [31/200] Batch [226/391] Loss: 0.1762\n",
            "Epoch [31/200] Batch [227/391] Loss: 0.1628\n",
            "Epoch [31/200] Batch [228/391] Loss: 0.1365\n",
            "Epoch [31/200] Batch [229/391] Loss: 0.2008\n",
            "Epoch [31/200] Batch [230/391] Loss: 0.0855\n",
            "Epoch [31/200] Batch [231/391] Loss: 0.0894\n",
            "Epoch [31/200] Batch [232/391] Loss: 0.1962\n",
            "Epoch [31/200] Batch [233/391] Loss: 0.1271\n",
            "Epoch [31/200] Batch [234/391] Loss: 0.0928\n",
            "Epoch [31/200] Batch [235/391] Loss: 0.1289\n",
            "Epoch [31/200] Batch [236/391] Loss: 0.1895\n",
            "Epoch [31/200] Batch [237/391] Loss: 0.1767\n",
            "Epoch [31/200] Batch [238/391] Loss: 0.1957\n",
            "Epoch [31/200] Batch [239/391] Loss: 0.1337\n",
            "Epoch [31/200] Batch [240/391] Loss: 0.1251\n",
            "Epoch [31/200] Batch [241/391] Loss: 0.0667\n",
            "Epoch [31/200] Batch [242/391] Loss: 0.1985\n",
            "Epoch [31/200] Batch [243/391] Loss: 0.1622\n",
            "Epoch [31/200] Batch [244/391] Loss: 0.0728\n",
            "Epoch [31/200] Batch [245/391] Loss: 0.1181\n",
            "Epoch [31/200] Batch [246/391] Loss: 0.2185\n",
            "Epoch [31/200] Batch [247/391] Loss: 0.1876\n",
            "Epoch [31/200] Batch [248/391] Loss: 0.1419\n",
            "Epoch [31/200] Batch [249/391] Loss: 0.0867\n",
            "Epoch [31/200] Batch [250/391] Loss: 0.1437\n",
            "Epoch [31/200] Batch [251/391] Loss: 0.1135\n",
            "Epoch [31/200] Batch [252/391] Loss: 0.0695\n",
            "Epoch [31/200] Batch [253/391] Loss: 0.1483\n",
            "Epoch [31/200] Batch [254/391] Loss: 0.1178\n",
            "Epoch [31/200] Batch [255/391] Loss: 0.0993\n",
            "Epoch [31/200] Batch [256/391] Loss: 0.1265\n",
            "Epoch [31/200] Batch [257/391] Loss: 0.2058\n",
            "Epoch [31/200] Batch [258/391] Loss: 0.1174\n",
            "Epoch [31/200] Batch [259/391] Loss: 0.1253\n",
            "Epoch [31/200] Batch [260/391] Loss: 0.1348\n",
            "Epoch [31/200] Batch [261/391] Loss: 0.1666\n",
            "Epoch [31/200] Batch [262/391] Loss: 0.2171\n",
            "Epoch [31/200] Batch [263/391] Loss: 0.2099\n",
            "Epoch [31/200] Batch [264/391] Loss: 0.0621\n",
            "Epoch [31/200] Batch [265/391] Loss: 0.0649\n",
            "Epoch [31/200] Batch [266/391] Loss: 0.1126\n",
            "Epoch [31/200] Batch [267/391] Loss: 0.1909\n",
            "Epoch [31/200] Batch [268/391] Loss: 0.2261\n",
            "Epoch [31/200] Batch [269/391] Loss: 0.1499\n",
            "Epoch [31/200] Batch [270/391] Loss: 0.0978\n",
            "Epoch [31/200] Batch [271/391] Loss: 0.0972\n",
            "Epoch [31/200] Batch [272/391] Loss: 0.2159\n",
            "Epoch [31/200] Batch [273/391] Loss: 0.1192\n",
            "Epoch [31/200] Batch [274/391] Loss: 0.1790\n",
            "Epoch [31/200] Batch [275/391] Loss: 0.0841\n",
            "Epoch [31/200] Batch [276/391] Loss: 0.1226\n",
            "Epoch [31/200] Batch [277/391] Loss: 0.1072\n",
            "Epoch [31/200] Batch [278/391] Loss: 0.1426\n",
            "Epoch [31/200] Batch [279/391] Loss: 0.1018\n",
            "Epoch [31/200] Batch [280/391] Loss: 0.1317\n",
            "Epoch [31/200] Batch [281/391] Loss: 0.2693\n",
            "Epoch [31/200] Batch [282/391] Loss: 0.0676\n",
            "Epoch [31/200] Batch [283/391] Loss: 0.1604\n",
            "Epoch [31/200] Batch [284/391] Loss: 0.1137\n",
            "Epoch [31/200] Batch [285/391] Loss: 0.1485\n",
            "Epoch [31/200] Batch [286/391] Loss: 0.1812\n",
            "Epoch [31/200] Batch [287/391] Loss: 0.1564\n",
            "Epoch [31/200] Batch [288/391] Loss: 0.1311\n",
            "Epoch [31/200] Batch [289/391] Loss: 0.2602\n",
            "Epoch [31/200] Batch [290/391] Loss: 0.1497\n",
            "Epoch [31/200] Batch [291/391] Loss: 0.1853\n",
            "Epoch [31/200] Batch [292/391] Loss: 0.1208\n",
            "Epoch [31/200] Batch [293/391] Loss: 0.1065\n",
            "Epoch [31/200] Batch [294/391] Loss: 0.1565\n",
            "Epoch [31/200] Batch [295/391] Loss: 0.1792\n",
            "Epoch [31/200] Batch [296/391] Loss: 0.1435\n",
            "Epoch [31/200] Batch [297/391] Loss: 0.0918\n",
            "Epoch [31/200] Batch [298/391] Loss: 0.0835\n",
            "Epoch [31/200] Batch [299/391] Loss: 0.1263\n",
            "Epoch [31/200] Batch [300/391] Loss: 0.1123\n",
            "Epoch [31/200] Batch [301/391] Loss: 0.1131\n",
            "Epoch [31/200] Batch [302/391] Loss: 0.1404\n",
            "Epoch [31/200] Batch [303/391] Loss: 0.1245\n",
            "Epoch [31/200] Batch [304/391] Loss: 0.1062\n",
            "Epoch [31/200] Batch [305/391] Loss: 0.1266\n",
            "Epoch [31/200] Batch [306/391] Loss: 0.1418\n",
            "Epoch [31/200] Batch [307/391] Loss: 0.1303\n",
            "Epoch [31/200] Batch [308/391] Loss: 0.0870\n",
            "Epoch [31/200] Batch [309/391] Loss: 0.0853\n",
            "Epoch [31/200] Batch [310/391] Loss: 0.1368\n",
            "Epoch [31/200] Batch [311/391] Loss: 0.0778\n",
            "Epoch [31/200] Batch [312/391] Loss: 0.1628\n",
            "Epoch [31/200] Batch [313/391] Loss: 0.1736\n",
            "Epoch [31/200] Batch [314/391] Loss: 0.1343\n",
            "Epoch [31/200] Batch [315/391] Loss: 0.1048\n",
            "Epoch [31/200] Batch [316/391] Loss: 0.0470\n",
            "Epoch [31/200] Batch [317/391] Loss: 0.1625\n",
            "Epoch [31/200] Batch [318/391] Loss: 0.1522\n",
            "Epoch [31/200] Batch [319/391] Loss: 0.1447\n",
            "Epoch [31/200] Batch [320/391] Loss: 0.0938\n",
            "Epoch [31/200] Batch [321/391] Loss: 0.1644\n",
            "Epoch [31/200] Batch [322/391] Loss: 0.1713\n",
            "Epoch [31/200] Batch [323/391] Loss: 0.2106\n",
            "Epoch [31/200] Batch [324/391] Loss: 0.1476\n",
            "Epoch [31/200] Batch [325/391] Loss: 0.1239\n",
            "Epoch [31/200] Batch [326/391] Loss: 0.0987\n",
            "Epoch [31/200] Batch [327/391] Loss: 0.1542\n",
            "Epoch [31/200] Batch [328/391] Loss: 0.1382\n",
            "Epoch [31/200] Batch [329/391] Loss: 0.1502\n",
            "Epoch [31/200] Batch [330/391] Loss: 0.1238\n",
            "Epoch [31/200] Batch [331/391] Loss: 0.1431\n",
            "Epoch [31/200] Batch [332/391] Loss: 0.1841\n",
            "Epoch [31/200] Batch [333/391] Loss: 0.1547\n",
            "Epoch [31/200] Batch [334/391] Loss: 0.1596\n",
            "Epoch [31/200] Batch [335/391] Loss: 0.0994\n",
            "Epoch [31/200] Batch [336/391] Loss: 0.1377\n",
            "Epoch [31/200] Batch [337/391] Loss: 0.1504\n",
            "Epoch [31/200] Batch [338/391] Loss: 0.0846\n",
            "Epoch [31/200] Batch [339/391] Loss: 0.1159\n",
            "Epoch [31/200] Batch [340/391] Loss: 0.1701\n",
            "Epoch [31/200] Batch [341/391] Loss: 0.2438\n",
            "Epoch [31/200] Batch [342/391] Loss: 0.2179\n",
            "Epoch [31/200] Batch [343/391] Loss: 0.1121\n",
            "Epoch [31/200] Batch [344/391] Loss: 0.2619\n",
            "Epoch [31/200] Batch [345/391] Loss: 0.0652\n",
            "Epoch [31/200] Batch [346/391] Loss: 0.1864\n",
            "Epoch [31/200] Batch [347/391] Loss: 0.2036\n",
            "Epoch [31/200] Batch [348/391] Loss: 0.1249\n",
            "Epoch [31/200] Batch [349/391] Loss: 0.1548\n",
            "Epoch [31/200] Batch [350/391] Loss: 0.1015\n",
            "Epoch [31/200] Batch [351/391] Loss: 0.0952\n",
            "Epoch [31/200] Batch [352/391] Loss: 0.1433\n",
            "Epoch [31/200] Batch [353/391] Loss: 0.1514\n",
            "Epoch [31/200] Batch [354/391] Loss: 0.1133\n",
            "Epoch [31/200] Batch [355/391] Loss: 0.1535\n",
            "Epoch [31/200] Batch [356/391] Loss: 0.1255\n",
            "Epoch [31/200] Batch [357/391] Loss: 0.2135\n",
            "Epoch [31/200] Batch [358/391] Loss: 0.1090\n",
            "Epoch [31/200] Batch [359/391] Loss: 0.1539\n",
            "Epoch [31/200] Batch [360/391] Loss: 0.1507\n",
            "Epoch [31/200] Batch [361/391] Loss: 0.1592\n",
            "Epoch [31/200] Batch [362/391] Loss: 0.1592\n",
            "Epoch [31/200] Batch [363/391] Loss: 0.1320\n",
            "Epoch [31/200] Batch [364/391] Loss: 0.1225\n",
            "Epoch [31/200] Batch [365/391] Loss: 0.2080\n",
            "Epoch [31/200] Batch [366/391] Loss: 0.1113\n",
            "Epoch [31/200] Batch [367/391] Loss: 0.1755\n",
            "Epoch [31/200] Batch [368/391] Loss: 0.0912\n",
            "Epoch [31/200] Batch [369/391] Loss: 0.1681\n",
            "Epoch [31/200] Batch [370/391] Loss: 0.1840\n",
            "Epoch [31/200] Batch [371/391] Loss: 0.0822\n",
            "Epoch [31/200] Batch [372/391] Loss: 0.0932\n",
            "Epoch [31/200] Batch [373/391] Loss: 0.0976\n",
            "Epoch [31/200] Batch [374/391] Loss: 0.1285\n",
            "Epoch [31/200] Batch [375/391] Loss: 0.0996\n",
            "Epoch [31/200] Batch [376/391] Loss: 0.1106\n",
            "Epoch [31/200] Batch [377/391] Loss: 0.1646\n",
            "Epoch [31/200] Batch [378/391] Loss: 0.0687\n",
            "Epoch [31/200] Batch [379/391] Loss: 0.1552\n",
            "Epoch [31/200] Batch [380/391] Loss: 0.1444\n",
            "Epoch [31/200] Batch [381/391] Loss: 0.2008\n",
            "Epoch [31/200] Batch [382/391] Loss: 0.2614\n",
            "Epoch [31/200] Batch [383/391] Loss: 0.1630\n",
            "Epoch [31/200] Batch [384/391] Loss: 0.1300\n",
            "Epoch [31/200] Batch [385/391] Loss: 0.1346\n",
            "Epoch [31/200] Batch [386/391] Loss: 0.0939\n",
            "Epoch [31/200] Batch [387/391] Loss: 0.1109\n",
            "Epoch [31/200] Batch [388/391] Loss: 0.2419\n",
            "Epoch [31/200] Batch [389/391] Loss: 0.1543\n",
            "Epoch [31/200] Batch [390/391] Loss: 0.1608\n",
            "Epoch [31/200] Batch [391/391] Loss: 0.2083\n",
            "Epoch [31/200] - Train Loss: 0.1308 - Test Loss: 1.0842 - Train Acc: 81.85% - Test Acc: 74.25%\n",
            "Epoch [32/200] Batch [1/391] Loss: 0.1099\n",
            "Epoch [32/200] Batch [2/391] Loss: 0.0739\n",
            "Epoch [32/200] Batch [3/391] Loss: 0.1324\n",
            "Epoch [32/200] Batch [4/391] Loss: 0.1167\n",
            "Epoch [32/200] Batch [5/391] Loss: 0.1509\n",
            "Epoch [32/200] Batch [6/391] Loss: 0.0961\n",
            "Epoch [32/200] Batch [7/391] Loss: 0.1006\n",
            "Epoch [32/200] Batch [8/391] Loss: 0.1548\n",
            "Epoch [32/200] Batch [9/391] Loss: 0.1643\n",
            "Epoch [32/200] Batch [10/391] Loss: 0.1353\n",
            "Epoch [32/200] Batch [11/391] Loss: 0.0956\n",
            "Epoch [32/200] Batch [12/391] Loss: 0.2363\n",
            "Epoch [32/200] Batch [13/391] Loss: 0.0813\n",
            "Epoch [32/200] Batch [14/391] Loss: 0.0874\n",
            "Epoch [32/200] Batch [15/391] Loss: 0.1091\n",
            "Epoch [32/200] Batch [16/391] Loss: 0.1437\n",
            "Epoch [32/200] Batch [17/391] Loss: 0.1410\n",
            "Epoch [32/200] Batch [18/391] Loss: 0.0922\n",
            "Epoch [32/200] Batch [19/391] Loss: 0.1337\n",
            "Epoch [32/200] Batch [20/391] Loss: 0.1176\n",
            "Epoch [32/200] Batch [21/391] Loss: 0.0950\n",
            "Epoch [32/200] Batch [22/391] Loss: 0.1554\n",
            "Epoch [32/200] Batch [23/391] Loss: 0.1266\n",
            "Epoch [32/200] Batch [24/391] Loss: 0.1912\n",
            "Epoch [32/200] Batch [25/391] Loss: 0.1271\n",
            "Epoch [32/200] Batch [26/391] Loss: 0.1393\n",
            "Epoch [32/200] Batch [27/391] Loss: 0.0956\n",
            "Epoch [32/200] Batch [28/391] Loss: 0.1039\n",
            "Epoch [32/200] Batch [29/391] Loss: 0.1068\n",
            "Epoch [32/200] Batch [30/391] Loss: 0.1019\n",
            "Epoch [32/200] Batch [31/391] Loss: 0.1275\n",
            "Epoch [32/200] Batch [32/391] Loss: 0.0523\n",
            "Epoch [32/200] Batch [33/391] Loss: 0.1004\n",
            "Epoch [32/200] Batch [34/391] Loss: 0.1177\n",
            "Epoch [32/200] Batch [35/391] Loss: 0.1139\n",
            "Epoch [32/200] Batch [36/391] Loss: 0.1128\n",
            "Epoch [32/200] Batch [37/391] Loss: 0.1181\n",
            "Epoch [32/200] Batch [38/391] Loss: 0.1246\n",
            "Epoch [32/200] Batch [39/391] Loss: 0.0995\n",
            "Epoch [32/200] Batch [40/391] Loss: 0.1075\n",
            "Epoch [32/200] Batch [41/391] Loss: 0.1446\n",
            "Epoch [32/200] Batch [42/391] Loss: 0.0605\n",
            "Epoch [32/200] Batch [43/391] Loss: 0.1336\n",
            "Epoch [32/200] Batch [44/391] Loss: 0.0486\n",
            "Epoch [32/200] Batch [45/391] Loss: 0.1294\n",
            "Epoch [32/200] Batch [46/391] Loss: 0.0816\n",
            "Epoch [32/200] Batch [47/391] Loss: 0.0923\n",
            "Epoch [32/200] Batch [48/391] Loss: 0.1397\n",
            "Epoch [32/200] Batch [49/391] Loss: 0.1843\n",
            "Epoch [32/200] Batch [50/391] Loss: 0.1162\n",
            "Epoch [32/200] Batch [51/391] Loss: 0.0929\n",
            "Epoch [32/200] Batch [52/391] Loss: 0.0999\n",
            "Epoch [32/200] Batch [53/391] Loss: 0.0773\n",
            "Epoch [32/200] Batch [54/391] Loss: 0.1363\n",
            "Epoch [32/200] Batch [55/391] Loss: 0.1131\n",
            "Epoch [32/200] Batch [56/391] Loss: 0.0984\n",
            "Epoch [32/200] Batch [57/391] Loss: 0.1371\n",
            "Epoch [32/200] Batch [58/391] Loss: 0.0948\n",
            "Epoch [32/200] Batch [59/391] Loss: 0.0334\n",
            "Epoch [32/200] Batch [60/391] Loss: 0.1544\n",
            "Epoch [32/200] Batch [61/391] Loss: 0.1325\n",
            "Epoch [32/200] Batch [62/391] Loss: 0.0873\n",
            "Epoch [32/200] Batch [63/391] Loss: 0.0990\n",
            "Epoch [32/200] Batch [64/391] Loss: 0.1578\n",
            "Epoch [32/200] Batch [65/391] Loss: 0.0913\n",
            "Epoch [32/200] Batch [66/391] Loss: 0.1235\n",
            "Epoch [32/200] Batch [67/391] Loss: 0.0879\n",
            "Epoch [32/200] Batch [68/391] Loss: 0.0589\n",
            "Epoch [32/200] Batch [69/391] Loss: 0.1264\n",
            "Epoch [32/200] Batch [70/391] Loss: 0.1194\n",
            "Epoch [32/200] Batch [71/391] Loss: 0.1003\n",
            "Epoch [32/200] Batch [72/391] Loss: 0.1206\n",
            "Epoch [32/200] Batch [73/391] Loss: 0.1262\n",
            "Epoch [32/200] Batch [74/391] Loss: 0.1527\n",
            "Epoch [32/200] Batch [75/391] Loss: 0.1511\n",
            "Epoch [32/200] Batch [76/391] Loss: 0.1959\n",
            "Epoch [32/200] Batch [77/391] Loss: 0.0993\n",
            "Epoch [32/200] Batch [78/391] Loss: 0.1121\n",
            "Epoch [32/200] Batch [79/391] Loss: 0.0521\n",
            "Epoch [32/200] Batch [80/391] Loss: 0.1024\n",
            "Epoch [32/200] Batch [81/391] Loss: 0.1199\n",
            "Epoch [32/200] Batch [82/391] Loss: 0.1558\n",
            "Epoch [32/200] Batch [83/391] Loss: 0.0812\n",
            "Epoch [32/200] Batch [84/391] Loss: 0.1325\n",
            "Epoch [32/200] Batch [85/391] Loss: 0.1781\n",
            "Epoch [32/200] Batch [86/391] Loss: 0.1241\n",
            "Epoch [32/200] Batch [87/391] Loss: 0.1128\n",
            "Epoch [32/200] Batch [88/391] Loss: 0.1375\n",
            "Epoch [32/200] Batch [89/391] Loss: 0.0693\n",
            "Epoch [32/200] Batch [90/391] Loss: 0.1018\n",
            "Epoch [32/200] Batch [91/391] Loss: 0.1233\n",
            "Epoch [32/200] Batch [92/391] Loss: 0.0792\n",
            "Epoch [32/200] Batch [93/391] Loss: 0.1271\n",
            "Epoch [32/200] Batch [94/391] Loss: 0.1687\n",
            "Epoch [32/200] Batch [95/391] Loss: 0.1117\n",
            "Epoch [32/200] Batch [96/391] Loss: 0.0647\n",
            "Epoch [32/200] Batch [97/391] Loss: 0.1529\n",
            "Epoch [32/200] Batch [98/391] Loss: 0.0727\n",
            "Epoch [32/200] Batch [99/391] Loss: 0.0644\n",
            "Epoch [32/200] Batch [100/391] Loss: 0.1221\n",
            "Epoch [32/200] Batch [101/391] Loss: 0.0761\n",
            "Epoch [32/200] Batch [102/391] Loss: 0.1207\n",
            "Epoch [32/200] Batch [103/391] Loss: 0.1319\n",
            "Epoch [32/200] Batch [104/391] Loss: 0.0948\n",
            "Epoch [32/200] Batch [105/391] Loss: 0.1229\n",
            "Epoch [32/200] Batch [106/391] Loss: 0.1111\n",
            "Epoch [32/200] Batch [107/391] Loss: 0.0994\n",
            "Epoch [32/200] Batch [108/391] Loss: 0.1011\n",
            "Epoch [32/200] Batch [109/391] Loss: 0.0875\n",
            "Epoch [32/200] Batch [110/391] Loss: 0.0646\n",
            "Epoch [32/200] Batch [111/391] Loss: 0.1012\n",
            "Epoch [32/200] Batch [112/391] Loss: 0.0571\n",
            "Epoch [32/200] Batch [113/391] Loss: 0.1450\n",
            "Epoch [32/200] Batch [114/391] Loss: 0.1290\n",
            "Epoch [32/200] Batch [115/391] Loss: 0.1002\n",
            "Epoch [32/200] Batch [116/391] Loss: 0.0406\n",
            "Epoch [32/200] Batch [117/391] Loss: 0.0978\n",
            "Epoch [32/200] Batch [118/391] Loss: 0.0821\n",
            "Epoch [32/200] Batch [119/391] Loss: 0.1150\n",
            "Epoch [32/200] Batch [120/391] Loss: 0.1217\n",
            "Epoch [32/200] Batch [121/391] Loss: 0.1491\n",
            "Epoch [32/200] Batch [122/391] Loss: 0.1510\n",
            "Epoch [32/200] Batch [123/391] Loss: 0.0937\n",
            "Epoch [32/200] Batch [124/391] Loss: 0.1165\n",
            "Epoch [32/200] Batch [125/391] Loss: 0.1440\n",
            "Epoch [32/200] Batch [126/391] Loss: 0.1134\n",
            "Epoch [32/200] Batch [127/391] Loss: 0.1784\n",
            "Epoch [32/200] Batch [128/391] Loss: 0.1212\n",
            "Epoch [32/200] Batch [129/391] Loss: 0.0812\n",
            "Epoch [32/200] Batch [130/391] Loss: 0.0703\n",
            "Epoch [32/200] Batch [131/391] Loss: 0.2689\n",
            "Epoch [32/200] Batch [132/391] Loss: 0.1774\n",
            "Epoch [32/200] Batch [133/391] Loss: 0.0752\n",
            "Epoch [32/200] Batch [134/391] Loss: 0.1161\n",
            "Epoch [32/200] Batch [135/391] Loss: 0.2018\n",
            "Epoch [32/200] Batch [136/391] Loss: 0.0842\n",
            "Epoch [32/200] Batch [137/391] Loss: 0.1397\n",
            "Epoch [32/200] Batch [138/391] Loss: 0.2193\n",
            "Epoch [32/200] Batch [139/391] Loss: 0.0947\n",
            "Epoch [32/200] Batch [140/391] Loss: 0.0629\n",
            "Epoch [32/200] Batch [141/391] Loss: 0.1415\n",
            "Epoch [32/200] Batch [142/391] Loss: 0.1373\n",
            "Epoch [32/200] Batch [143/391] Loss: 0.1136\n",
            "Epoch [32/200] Batch [144/391] Loss: 0.0929\n",
            "Epoch [32/200] Batch [145/391] Loss: 0.1508\n",
            "Epoch [32/200] Batch [146/391] Loss: 0.1529\n",
            "Epoch [32/200] Batch [147/391] Loss: 0.1610\n",
            "Epoch [32/200] Batch [148/391] Loss: 0.1216\n",
            "Epoch [32/200] Batch [149/391] Loss: 0.0666\n",
            "Epoch [32/200] Batch [150/391] Loss: 0.1701\n",
            "Epoch [32/200] Batch [151/391] Loss: 0.0689\n",
            "Epoch [32/200] Batch [152/391] Loss: 0.0821\n",
            "Epoch [32/200] Batch [153/391] Loss: 0.1566\n",
            "Epoch [32/200] Batch [154/391] Loss: 0.0706\n",
            "Epoch [32/200] Batch [155/391] Loss: 0.1898\n",
            "Epoch [32/200] Batch [156/391] Loss: 0.1192\n",
            "Epoch [32/200] Batch [157/391] Loss: 0.1430\n",
            "Epoch [32/200] Batch [158/391] Loss: 0.1572\n",
            "Epoch [32/200] Batch [159/391] Loss: 0.1128\n",
            "Epoch [32/200] Batch [160/391] Loss: 0.1013\n",
            "Epoch [32/200] Batch [161/391] Loss: 0.1439\n",
            "Epoch [32/200] Batch [162/391] Loss: 0.1323\n",
            "Epoch [32/200] Batch [163/391] Loss: 0.1311\n",
            "Epoch [32/200] Batch [164/391] Loss: 0.1075\n",
            "Epoch [32/200] Batch [165/391] Loss: 0.1757\n",
            "Epoch [32/200] Batch [166/391] Loss: 0.1490\n",
            "Epoch [32/200] Batch [167/391] Loss: 0.0703\n",
            "Epoch [32/200] Batch [168/391] Loss: 0.1316\n",
            "Epoch [32/200] Batch [169/391] Loss: 0.0830\n",
            "Epoch [32/200] Batch [170/391] Loss: 0.1414\n",
            "Epoch [32/200] Batch [171/391] Loss: 0.0884\n",
            "Epoch [32/200] Batch [172/391] Loss: 0.1217\n",
            "Epoch [32/200] Batch [173/391] Loss: 0.0671\n",
            "Epoch [32/200] Batch [174/391] Loss: 0.0821\n",
            "Epoch [32/200] Batch [175/391] Loss: 0.0941\n",
            "Epoch [32/200] Batch [176/391] Loss: 0.1762\n",
            "Epoch [32/200] Batch [177/391] Loss: 0.0771\n",
            "Epoch [32/200] Batch [178/391] Loss: 0.0904\n",
            "Epoch [32/200] Batch [179/391] Loss: 0.1802\n",
            "Epoch [32/200] Batch [180/391] Loss: 0.1969\n",
            "Epoch [32/200] Batch [181/391] Loss: 0.0773\n",
            "Epoch [32/200] Batch [182/391] Loss: 0.0935\n",
            "Epoch [32/200] Batch [183/391] Loss: 0.1541\n",
            "Epoch [32/200] Batch [184/391] Loss: 0.1693\n",
            "Epoch [32/200] Batch [185/391] Loss: 0.0994\n",
            "Epoch [32/200] Batch [186/391] Loss: 0.1034\n",
            "Epoch [32/200] Batch [187/391] Loss: 0.1071\n",
            "Epoch [32/200] Batch [188/391] Loss: 0.0971\n",
            "Epoch [32/200] Batch [189/391] Loss: 0.1497\n",
            "Epoch [32/200] Batch [190/391] Loss: 0.1533\n",
            "Epoch [32/200] Batch [191/391] Loss: 0.1001\n",
            "Epoch [32/200] Batch [192/391] Loss: 0.1397\n",
            "Epoch [32/200] Batch [193/391] Loss: 0.1248\n",
            "Epoch [32/200] Batch [194/391] Loss: 0.1471\n",
            "Epoch [32/200] Batch [195/391] Loss: 0.1156\n",
            "Epoch [32/200] Batch [196/391] Loss: 0.0853\n",
            "Epoch [32/200] Batch [197/391] Loss: 0.1092\n",
            "Epoch [32/200] Batch [198/391] Loss: 0.1450\n",
            "Epoch [32/200] Batch [199/391] Loss: 0.1268\n",
            "Epoch [32/200] Batch [200/391] Loss: 0.1820\n",
            "Epoch [32/200] Batch [201/391] Loss: 0.2359\n",
            "Epoch [32/200] Batch [202/391] Loss: 0.1284\n",
            "Epoch [32/200] Batch [203/391] Loss: 0.1435\n",
            "Epoch [32/200] Batch [204/391] Loss: 0.0872\n",
            "Epoch [32/200] Batch [205/391] Loss: 0.1100\n",
            "Epoch [32/200] Batch [206/391] Loss: 0.2519\n",
            "Epoch [32/200] Batch [207/391] Loss: 0.1178\n",
            "Epoch [32/200] Batch [208/391] Loss: 0.0742\n",
            "Epoch [32/200] Batch [209/391] Loss: 0.1335\n",
            "Epoch [32/200] Batch [210/391] Loss: 0.1765\n",
            "Epoch [32/200] Batch [211/391] Loss: 0.2033\n",
            "Epoch [32/200] Batch [212/391] Loss: 0.1072\n",
            "Epoch [32/200] Batch [213/391] Loss: 0.1924\n",
            "Epoch [32/200] Batch [214/391] Loss: 0.2257\n",
            "Epoch [32/200] Batch [215/391] Loss: 0.1933\n",
            "Epoch [32/200] Batch [216/391] Loss: 0.0562\n",
            "Epoch [32/200] Batch [217/391] Loss: 0.1266\n",
            "Epoch [32/200] Batch [218/391] Loss: 0.1074\n",
            "Epoch [32/200] Batch [219/391] Loss: 0.1445\n",
            "Epoch [32/200] Batch [220/391] Loss: 0.0808\n",
            "Epoch [32/200] Batch [221/391] Loss: 0.1205\n",
            "Epoch [32/200] Batch [222/391] Loss: 0.1535\n",
            "Epoch [32/200] Batch [223/391] Loss: 0.1495\n",
            "Epoch [32/200] Batch [224/391] Loss: 0.2097\n",
            "Epoch [32/200] Batch [225/391] Loss: 0.1466\n",
            "Epoch [32/200] Batch [226/391] Loss: 0.1786\n",
            "Epoch [32/200] Batch [227/391] Loss: 0.1613\n",
            "Epoch [32/200] Batch [228/391] Loss: 0.2893\n",
            "Epoch [32/200] Batch [229/391] Loss: 0.1497\n",
            "Epoch [32/200] Batch [230/391] Loss: 0.1321\n",
            "Epoch [32/200] Batch [231/391] Loss: 0.1017\n",
            "Epoch [32/200] Batch [232/391] Loss: 0.1230\n",
            "Epoch [32/200] Batch [233/391] Loss: 0.1097\n",
            "Epoch [32/200] Batch [234/391] Loss: 0.1201\n",
            "Epoch [32/200] Batch [235/391] Loss: 0.0629\n",
            "Epoch [32/200] Batch [236/391] Loss: 0.1927\n",
            "Epoch [32/200] Batch [237/391] Loss: 0.2161\n",
            "Epoch [32/200] Batch [238/391] Loss: 0.1995\n",
            "Epoch [32/200] Batch [239/391] Loss: 0.1590\n",
            "Epoch [32/200] Batch [240/391] Loss: 0.1637\n",
            "Epoch [32/200] Batch [241/391] Loss: 0.1275\n",
            "Epoch [32/200] Batch [242/391] Loss: 0.2119\n",
            "Epoch [32/200] Batch [243/391] Loss: 0.2232\n",
            "Epoch [32/200] Batch [244/391] Loss: 0.1714\n",
            "Epoch [32/200] Batch [245/391] Loss: 0.1043\n",
            "Epoch [32/200] Batch [246/391] Loss: 0.1545\n",
            "Epoch [32/200] Batch [247/391] Loss: 0.2013\n",
            "Epoch [32/200] Batch [248/391] Loss: 0.1093\n",
            "Epoch [32/200] Batch [249/391] Loss: 0.0621\n",
            "Epoch [32/200] Batch [250/391] Loss: 0.1658\n",
            "Epoch [32/200] Batch [251/391] Loss: 0.1029\n",
            "Epoch [32/200] Batch [252/391] Loss: 0.2393\n",
            "Epoch [32/200] Batch [253/391] Loss: 0.1385\n",
            "Epoch [32/200] Batch [254/391] Loss: 0.1248\n",
            "Epoch [32/200] Batch [255/391] Loss: 0.1184\n",
            "Epoch [32/200] Batch [256/391] Loss: 0.2848\n",
            "Epoch [32/200] Batch [257/391] Loss: 0.1598\n",
            "Epoch [32/200] Batch [258/391] Loss: 0.0878\n",
            "Epoch [32/200] Batch [259/391] Loss: 0.1794\n",
            "Epoch [32/200] Batch [260/391] Loss: 0.0590\n",
            "Epoch [32/200] Batch [261/391] Loss: 0.1293\n",
            "Epoch [32/200] Batch [262/391] Loss: 0.0858\n",
            "Epoch [32/200] Batch [263/391] Loss: 0.1521\n",
            "Epoch [32/200] Batch [264/391] Loss: 0.1457\n",
            "Epoch [32/200] Batch [265/391] Loss: 0.1650\n",
            "Epoch [32/200] Batch [266/391] Loss: 0.1084\n",
            "Epoch [32/200] Batch [267/391] Loss: 0.1586\n",
            "Epoch [32/200] Batch [268/391] Loss: 0.1101\n",
            "Epoch [32/200] Batch [269/391] Loss: 0.1125\n",
            "Epoch [32/200] Batch [270/391] Loss: 0.1253\n",
            "Epoch [32/200] Batch [271/391] Loss: 0.1037\n",
            "Epoch [32/200] Batch [272/391] Loss: 0.0779\n",
            "Epoch [32/200] Batch [273/391] Loss: 0.1156\n",
            "Epoch [32/200] Batch [274/391] Loss: 0.1635\n",
            "Epoch [32/200] Batch [275/391] Loss: 0.2219\n",
            "Epoch [32/200] Batch [276/391] Loss: 0.1821\n",
            "Epoch [32/200] Batch [277/391] Loss: 0.1109\n",
            "Epoch [32/200] Batch [278/391] Loss: 0.1612\n",
            "Epoch [32/200] Batch [279/391] Loss: 0.1138\n",
            "Epoch [32/200] Batch [280/391] Loss: 0.2148\n",
            "Epoch [32/200] Batch [281/391] Loss: 0.0881\n",
            "Epoch [32/200] Batch [282/391] Loss: 0.1270\n",
            "Epoch [32/200] Batch [283/391] Loss: 0.1545\n",
            "Epoch [32/200] Batch [284/391] Loss: 0.1437\n",
            "Epoch [32/200] Batch [285/391] Loss: 0.0626\n",
            "Epoch [32/200] Batch [286/391] Loss: 0.1084\n",
            "Epoch [32/200] Batch [287/391] Loss: 0.0821\n",
            "Epoch [32/200] Batch [288/391] Loss: 0.1266\n",
            "Epoch [32/200] Batch [289/391] Loss: 0.0952\n",
            "Epoch [32/200] Batch [290/391] Loss: 0.1974\n",
            "Epoch [32/200] Batch [291/391] Loss: 0.1618\n",
            "Epoch [32/200] Batch [292/391] Loss: 0.0911\n",
            "Epoch [32/200] Batch [293/391] Loss: 0.2295\n",
            "Epoch [32/200] Batch [294/391] Loss: 0.1664\n",
            "Epoch [32/200] Batch [295/391] Loss: 0.0822\n",
            "Epoch [32/200] Batch [296/391] Loss: 0.1203\n",
            "Epoch [32/200] Batch [297/391] Loss: 0.0772\n",
            "Epoch [32/200] Batch [298/391] Loss: 0.0866\n",
            "Epoch [32/200] Batch [299/391] Loss: 0.1941\n",
            "Epoch [32/200] Batch [300/391] Loss: 0.2560\n",
            "Epoch [32/200] Batch [301/391] Loss: 0.1295\n",
            "Epoch [32/200] Batch [302/391] Loss: 0.1369\n",
            "Epoch [32/200] Batch [303/391] Loss: 0.1786\n",
            "Epoch [32/200] Batch [304/391] Loss: 0.0804\n",
            "Epoch [32/200] Batch [305/391] Loss: 0.1479\n",
            "Epoch [32/200] Batch [306/391] Loss: 0.1133\n",
            "Epoch [32/200] Batch [307/391] Loss: 0.1032\n",
            "Epoch [32/200] Batch [308/391] Loss: 0.1353\n",
            "Epoch [32/200] Batch [309/391] Loss: 0.1167\n",
            "Epoch [32/200] Batch [310/391] Loss: 0.1170\n",
            "Epoch [32/200] Batch [311/391] Loss: 0.1399\n",
            "Epoch [32/200] Batch [312/391] Loss: 0.1864\n",
            "Epoch [32/200] Batch [313/391] Loss: 0.1743\n",
            "Epoch [32/200] Batch [314/391] Loss: 0.1647\n",
            "Epoch [32/200] Batch [315/391] Loss: 0.0811\n",
            "Epoch [32/200] Batch [316/391] Loss: 0.1292\n",
            "Epoch [32/200] Batch [317/391] Loss: 0.0438\n",
            "Epoch [32/200] Batch [318/391] Loss: 0.0786\n",
            "Epoch [32/200] Batch [319/391] Loss: 0.0636\n",
            "Epoch [32/200] Batch [320/391] Loss: 0.1332\n",
            "Epoch [32/200] Batch [321/391] Loss: 0.1445\n",
            "Epoch [32/200] Batch [322/391] Loss: 0.1233\n",
            "Epoch [32/200] Batch [323/391] Loss: 0.1405\n",
            "Epoch [32/200] Batch [324/391] Loss: 0.1351\n",
            "Epoch [32/200] Batch [325/391] Loss: 0.1440\n",
            "Epoch [32/200] Batch [326/391] Loss: 0.1187\n",
            "Epoch [32/200] Batch [327/391] Loss: 0.1840\n",
            "Epoch [32/200] Batch [328/391] Loss: 0.1129\n",
            "Epoch [32/200] Batch [329/391] Loss: 0.1194\n",
            "Epoch [32/200] Batch [330/391] Loss: 0.1060\n",
            "Epoch [32/200] Batch [331/391] Loss: 0.0528\n",
            "Epoch [32/200] Batch [332/391] Loss: 0.1121\n",
            "Epoch [32/200] Batch [333/391] Loss: 0.3052\n",
            "Epoch [32/200] Batch [334/391] Loss: 0.0934\n",
            "Epoch [32/200] Batch [335/391] Loss: 0.2254\n",
            "Epoch [32/200] Batch [336/391] Loss: 0.1354\n",
            "Epoch [32/200] Batch [337/391] Loss: 0.1752\n",
            "Epoch [32/200] Batch [338/391] Loss: 0.0732\n",
            "Epoch [32/200] Batch [339/391] Loss: 0.2149\n",
            "Epoch [32/200] Batch [340/391] Loss: 0.1014\n",
            "Epoch [32/200] Batch [341/391] Loss: 0.1428\n",
            "Epoch [32/200] Batch [342/391] Loss: 0.1144\n",
            "Epoch [32/200] Batch [343/391] Loss: 0.0999\n",
            "Epoch [32/200] Batch [344/391] Loss: 0.1361\n",
            "Epoch [32/200] Batch [345/391] Loss: 0.1068\n",
            "Epoch [32/200] Batch [346/391] Loss: 0.1229\n",
            "Epoch [32/200] Batch [347/391] Loss: 0.1055\n",
            "Epoch [32/200] Batch [348/391] Loss: 0.1456\n",
            "Epoch [32/200] Batch [349/391] Loss: 0.1205\n",
            "Epoch [32/200] Batch [350/391] Loss: 0.1256\n",
            "Epoch [32/200] Batch [351/391] Loss: 0.1215\n",
            "Epoch [32/200] Batch [352/391] Loss: 0.2067\n",
            "Epoch [32/200] Batch [353/391] Loss: 0.1860\n",
            "Epoch [32/200] Batch [354/391] Loss: 0.1544\n",
            "Epoch [32/200] Batch [355/391] Loss: 0.1035\n",
            "Epoch [32/200] Batch [356/391] Loss: 0.1010\n",
            "Epoch [32/200] Batch [357/391] Loss: 0.1255\n",
            "Epoch [32/200] Batch [358/391] Loss: 0.1028\n",
            "Epoch [32/200] Batch [359/391] Loss: 0.1338\n",
            "Epoch [32/200] Batch [360/391] Loss: 0.2335\n",
            "Epoch [32/200] Batch [361/391] Loss: 0.1713\n",
            "Epoch [32/200] Batch [362/391] Loss: 0.1265\n",
            "Epoch [32/200] Batch [363/391] Loss: 0.1166\n",
            "Epoch [32/200] Batch [364/391] Loss: 0.0839\n",
            "Epoch [32/200] Batch [365/391] Loss: 0.1072\n",
            "Epoch [32/200] Batch [366/391] Loss: 0.0919\n",
            "Epoch [32/200] Batch [367/391] Loss: 0.1815\n",
            "Epoch [32/200] Batch [368/391] Loss: 0.1615\n",
            "Epoch [32/200] Batch [369/391] Loss: 0.2098\n",
            "Epoch [32/200] Batch [370/391] Loss: 0.1255\n",
            "Epoch [32/200] Batch [371/391] Loss: 0.1926\n",
            "Epoch [32/200] Batch [372/391] Loss: 0.1191\n",
            "Epoch [32/200] Batch [373/391] Loss: 0.1034\n",
            "Epoch [32/200] Batch [374/391] Loss: 0.1746\n",
            "Epoch [32/200] Batch [375/391] Loss: 0.1340\n",
            "Epoch [32/200] Batch [376/391] Loss: 0.0730\n",
            "Epoch [32/200] Batch [377/391] Loss: 0.2787\n",
            "Epoch [32/200] Batch [378/391] Loss: 0.2308\n",
            "Epoch [32/200] Batch [379/391] Loss: 0.0549\n",
            "Epoch [32/200] Batch [380/391] Loss: 0.1434\n",
            "Epoch [32/200] Batch [381/391] Loss: 0.1038\n",
            "Epoch [32/200] Batch [382/391] Loss: 0.1732\n",
            "Epoch [32/200] Batch [383/391] Loss: 0.1851\n",
            "Epoch [32/200] Batch [384/391] Loss: 0.0954\n",
            "Epoch [32/200] Batch [385/391] Loss: 0.0907\n",
            "Epoch [32/200] Batch [386/391] Loss: 0.2034\n",
            "Epoch [32/200] Batch [387/391] Loss: 0.1828\n",
            "Epoch [32/200] Batch [388/391] Loss: 0.0924\n",
            "Epoch [32/200] Batch [389/391] Loss: 0.1923\n",
            "Epoch [32/200] Batch [390/391] Loss: 0.0920\n",
            "Epoch [32/200] Batch [391/391] Loss: 0.0841\n",
            "Epoch [32/200] - Train Loss: 0.1290 - Test Loss: 1.1851 - Train Acc: 84.21% - Test Acc: 76.23%\n",
            "Epoch [33/200] Batch [1/391] Loss: 0.1291\n",
            "Epoch [33/200] Batch [2/391] Loss: 0.1234\n",
            "Epoch [33/200] Batch [3/391] Loss: 0.0923\n",
            "Epoch [33/200] Batch [4/391] Loss: 0.1123\n",
            "Epoch [33/200] Batch [5/391] Loss: 0.1926\n",
            "Epoch [33/200] Batch [6/391] Loss: 0.0968\n",
            "Epoch [33/200] Batch [7/391] Loss: 0.1066\n",
            "Epoch [33/200] Batch [8/391] Loss: 0.1227\n",
            "Epoch [33/200] Batch [9/391] Loss: 0.0826\n",
            "Epoch [33/200] Batch [10/391] Loss: 0.1462\n",
            "Epoch [33/200] Batch [11/391] Loss: 0.1465\n",
            "Epoch [33/200] Batch [12/391] Loss: 0.0813\n",
            "Epoch [33/200] Batch [13/391] Loss: 0.1454\n",
            "Epoch [33/200] Batch [14/391] Loss: 0.0440\n",
            "Epoch [33/200] Batch [15/391] Loss: 0.0637\n",
            "Epoch [33/200] Batch [16/391] Loss: 0.1428\n",
            "Epoch [33/200] Batch [17/391] Loss: 0.1190\n",
            "Epoch [33/200] Batch [18/391] Loss: 0.0337\n",
            "Epoch [33/200] Batch [19/391] Loss: 0.1843\n",
            "Epoch [33/200] Batch [20/391] Loss: 0.0663\n",
            "Epoch [33/200] Batch [21/391] Loss: 0.1055\n",
            "Epoch [33/200] Batch [22/391] Loss: 0.1590\n",
            "Epoch [33/200] Batch [23/391] Loss: 0.0876\n",
            "Epoch [33/200] Batch [24/391] Loss: 0.0904\n",
            "Epoch [33/200] Batch [25/391] Loss: 0.1322\n",
            "Epoch [33/200] Batch [26/391] Loss: 0.1081\n",
            "Epoch [33/200] Batch [27/391] Loss: 0.1204\n",
            "Epoch [33/200] Batch [28/391] Loss: 0.0786\n",
            "Epoch [33/200] Batch [29/391] Loss: 0.0753\n",
            "Epoch [33/200] Batch [30/391] Loss: 0.0841\n",
            "Epoch [33/200] Batch [31/391] Loss: 0.0795\n",
            "Epoch [33/200] Batch [32/391] Loss: 0.0750\n",
            "Epoch [33/200] Batch [33/391] Loss: 0.0773\n",
            "Epoch [33/200] Batch [34/391] Loss: 0.0966\n",
            "Epoch [33/200] Batch [35/391] Loss: 0.0598\n",
            "Epoch [33/200] Batch [36/391] Loss: 0.0639\n",
            "Epoch [33/200] Batch [37/391] Loss: 0.0837\n",
            "Epoch [33/200] Batch [38/391] Loss: 0.0705\n",
            "Epoch [33/200] Batch [39/391] Loss: 0.1024\n",
            "Epoch [33/200] Batch [40/391] Loss: 0.0474\n",
            "Epoch [33/200] Batch [41/391] Loss: 0.0784\n",
            "Epoch [33/200] Batch [42/391] Loss: 0.1183\n",
            "Epoch [33/200] Batch [43/391] Loss: 0.1279\n",
            "Epoch [33/200] Batch [44/391] Loss: 0.0671\n",
            "Epoch [33/200] Batch [45/391] Loss: 0.0587\n",
            "Epoch [33/200] Batch [46/391] Loss: 0.0900\n",
            "Epoch [33/200] Batch [47/391] Loss: 0.1080\n",
            "Epoch [33/200] Batch [48/391] Loss: 0.0507\n",
            "Epoch [33/200] Batch [49/391] Loss: 0.1656\n",
            "Epoch [33/200] Batch [50/391] Loss: 0.0413\n",
            "Epoch [33/200] Batch [51/391] Loss: 0.0503\n",
            "Epoch [33/200] Batch [52/391] Loss: 0.1145\n",
            "Epoch [33/200] Batch [53/391] Loss: 0.0898\n",
            "Epoch [33/200] Batch [54/391] Loss: 0.1141\n",
            "Epoch [33/200] Batch [55/391] Loss: 0.1559\n",
            "Epoch [33/200] Batch [56/391] Loss: 0.0485\n",
            "Epoch [33/200] Batch [57/391] Loss: 0.0639\n",
            "Epoch [33/200] Batch [58/391] Loss: 0.1248\n",
            "Epoch [33/200] Batch [59/391] Loss: 0.1150\n",
            "Epoch [33/200] Batch [60/391] Loss: 0.1057\n",
            "Epoch [33/200] Batch [61/391] Loss: 0.1201\n",
            "Epoch [33/200] Batch [62/391] Loss: 0.1102\n",
            "Epoch [33/200] Batch [63/391] Loss: 0.0856\n",
            "Epoch [33/200] Batch [64/391] Loss: 0.1076\n",
            "Epoch [33/200] Batch [65/391] Loss: 0.1167\n",
            "Epoch [33/200] Batch [66/391] Loss: 0.0465\n",
            "Epoch [33/200] Batch [67/391] Loss: 0.0922\n",
            "Epoch [33/200] Batch [68/391] Loss: 0.1310\n",
            "Epoch [33/200] Batch [69/391] Loss: 0.1048\n",
            "Epoch [33/200] Batch [70/391] Loss: 0.1208\n",
            "Epoch [33/200] Batch [71/391] Loss: 0.0997\n",
            "Epoch [33/200] Batch [72/391] Loss: 0.0554\n",
            "Epoch [33/200] Batch [73/391] Loss: 0.0456\n",
            "Epoch [33/200] Batch [74/391] Loss: 0.0978\n",
            "Epoch [33/200] Batch [75/391] Loss: 0.0968\n",
            "Epoch [33/200] Batch [76/391] Loss: 0.1166\n",
            "Epoch [33/200] Batch [77/391] Loss: 0.0887\n",
            "Epoch [33/200] Batch [78/391] Loss: 0.1039\n",
            "Epoch [33/200] Batch [79/391] Loss: 0.0908\n",
            "Epoch [33/200] Batch [80/391] Loss: 0.1054\n",
            "Epoch [33/200] Batch [81/391] Loss: 0.0826\n",
            "Epoch [33/200] Batch [82/391] Loss: 0.0670\n",
            "Epoch [33/200] Batch [83/391] Loss: 0.0928\n",
            "Epoch [33/200] Batch [84/391] Loss: 0.0879\n",
            "Epoch [33/200] Batch [85/391] Loss: 0.0783\n",
            "Epoch [33/200] Batch [86/391] Loss: 0.0816\n",
            "Epoch [33/200] Batch [87/391] Loss: 0.1015\n",
            "Epoch [33/200] Batch [88/391] Loss: 0.1295\n",
            "Epoch [33/200] Batch [89/391] Loss: 0.0621\n",
            "Epoch [33/200] Batch [90/391] Loss: 0.0807\n",
            "Epoch [33/200] Batch [91/391] Loss: 0.1055\n",
            "Epoch [33/200] Batch [92/391] Loss: 0.0410\n",
            "Epoch [33/200] Batch [93/391] Loss: 0.1101\n",
            "Epoch [33/200] Batch [94/391] Loss: 0.1126\n",
            "Epoch [33/200] Batch [95/391] Loss: 0.1394\n",
            "Epoch [33/200] Batch [96/391] Loss: 0.1461\n",
            "Epoch [33/200] Batch [97/391] Loss: 0.1227\n",
            "Epoch [33/200] Batch [98/391] Loss: 0.0626\n",
            "Epoch [33/200] Batch [99/391] Loss: 0.0516\n",
            "Epoch [33/200] Batch [100/391] Loss: 0.0513\n",
            "Epoch [33/200] Batch [101/391] Loss: 0.0946\n",
            "Epoch [33/200] Batch [102/391] Loss: 0.1416\n",
            "Epoch [33/200] Batch [103/391] Loss: 0.0901\n",
            "Epoch [33/200] Batch [104/391] Loss: 0.1054\n",
            "Epoch [33/200] Batch [105/391] Loss: 0.1005\n",
            "Epoch [33/200] Batch [106/391] Loss: 0.1646\n",
            "Epoch [33/200] Batch [107/391] Loss: 0.0529\n",
            "Epoch [33/200] Batch [108/391] Loss: 0.0470\n",
            "Epoch [33/200] Batch [109/391] Loss: 0.0422\n",
            "Epoch [33/200] Batch [110/391] Loss: 0.0868\n",
            "Epoch [33/200] Batch [111/391] Loss: 0.0828\n",
            "Epoch [33/200] Batch [112/391] Loss: 0.1210\n",
            "Epoch [33/200] Batch [113/391] Loss: 0.1177\n",
            "Epoch [33/200] Batch [114/391] Loss: 0.0524\n",
            "Epoch [33/200] Batch [115/391] Loss: 0.0573\n",
            "Epoch [33/200] Batch [116/391] Loss: 0.0790\n",
            "Epoch [33/200] Batch [117/391] Loss: 0.1014\n",
            "Epoch [33/200] Batch [118/391] Loss: 0.0710\n",
            "Epoch [33/200] Batch [119/391] Loss: 0.1193\n",
            "Epoch [33/200] Batch [120/391] Loss: 0.0933\n",
            "Epoch [33/200] Batch [121/391] Loss: 0.1134\n",
            "Epoch [33/200] Batch [122/391] Loss: 0.1059\n",
            "Epoch [33/200] Batch [123/391] Loss: 0.1044\n",
            "Epoch [33/200] Batch [124/391] Loss: 0.0911\n",
            "Epoch [33/200] Batch [125/391] Loss: 0.1045\n",
            "Epoch [33/200] Batch [126/391] Loss: 0.1442\n",
            "Epoch [33/200] Batch [127/391] Loss: 0.1149\n",
            "Epoch [33/200] Batch [128/391] Loss: 0.0845\n",
            "Epoch [33/200] Batch [129/391] Loss: 0.0194\n",
            "Epoch [33/200] Batch [130/391] Loss: 0.1476\n",
            "Epoch [33/200] Batch [131/391] Loss: 0.0892\n",
            "Epoch [33/200] Batch [132/391] Loss: 0.1513\n",
            "Epoch [33/200] Batch [133/391] Loss: 0.0844\n",
            "Epoch [33/200] Batch [134/391] Loss: 0.1011\n",
            "Epoch [33/200] Batch [135/391] Loss: 0.1460\n",
            "Epoch [33/200] Batch [136/391] Loss: 0.0742\n",
            "Epoch [33/200] Batch [137/391] Loss: 0.1046\n",
            "Epoch [33/200] Batch [138/391] Loss: 0.1854\n",
            "Epoch [33/200] Batch [139/391] Loss: 0.0856\n",
            "Epoch [33/200] Batch [140/391] Loss: 0.1018\n",
            "Epoch [33/200] Batch [141/391] Loss: 0.1229\n",
            "Epoch [33/200] Batch [142/391] Loss: 0.0838\n",
            "Epoch [33/200] Batch [143/391] Loss: 0.0825\n",
            "Epoch [33/200] Batch [144/391] Loss: 0.1046\n",
            "Epoch [33/200] Batch [145/391] Loss: 0.0909\n",
            "Epoch [33/200] Batch [146/391] Loss: 0.1215\n",
            "Epoch [33/200] Batch [147/391] Loss: 0.1479\n",
            "Epoch [33/200] Batch [148/391] Loss: 0.0861\n",
            "Epoch [33/200] Batch [149/391] Loss: 0.1170\n",
            "Epoch [33/200] Batch [150/391] Loss: 0.0827\n",
            "Epoch [33/200] Batch [151/391] Loss: 0.1125\n",
            "Epoch [33/200] Batch [152/391] Loss: 0.3242\n",
            "Epoch [33/200] Batch [153/391] Loss: 0.1323\n",
            "Epoch [33/200] Batch [154/391] Loss: 0.0456\n",
            "Epoch [33/200] Batch [155/391] Loss: 0.1179\n",
            "Epoch [33/200] Batch [156/391] Loss: 0.1473\n",
            "Epoch [33/200] Batch [157/391] Loss: 0.0869\n",
            "Epoch [33/200] Batch [158/391] Loss: 0.0917\n",
            "Epoch [33/200] Batch [159/391] Loss: 0.0622\n",
            "Epoch [33/200] Batch [160/391] Loss: 0.1004\n",
            "Epoch [33/200] Batch [161/391] Loss: 0.2431\n",
            "Epoch [33/200] Batch [162/391] Loss: 0.0818\n",
            "Epoch [33/200] Batch [163/391] Loss: 0.1264\n",
            "Epoch [33/200] Batch [164/391] Loss: 0.1029\n",
            "Epoch [33/200] Batch [165/391] Loss: 0.1504\n",
            "Epoch [33/200] Batch [166/391] Loss: 0.1143\n",
            "Epoch [33/200] Batch [167/391] Loss: 0.0996\n",
            "Epoch [33/200] Batch [168/391] Loss: 0.0935\n",
            "Epoch [33/200] Batch [169/391] Loss: 0.0834\n",
            "Epoch [33/200] Batch [170/391] Loss: 0.1207\n",
            "Epoch [33/200] Batch [171/391] Loss: 0.0385\n",
            "Epoch [33/200] Batch [172/391] Loss: 0.1005\n",
            "Epoch [33/200] Batch [173/391] Loss: 0.0801\n",
            "Epoch [33/200] Batch [174/391] Loss: 0.1514\n",
            "Epoch [33/200] Batch [175/391] Loss: 0.0977\n",
            "Epoch [33/200] Batch [176/391] Loss: 0.1468\n",
            "Epoch [33/200] Batch [177/391] Loss: 0.1622\n",
            "Epoch [33/200] Batch [178/391] Loss: 0.1456\n",
            "Epoch [33/200] Batch [179/391] Loss: 0.0991\n",
            "Epoch [33/200] Batch [180/391] Loss: 0.0738\n",
            "Epoch [33/200] Batch [181/391] Loss: 0.0836\n",
            "Epoch [33/200] Batch [182/391] Loss: 0.1637\n",
            "Epoch [33/200] Batch [183/391] Loss: 0.0587\n",
            "Epoch [33/200] Batch [184/391] Loss: 0.1269\n",
            "Epoch [33/200] Batch [185/391] Loss: 0.1061\n",
            "Epoch [33/200] Batch [186/391] Loss: 0.0891\n",
            "Epoch [33/200] Batch [187/391] Loss: 0.0922\n",
            "Epoch [33/200] Batch [188/391] Loss: 0.1379\n",
            "Epoch [33/200] Batch [189/391] Loss: 0.1285\n",
            "Epoch [33/200] Batch [190/391] Loss: 0.1319\n",
            "Epoch [33/200] Batch [191/391] Loss: 0.1375\n",
            "Epoch [33/200] Batch [192/391] Loss: 0.1099\n",
            "Epoch [33/200] Batch [193/391] Loss: 0.0502\n",
            "Epoch [33/200] Batch [194/391] Loss: 0.1660\n",
            "Epoch [33/200] Batch [195/391] Loss: 0.1793\n",
            "Epoch [33/200] Batch [196/391] Loss: 0.0877\n",
            "Epoch [33/200] Batch [197/391] Loss: 0.2145\n",
            "Epoch [33/200] Batch [198/391] Loss: 0.1796\n",
            "Epoch [33/200] Batch [199/391] Loss: 0.1899\n",
            "Epoch [33/200] Batch [200/391] Loss: 0.1969\n",
            "Epoch [33/200] Batch [201/391] Loss: 0.1457\n",
            "Epoch [33/200] Batch [202/391] Loss: 0.1268\n",
            "Epoch [33/200] Batch [203/391] Loss: 0.1213\n",
            "Epoch [33/200] Batch [204/391] Loss: 0.0874\n",
            "Epoch [33/200] Batch [205/391] Loss: 0.1450\n",
            "Epoch [33/200] Batch [206/391] Loss: 0.1429\n",
            "Epoch [33/200] Batch [207/391] Loss: 0.1412\n",
            "Epoch [33/200] Batch [208/391] Loss: 0.2516\n",
            "Epoch [33/200] Batch [209/391] Loss: 0.1418\n",
            "Epoch [33/200] Batch [210/391] Loss: 0.0746\n",
            "Epoch [33/200] Batch [211/391] Loss: 0.0587\n",
            "Epoch [33/200] Batch [212/391] Loss: 0.1217\n",
            "Epoch [33/200] Batch [213/391] Loss: 0.1482\n",
            "Epoch [33/200] Batch [214/391] Loss: 0.1363\n",
            "Epoch [33/200] Batch [215/391] Loss: 0.1107\n",
            "Epoch [33/200] Batch [216/391] Loss: 0.1511\n",
            "Epoch [33/200] Batch [217/391] Loss: 0.1877\n",
            "Epoch [33/200] Batch [218/391] Loss: 0.1323\n",
            "Epoch [33/200] Batch [219/391] Loss: 0.1015\n",
            "Epoch [33/200] Batch [220/391] Loss: 0.1313\n",
            "Epoch [33/200] Batch [221/391] Loss: 0.0858\n",
            "Epoch [33/200] Batch [222/391] Loss: 0.1079\n",
            "Epoch [33/200] Batch [223/391] Loss: 0.1141\n",
            "Epoch [33/200] Batch [224/391] Loss: 0.1534\n",
            "Epoch [33/200] Batch [225/391] Loss: 0.1917\n",
            "Epoch [33/200] Batch [226/391] Loss: 0.1255\n",
            "Epoch [33/200] Batch [227/391] Loss: 0.1218\n",
            "Epoch [33/200] Batch [228/391] Loss: 0.0870\n",
            "Epoch [33/200] Batch [229/391] Loss: 0.0761\n",
            "Epoch [33/200] Batch [230/391] Loss: 0.1339\n",
            "Epoch [33/200] Batch [231/391] Loss: 0.0805\n",
            "Epoch [33/200] Batch [232/391] Loss: 0.1684\n",
            "Epoch [33/200] Batch [233/391] Loss: 0.0839\n",
            "Epoch [33/200] Batch [234/391] Loss: 0.1460\n",
            "Epoch [33/200] Batch [235/391] Loss: 0.1599\n",
            "Epoch [33/200] Batch [236/391] Loss: 0.0839\n",
            "Epoch [33/200] Batch [237/391] Loss: 0.1647\n",
            "Epoch [33/200] Batch [238/391] Loss: 0.1024\n",
            "Epoch [33/200] Batch [239/391] Loss: 0.1250\n",
            "Epoch [33/200] Batch [240/391] Loss: 0.0977\n",
            "Epoch [33/200] Batch [241/391] Loss: 0.1345\n",
            "Epoch [33/200] Batch [242/391] Loss: 0.1460\n",
            "Epoch [33/200] Batch [243/391] Loss: 0.1640\n",
            "Epoch [33/200] Batch [244/391] Loss: 0.1663\n",
            "Epoch [33/200] Batch [245/391] Loss: 0.1088\n",
            "Epoch [33/200] Batch [246/391] Loss: 0.1655\n",
            "Epoch [33/200] Batch [247/391] Loss: 0.1962\n",
            "Epoch [33/200] Batch [248/391] Loss: 0.0821\n",
            "Epoch [33/200] Batch [249/391] Loss: 0.1866\n",
            "Epoch [33/200] Batch [250/391] Loss: 0.2279\n",
            "Epoch [33/200] Batch [251/391] Loss: 0.0860\n",
            "Epoch [33/200] Batch [252/391] Loss: 0.1481\n",
            "Epoch [33/200] Batch [253/391] Loss: 0.2589\n",
            "Epoch [33/200] Batch [254/391] Loss: 0.1347\n",
            "Epoch [33/200] Batch [255/391] Loss: 0.1444\n",
            "Epoch [33/200] Batch [256/391] Loss: 0.1513\n",
            "Epoch [33/200] Batch [257/391] Loss: 0.1288\n",
            "Epoch [33/200] Batch [258/391] Loss: 0.0785\n",
            "Epoch [33/200] Batch [259/391] Loss: 0.1226\n",
            "Epoch [33/200] Batch [260/391] Loss: 0.1398\n",
            "Epoch [33/200] Batch [261/391] Loss: 0.1065\n",
            "Epoch [33/200] Batch [262/391] Loss: 0.0938\n",
            "Epoch [33/200] Batch [263/391] Loss: 0.0640\n",
            "Epoch [33/200] Batch [264/391] Loss: 0.1224\n",
            "Epoch [33/200] Batch [265/391] Loss: 0.1065\n",
            "Epoch [33/200] Batch [266/391] Loss: 0.0783\n",
            "Epoch [33/200] Batch [267/391] Loss: 0.0918\n",
            "Epoch [33/200] Batch [268/391] Loss: 0.1326\n",
            "Epoch [33/200] Batch [269/391] Loss: 0.1404\n",
            "Epoch [33/200] Batch [270/391] Loss: 0.0751\n",
            "Epoch [33/200] Batch [271/391] Loss: 0.0691\n",
            "Epoch [33/200] Batch [272/391] Loss: 0.1319\n",
            "Epoch [33/200] Batch [273/391] Loss: 0.0881\n",
            "Epoch [33/200] Batch [274/391] Loss: 0.1474\n",
            "Epoch [33/200] Batch [275/391] Loss: 0.1005\n",
            "Epoch [33/200] Batch [276/391] Loss: 0.1426\n",
            "Epoch [33/200] Batch [277/391] Loss: 0.0734\n",
            "Epoch [33/200] Batch [278/391] Loss: 0.0911\n",
            "Epoch [33/200] Batch [279/391] Loss: 0.0587\n",
            "Epoch [33/200] Batch [280/391] Loss: 0.0595\n",
            "Epoch [33/200] Batch [281/391] Loss: 0.2066\n",
            "Epoch [33/200] Batch [282/391] Loss: 0.0782\n",
            "Epoch [33/200] Batch [283/391] Loss: 0.0856\n",
            "Epoch [33/200] Batch [284/391] Loss: 0.0804\n",
            "Epoch [33/200] Batch [285/391] Loss: 0.2376\n",
            "Epoch [33/200] Batch [286/391] Loss: 0.1393\n",
            "Epoch [33/200] Batch [287/391] Loss: 0.0558\n",
            "Epoch [33/200] Batch [288/391] Loss: 0.2195\n",
            "Epoch [33/200] Batch [289/391] Loss: 0.0835\n",
            "Epoch [33/200] Batch [290/391] Loss: 0.1807\n",
            "Epoch [33/200] Batch [291/391] Loss: 0.1143\n",
            "Epoch [33/200] Batch [292/391] Loss: 0.1027\n",
            "Epoch [33/200] Batch [293/391] Loss: 0.0946\n",
            "Epoch [33/200] Batch [294/391] Loss: 0.0964\n",
            "Epoch [33/200] Batch [295/391] Loss: 0.1129\n",
            "Epoch [33/200] Batch [296/391] Loss: 0.1330\n",
            "Epoch [33/200] Batch [297/391] Loss: 0.1328\n",
            "Epoch [33/200] Batch [298/391] Loss: 0.2220\n",
            "Epoch [33/200] Batch [299/391] Loss: 0.0553\n",
            "Epoch [33/200] Batch [300/391] Loss: 0.0930\n",
            "Epoch [33/200] Batch [301/391] Loss: 0.2053\n",
            "Epoch [33/200] Batch [302/391] Loss: 0.1670\n",
            "Epoch [33/200] Batch [303/391] Loss: 0.0981\n",
            "Epoch [33/200] Batch [304/391] Loss: 0.0959\n",
            "Epoch [33/200] Batch [305/391] Loss: 0.1181\n",
            "Epoch [33/200] Batch [306/391] Loss: 0.0943\n",
            "Epoch [33/200] Batch [307/391] Loss: 0.1281\n",
            "Epoch [33/200] Batch [308/391] Loss: 0.1155\n",
            "Epoch [33/200] Batch [309/391] Loss: 0.2056\n",
            "Epoch [33/200] Batch [310/391] Loss: 0.0975\n",
            "Epoch [33/200] Batch [311/391] Loss: 0.0996\n",
            "Epoch [33/200] Batch [312/391] Loss: 0.0410\n",
            "Epoch [33/200] Batch [313/391] Loss: 0.1386\n",
            "Epoch [33/200] Batch [314/391] Loss: 0.0581\n",
            "Epoch [33/200] Batch [315/391] Loss: 0.1074\n",
            "Epoch [33/200] Batch [316/391] Loss: 0.1000\n",
            "Epoch [33/200] Batch [317/391] Loss: 0.1017\n",
            "Epoch [33/200] Batch [318/391] Loss: 0.1317\n",
            "Epoch [33/200] Batch [319/391] Loss: 0.0970\n",
            "Epoch [33/200] Batch [320/391] Loss: 0.1351\n",
            "Epoch [33/200] Batch [321/391] Loss: 0.1428\n",
            "Epoch [33/200] Batch [322/391] Loss: 0.1372\n",
            "Epoch [33/200] Batch [323/391] Loss: 0.0985\n",
            "Epoch [33/200] Batch [324/391] Loss: 0.1747\n",
            "Epoch [33/200] Batch [325/391] Loss: 0.1024\n",
            "Epoch [33/200] Batch [326/391] Loss: 0.1967\n",
            "Epoch [33/200] Batch [327/391] Loss: 0.1340\n",
            "Epoch [33/200] Batch [328/391] Loss: 0.0799\n",
            "Epoch [33/200] Batch [329/391] Loss: 0.1562\n",
            "Epoch [33/200] Batch [330/391] Loss: 0.0937\n",
            "Epoch [33/200] Batch [331/391] Loss: 0.2274\n",
            "Epoch [33/200] Batch [332/391] Loss: 0.0909\n",
            "Epoch [33/200] Batch [333/391] Loss: 0.1454\n",
            "Epoch [33/200] Batch [334/391] Loss: 0.1780\n",
            "Epoch [33/200] Batch [335/391] Loss: 0.1635\n",
            "Epoch [33/200] Batch [336/391] Loss: 0.1200\n",
            "Epoch [33/200] Batch [337/391] Loss: 0.0970\n",
            "Epoch [33/200] Batch [338/391] Loss: 0.1574\n",
            "Epoch [33/200] Batch [339/391] Loss: 0.1603\n",
            "Epoch [33/200] Batch [340/391] Loss: 0.0523\n",
            "Epoch [33/200] Batch [341/391] Loss: 0.0706\n",
            "Epoch [33/200] Batch [342/391] Loss: 0.0607\n",
            "Epoch [33/200] Batch [343/391] Loss: 0.1110\n",
            "Epoch [33/200] Batch [344/391] Loss: 0.1015\n",
            "Epoch [33/200] Batch [345/391] Loss: 0.1523\n",
            "Epoch [33/200] Batch [346/391] Loss: 0.1697\n",
            "Epoch [33/200] Batch [347/391] Loss: 0.0647\n",
            "Epoch [33/200] Batch [348/391] Loss: 0.1164\n",
            "Epoch [33/200] Batch [349/391] Loss: 0.1183\n",
            "Epoch [33/200] Batch [350/391] Loss: 0.1520\n",
            "Epoch [33/200] Batch [351/391] Loss: 0.1326\n",
            "Epoch [33/200] Batch [352/391] Loss: 0.1024\n",
            "Epoch [33/200] Batch [353/391] Loss: 0.1941\n",
            "Epoch [33/200] Batch [354/391] Loss: 0.1868\n",
            "Epoch [33/200] Batch [355/391] Loss: 0.0697\n",
            "Epoch [33/200] Batch [356/391] Loss: 0.1397\n",
            "Epoch [33/200] Batch [357/391] Loss: 0.1021\n",
            "Epoch [33/200] Batch [358/391] Loss: 0.1100\n",
            "Epoch [33/200] Batch [359/391] Loss: 0.1172\n",
            "Epoch [33/200] Batch [360/391] Loss: 0.1692\n",
            "Epoch [33/200] Batch [361/391] Loss: 0.0944\n",
            "Epoch [33/200] Batch [362/391] Loss: 0.1095\n",
            "Epoch [33/200] Batch [363/391] Loss: 0.1323\n",
            "Epoch [33/200] Batch [364/391] Loss: 0.1406\n",
            "Epoch [33/200] Batch [365/391] Loss: 0.1119\n",
            "Epoch [33/200] Batch [366/391] Loss: 0.0909\n",
            "Epoch [33/200] Batch [367/391] Loss: 0.1330\n",
            "Epoch [33/200] Batch [368/391] Loss: 0.1234\n",
            "Epoch [33/200] Batch [369/391] Loss: 0.1205\n",
            "Epoch [33/200] Batch [370/391] Loss: 0.1630\n",
            "Epoch [33/200] Batch [371/391] Loss: 0.0948\n",
            "Epoch [33/200] Batch [372/391] Loss: 0.1393\n",
            "Epoch [33/200] Batch [373/391] Loss: 0.1473\n",
            "Epoch [33/200] Batch [374/391] Loss: 0.2411\n",
            "Epoch [33/200] Batch [375/391] Loss: 0.1055\n",
            "Epoch [33/200] Batch [376/391] Loss: 0.1593\n",
            "Epoch [33/200] Batch [377/391] Loss: 0.1834\n",
            "Epoch [33/200] Batch [378/391] Loss: 0.1258\n",
            "Epoch [33/200] Batch [379/391] Loss: 0.1864\n",
            "Epoch [33/200] Batch [380/391] Loss: 0.1870\n",
            "Epoch [33/200] Batch [381/391] Loss: 0.1834\n",
            "Epoch [33/200] Batch [382/391] Loss: 0.1559\n",
            "Epoch [33/200] Batch [383/391] Loss: 0.3111\n",
            "Epoch [33/200] Batch [384/391] Loss: 0.1496\n",
            "Epoch [33/200] Batch [385/391] Loss: 0.1010\n",
            "Epoch [33/200] Batch [386/391] Loss: 0.2010\n",
            "Epoch [33/200] Batch [387/391] Loss: 0.1512\n",
            "Epoch [33/200] Batch [388/391] Loss: 0.2139\n",
            "Epoch [33/200] Batch [389/391] Loss: 0.1857\n",
            "Epoch [33/200] Batch [390/391] Loss: 0.1883\n",
            "Epoch [33/200] Batch [391/391] Loss: 0.0993\n",
            "Epoch [33/200] - Train Loss: 0.1166 - Test Loss: 0.9953 - Train Acc: 83.31% - Test Acc: 74.72%\n",
            "Epoch [34/200] Batch [1/391] Loss: 0.1286\n",
            "Epoch [34/200] Batch [2/391] Loss: 0.0686\n",
            "Epoch [34/200] Batch [3/391] Loss: 0.1364\n",
            "Epoch [34/200] Batch [4/391] Loss: 0.1016\n",
            "Epoch [34/200] Batch [5/391] Loss: 0.2125\n",
            "Epoch [34/200] Batch [6/391] Loss: 0.1017\n",
            "Epoch [34/200] Batch [7/391] Loss: 0.1024\n",
            "Epoch [34/200] Batch [8/391] Loss: 0.0868\n",
            "Epoch [34/200] Batch [9/391] Loss: 0.1406\n",
            "Epoch [34/200] Batch [10/391] Loss: 0.0799\n",
            "Epoch [34/200] Batch [11/391] Loss: 0.0926\n",
            "Epoch [34/200] Batch [12/391] Loss: 0.1066\n",
            "Epoch [34/200] Batch [13/391] Loss: 0.0758\n",
            "Epoch [34/200] Batch [14/391] Loss: 0.1297\n",
            "Epoch [34/200] Batch [15/391] Loss: 0.0707\n",
            "Epoch [34/200] Batch [16/391] Loss: 0.1169\n",
            "Epoch [34/200] Batch [17/391] Loss: 0.0825\n",
            "Epoch [34/200] Batch [18/391] Loss: 0.0906\n",
            "Epoch [34/200] Batch [19/391] Loss: 0.0409\n",
            "Epoch [34/200] Batch [20/391] Loss: 0.1537\n",
            "Epoch [34/200] Batch [21/391] Loss: 0.1142\n",
            "Epoch [34/200] Batch [22/391] Loss: 0.1884\n",
            "Epoch [34/200] Batch [23/391] Loss: 0.1451\n",
            "Epoch [34/200] Batch [24/391] Loss: 0.0827\n",
            "Epoch [34/200] Batch [25/391] Loss: 0.1209\n",
            "Epoch [34/200] Batch [26/391] Loss: 0.2416\n",
            "Epoch [34/200] Batch [27/391] Loss: 0.1233\n",
            "Epoch [34/200] Batch [28/391] Loss: 0.0919\n",
            "Epoch [34/200] Batch [29/391] Loss: 0.0725\n",
            "Epoch [34/200] Batch [30/391] Loss: 0.0934\n",
            "Epoch [34/200] Batch [31/391] Loss: 0.0932\n",
            "Epoch [34/200] Batch [32/391] Loss: 0.0652\n",
            "Epoch [34/200] Batch [33/391] Loss: 0.1064\n",
            "Epoch [34/200] Batch [34/391] Loss: 0.1651\n",
            "Epoch [34/200] Batch [35/391] Loss: 0.0962\n",
            "Epoch [34/200] Batch [36/391] Loss: 0.0865\n",
            "Epoch [34/200] Batch [37/391] Loss: 0.1467\n",
            "Epoch [34/200] Batch [38/391] Loss: 0.1050\n",
            "Epoch [34/200] Batch [39/391] Loss: 0.0992\n",
            "Epoch [34/200] Batch [40/391] Loss: 0.1133\n",
            "Epoch [34/200] Batch [41/391] Loss: 0.1263\n",
            "Epoch [34/200] Batch [42/391] Loss: 0.0992\n",
            "Epoch [34/200] Batch [43/391] Loss: 0.0823\n",
            "Epoch [34/200] Batch [44/391] Loss: 0.1091\n",
            "Epoch [34/200] Batch [45/391] Loss: 0.0617\n",
            "Epoch [34/200] Batch [46/391] Loss: 0.1152\n",
            "Epoch [34/200] Batch [47/391] Loss: 0.0684\n",
            "Epoch [34/200] Batch [48/391] Loss: 0.0468\n",
            "Epoch [34/200] Batch [49/391] Loss: 0.1018\n",
            "Epoch [34/200] Batch [50/391] Loss: 0.0847\n",
            "Epoch [34/200] Batch [51/391] Loss: 0.0796\n",
            "Epoch [34/200] Batch [52/391] Loss: 0.0531\n",
            "Epoch [34/200] Batch [53/391] Loss: 0.0746\n",
            "Epoch [34/200] Batch [54/391] Loss: 0.0783\n",
            "Epoch [34/200] Batch [55/391] Loss: 0.1127\n",
            "Epoch [34/200] Batch [56/391] Loss: 0.0894\n",
            "Epoch [34/200] Batch [57/391] Loss: 0.0985\n",
            "Epoch [34/200] Batch [58/391] Loss: 0.1187\n",
            "Epoch [34/200] Batch [59/391] Loss: 0.0898\n",
            "Epoch [34/200] Batch [60/391] Loss: 0.0600\n",
            "Epoch [34/200] Batch [61/391] Loss: 0.0948\n",
            "Epoch [34/200] Batch [62/391] Loss: 0.0890\n",
            "Epoch [34/200] Batch [63/391] Loss: 0.0616\n",
            "Epoch [34/200] Batch [64/391] Loss: 0.2091\n",
            "Epoch [34/200] Batch [65/391] Loss: 0.1089\n",
            "Epoch [34/200] Batch [66/391] Loss: 0.0771\n",
            "Epoch [34/200] Batch [67/391] Loss: 0.0575\n",
            "Epoch [34/200] Batch [68/391] Loss: 0.0869\n",
            "Epoch [34/200] Batch [69/391] Loss: 0.1652\n",
            "Epoch [34/200] Batch [70/391] Loss: 0.0525\n",
            "Epoch [34/200] Batch [71/391] Loss: 0.0789\n",
            "Epoch [34/200] Batch [72/391] Loss: 0.0642\n",
            "Epoch [34/200] Batch [73/391] Loss: 0.0455\n",
            "Epoch [34/200] Batch [74/391] Loss: 0.1407\n",
            "Epoch [34/200] Batch [75/391] Loss: 0.1214\n",
            "Epoch [34/200] Batch [76/391] Loss: 0.0716\n",
            "Epoch [34/200] Batch [77/391] Loss: 0.0745\n",
            "Epoch [34/200] Batch [78/391] Loss: 0.0854\n",
            "Epoch [34/200] Batch [79/391] Loss: 0.1034\n",
            "Epoch [34/200] Batch [80/391] Loss: 0.0663\n",
            "Epoch [34/200] Batch [81/391] Loss: 0.1265\n",
            "Epoch [34/200] Batch [82/391] Loss: 0.1979\n",
            "Epoch [34/200] Batch [83/391] Loss: 0.0685\n",
            "Epoch [34/200] Batch [84/391] Loss: 0.1305\n",
            "Epoch [34/200] Batch [85/391] Loss: 0.0667\n",
            "Epoch [34/200] Batch [86/391] Loss: 0.0798\n",
            "Epoch [34/200] Batch [87/391] Loss: 0.1267\n",
            "Epoch [34/200] Batch [88/391] Loss: 0.0885\n",
            "Epoch [34/200] Batch [89/391] Loss: 0.0605\n",
            "Epoch [34/200] Batch [90/391] Loss: 0.0378\n",
            "Epoch [34/200] Batch [91/391] Loss: 0.0714\n",
            "Epoch [34/200] Batch [92/391] Loss: 0.1339\n",
            "Epoch [34/200] Batch [93/391] Loss: 0.1193\n",
            "Epoch [34/200] Batch [94/391] Loss: 0.1169\n",
            "Epoch [34/200] Batch [95/391] Loss: 0.1081\n",
            "Epoch [34/200] Batch [96/391] Loss: 0.1766\n",
            "Epoch [34/200] Batch [97/391] Loss: 0.0839\n",
            "Epoch [34/200] Batch [98/391] Loss: 0.0514\n",
            "Epoch [34/200] Batch [99/391] Loss: 0.0846\n",
            "Epoch [34/200] Batch [100/391] Loss: 0.0625\n",
            "Epoch [34/200] Batch [101/391] Loss: 0.0834\n",
            "Epoch [34/200] Batch [102/391] Loss: 0.0935\n",
            "Epoch [34/200] Batch [103/391] Loss: 0.1273\n",
            "Epoch [34/200] Batch [104/391] Loss: 0.0677\n",
            "Epoch [34/200] Batch [105/391] Loss: 0.1010\n",
            "Epoch [34/200] Batch [106/391] Loss: 0.0577\n",
            "Epoch [34/200] Batch [107/391] Loss: 0.0738\n",
            "Epoch [34/200] Batch [108/391] Loss: 0.0868\n",
            "Epoch [34/200] Batch [109/391] Loss: 0.1618\n",
            "Epoch [34/200] Batch [110/391] Loss: 0.0574\n",
            "Epoch [34/200] Batch [111/391] Loss: 0.0837\n",
            "Epoch [34/200] Batch [112/391] Loss: 0.2380\n",
            "Epoch [34/200] Batch [113/391] Loss: 0.1304\n",
            "Epoch [34/200] Batch [114/391] Loss: 0.1433\n",
            "Epoch [34/200] Batch [115/391] Loss: 0.0647\n",
            "Epoch [34/200] Batch [116/391] Loss: 0.1216\n",
            "Epoch [34/200] Batch [117/391] Loss: 0.0793\n",
            "Epoch [34/200] Batch [118/391] Loss: 0.1029\n",
            "Epoch [34/200] Batch [119/391] Loss: 0.0700\n",
            "Epoch [34/200] Batch [120/391] Loss: 0.1485\n",
            "Epoch [34/200] Batch [121/391] Loss: 0.1401\n",
            "Epoch [34/200] Batch [122/391] Loss: 0.1059\n",
            "Epoch [34/200] Batch [123/391] Loss: 0.1068\n",
            "Epoch [34/200] Batch [124/391] Loss: 0.0784\n",
            "Epoch [34/200] Batch [125/391] Loss: 0.0792\n",
            "Epoch [34/200] Batch [126/391] Loss: 0.0536\n",
            "Epoch [34/200] Batch [127/391] Loss: 0.0511\n",
            "Epoch [34/200] Batch [128/391] Loss: 0.0697\n",
            "Epoch [34/200] Batch [129/391] Loss: 0.1155\n",
            "Epoch [34/200] Batch [130/391] Loss: 0.1695\n",
            "Epoch [34/200] Batch [131/391] Loss: 0.1601\n",
            "Epoch [34/200] Batch [132/391] Loss: 0.0818\n",
            "Epoch [34/200] Batch [133/391] Loss: 0.1366\n",
            "Epoch [34/200] Batch [134/391] Loss: 0.1127\n",
            "Epoch [34/200] Batch [135/391] Loss: 0.1387\n",
            "Epoch [34/200] Batch [136/391] Loss: 0.1393\n",
            "Epoch [34/200] Batch [137/391] Loss: 0.1136\n",
            "Epoch [34/200] Batch [138/391] Loss: 0.1121\n",
            "Epoch [34/200] Batch [139/391] Loss: 0.1518\n",
            "Epoch [34/200] Batch [140/391] Loss: 0.1275\n",
            "Epoch [34/200] Batch [141/391] Loss: 0.0716\n",
            "Epoch [34/200] Batch [142/391] Loss: 0.1150\n",
            "Epoch [34/200] Batch [143/391] Loss: 0.0958\n",
            "Epoch [34/200] Batch [144/391] Loss: 0.0933\n",
            "Epoch [34/200] Batch [145/391] Loss: 0.1772\n",
            "Epoch [34/200] Batch [146/391] Loss: 0.2040\n",
            "Epoch [34/200] Batch [147/391] Loss: 0.0915\n",
            "Epoch [34/200] Batch [148/391] Loss: 0.0916\n",
            "Epoch [34/200] Batch [149/391] Loss: 0.0661\n",
            "Epoch [34/200] Batch [150/391] Loss: 0.0739\n",
            "Epoch [34/200] Batch [151/391] Loss: 0.0852\n",
            "Epoch [34/200] Batch [152/391] Loss: 0.1769\n",
            "Epoch [34/200] Batch [153/391] Loss: 0.0708\n",
            "Epoch [34/200] Batch [154/391] Loss: 0.1233\n",
            "Epoch [34/200] Batch [155/391] Loss: 0.1547\n",
            "Epoch [34/200] Batch [156/391] Loss: 0.0879\n",
            "Epoch [34/200] Batch [157/391] Loss: 0.1429\n",
            "Epoch [34/200] Batch [158/391] Loss: 0.0930\n",
            "Epoch [34/200] Batch [159/391] Loss: 0.0750\n",
            "Epoch [34/200] Batch [160/391] Loss: 0.1066\n",
            "Epoch [34/200] Batch [161/391] Loss: 0.0853\n",
            "Epoch [34/200] Batch [162/391] Loss: 0.1682\n",
            "Epoch [34/200] Batch [163/391] Loss: 0.0977\n",
            "Epoch [34/200] Batch [164/391] Loss: 0.0918\n",
            "Epoch [34/200] Batch [165/391] Loss: 0.1074\n",
            "Epoch [34/200] Batch [166/391] Loss: 0.1369\n",
            "Epoch [34/200] Batch [167/391] Loss: 0.1589\n",
            "Epoch [34/200] Batch [168/391] Loss: 0.1512\n",
            "Epoch [34/200] Batch [169/391] Loss: 0.1243\n",
            "Epoch [34/200] Batch [170/391] Loss: 0.0868\n",
            "Epoch [34/200] Batch [171/391] Loss: 0.1582\n",
            "Epoch [34/200] Batch [172/391] Loss: 0.0990\n",
            "Epoch [34/200] Batch [173/391] Loss: 0.0879\n",
            "Epoch [34/200] Batch [174/391] Loss: 0.1048\n",
            "Epoch [34/200] Batch [175/391] Loss: 0.1727\n",
            "Epoch [34/200] Batch [176/391] Loss: 0.1467\n",
            "Epoch [34/200] Batch [177/391] Loss: 0.1135\n",
            "Epoch [34/200] Batch [178/391] Loss: 0.1141\n",
            "Epoch [34/200] Batch [179/391] Loss: 0.1842\n",
            "Epoch [34/200] Batch [180/391] Loss: 0.1727\n",
            "Epoch [34/200] Batch [181/391] Loss: 0.1351\n",
            "Epoch [34/200] Batch [182/391] Loss: 0.1049\n",
            "Epoch [34/200] Batch [183/391] Loss: 0.0559\n",
            "Epoch [34/200] Batch [184/391] Loss: 0.0727\n",
            "Epoch [34/200] Batch [185/391] Loss: 0.0932\n",
            "Epoch [34/200] Batch [186/391] Loss: 0.0981\n",
            "Epoch [34/200] Batch [187/391] Loss: 0.1615\n",
            "Epoch [34/200] Batch [188/391] Loss: 0.1191\n",
            "Epoch [34/200] Batch [189/391] Loss: 0.1007\n",
            "Epoch [34/200] Batch [190/391] Loss: 0.1055\n",
            "Epoch [34/200] Batch [191/391] Loss: 0.0736\n",
            "Epoch [34/200] Batch [192/391] Loss: 0.1195\n",
            "Epoch [34/200] Batch [193/391] Loss: 0.0604\n",
            "Epoch [34/200] Batch [194/391] Loss: 0.0815\n",
            "Epoch [34/200] Batch [195/391] Loss: 0.1275\n",
            "Epoch [34/200] Batch [196/391] Loss: 0.1690\n",
            "Epoch [34/200] Batch [197/391] Loss: 0.1718\n",
            "Epoch [34/200] Batch [198/391] Loss: 0.1530\n",
            "Epoch [34/200] Batch [199/391] Loss: 0.1121\n",
            "Epoch [34/200] Batch [200/391] Loss: 0.1318\n",
            "Epoch [34/200] Batch [201/391] Loss: 0.0967\n",
            "Epoch [34/200] Batch [202/391] Loss: 0.1187\n",
            "Epoch [34/200] Batch [203/391] Loss: 0.0983\n",
            "Epoch [34/200] Batch [204/391] Loss: 0.0812\n",
            "Epoch [34/200] Batch [205/391] Loss: 0.0995\n",
            "Epoch [34/200] Batch [206/391] Loss: 0.0902\n",
            "Epoch [34/200] Batch [207/391] Loss: 0.1813\n",
            "Epoch [34/200] Batch [208/391] Loss: 0.1433\n",
            "Epoch [34/200] Batch [209/391] Loss: 0.1217\n",
            "Epoch [34/200] Batch [210/391] Loss: 0.2043\n",
            "Epoch [34/200] Batch [211/391] Loss: 0.1006\n",
            "Epoch [34/200] Batch [212/391] Loss: 0.1074\n",
            "Epoch [34/200] Batch [213/391] Loss: 0.1158\n",
            "Epoch [34/200] Batch [214/391] Loss: 0.1604\n",
            "Epoch [34/200] Batch [215/391] Loss: 0.0746\n",
            "Epoch [34/200] Batch [216/391] Loss: 0.1456\n",
            "Epoch [34/200] Batch [217/391] Loss: 0.0837\n",
            "Epoch [34/200] Batch [218/391] Loss: 0.0635\n",
            "Epoch [34/200] Batch [219/391] Loss: 0.2143\n",
            "Epoch [34/200] Batch [220/391] Loss: 0.1140\n",
            "Epoch [34/200] Batch [221/391] Loss: 0.1895\n",
            "Epoch [34/200] Batch [222/391] Loss: 0.1894\n",
            "Epoch [34/200] Batch [223/391] Loss: 0.0966\n",
            "Epoch [34/200] Batch [224/391] Loss: 0.1967\n",
            "Epoch [34/200] Batch [225/391] Loss: 0.0912\n",
            "Epoch [34/200] Batch [226/391] Loss: 0.0412\n",
            "Epoch [34/200] Batch [227/391] Loss: 0.1984\n",
            "Epoch [34/200] Batch [228/391] Loss: 0.1488\n",
            "Epoch [34/200] Batch [229/391] Loss: 0.1689\n",
            "Epoch [34/200] Batch [230/391] Loss: 0.1977\n",
            "Epoch [34/200] Batch [231/391] Loss: 0.1423\n",
            "Epoch [34/200] Batch [232/391] Loss: 0.0823\n",
            "Epoch [34/200] Batch [233/391] Loss: 0.2169\n",
            "Epoch [34/200] Batch [234/391] Loss: 0.1163\n",
            "Epoch [34/200] Batch [235/391] Loss: 0.1189\n",
            "Epoch [34/200] Batch [236/391] Loss: 0.1199\n",
            "Epoch [34/200] Batch [237/391] Loss: 0.1613\n",
            "Epoch [34/200] Batch [238/391] Loss: 0.1256\n",
            "Epoch [34/200] Batch [239/391] Loss: 0.1450\n",
            "Epoch [34/200] Batch [240/391] Loss: 0.1675\n",
            "Epoch [34/200] Batch [241/391] Loss: 0.0770\n",
            "Epoch [34/200] Batch [242/391] Loss: 0.0703\n",
            "Epoch [34/200] Batch [243/391] Loss: 0.1308\n",
            "Epoch [34/200] Batch [244/391] Loss: 0.1407\n",
            "Epoch [34/200] Batch [245/391] Loss: 0.1462\n",
            "Epoch [34/200] Batch [246/391] Loss: 0.1569\n",
            "Epoch [34/200] Batch [247/391] Loss: 0.1357\n",
            "Epoch [34/200] Batch [248/391] Loss: 0.2219\n",
            "Epoch [34/200] Batch [249/391] Loss: 0.0757\n",
            "Epoch [34/200] Batch [250/391] Loss: 0.1005\n",
            "Epoch [34/200] Batch [251/391] Loss: 0.1178\n",
            "Epoch [34/200] Batch [252/391] Loss: 0.1877\n",
            "Epoch [34/200] Batch [253/391] Loss: 0.1169\n",
            "Epoch [34/200] Batch [254/391] Loss: 0.1302\n",
            "Epoch [34/200] Batch [255/391] Loss: 0.1466\n",
            "Epoch [34/200] Batch [256/391] Loss: 0.1468\n",
            "Epoch [34/200] Batch [257/391] Loss: 0.0953\n",
            "Epoch [34/200] Batch [258/391] Loss: 0.0943\n",
            "Epoch [34/200] Batch [259/391] Loss: 0.1810\n",
            "Epoch [34/200] Batch [260/391] Loss: 0.0847\n",
            "Epoch [34/200] Batch [261/391] Loss: 0.1471\n",
            "Epoch [34/200] Batch [262/391] Loss: 0.1803\n",
            "Epoch [34/200] Batch [263/391] Loss: 0.1158\n",
            "Epoch [34/200] Batch [264/391] Loss: 0.1247\n",
            "Epoch [34/200] Batch [265/391] Loss: 0.0863\n",
            "Epoch [34/200] Batch [266/391] Loss: 0.1557\n",
            "Epoch [34/200] Batch [267/391] Loss: 0.1759\n",
            "Epoch [34/200] Batch [268/391] Loss: 0.1349\n",
            "Epoch [34/200] Batch [269/391] Loss: 0.1990\n",
            "Epoch [34/200] Batch [270/391] Loss: 0.0992\n",
            "Epoch [34/200] Batch [271/391] Loss: 0.1428\n",
            "Epoch [34/200] Batch [272/391] Loss: 0.1697\n",
            "Epoch [34/200] Batch [273/391] Loss: 0.1351\n",
            "Epoch [34/200] Batch [274/391] Loss: 0.1862\n",
            "Epoch [34/200] Batch [275/391] Loss: 0.1498\n",
            "Epoch [34/200] Batch [276/391] Loss: 0.0553\n",
            "Epoch [34/200] Batch [277/391] Loss: 0.1751\n",
            "Epoch [34/200] Batch [278/391] Loss: 0.1953\n",
            "Epoch [34/200] Batch [279/391] Loss: 0.0629\n",
            "Epoch [34/200] Batch [280/391] Loss: 0.0927\n",
            "Epoch [34/200] Batch [281/391] Loss: 0.2328\n",
            "Epoch [34/200] Batch [282/391] Loss: 0.1735\n",
            "Epoch [34/200] Batch [283/391] Loss: 0.2763\n",
            "Epoch [34/200] Batch [284/391] Loss: 0.1584\n",
            "Epoch [34/200] Batch [285/391] Loss: 0.1423\n",
            "Epoch [34/200] Batch [286/391] Loss: 0.2032\n",
            "Epoch [34/200] Batch [287/391] Loss: 0.1317\n",
            "Epoch [34/200] Batch [288/391] Loss: 0.1325\n",
            "Epoch [34/200] Batch [289/391] Loss: 0.0689\n",
            "Epoch [34/200] Batch [290/391] Loss: 0.1221\n",
            "Epoch [34/200] Batch [291/391] Loss: 0.1383\n",
            "Epoch [34/200] Batch [292/391] Loss: 0.0810\n",
            "Epoch [34/200] Batch [293/391] Loss: 0.1168\n",
            "Epoch [34/200] Batch [294/391] Loss: 0.1267\n",
            "Epoch [34/200] Batch [295/391] Loss: 0.1704\n",
            "Epoch [34/200] Batch [296/391] Loss: 0.2208\n",
            "Epoch [34/200] Batch [297/391] Loss: 0.2290\n",
            "Epoch [34/200] Batch [298/391] Loss: 0.2735\n",
            "Epoch [34/200] Batch [299/391] Loss: 0.1107\n",
            "Epoch [34/200] Batch [300/391] Loss: 0.1374\n",
            "Epoch [34/200] Batch [301/391] Loss: 0.1122\n",
            "Epoch [34/200] Batch [302/391] Loss: 0.2277\n",
            "Epoch [34/200] Batch [303/391] Loss: 0.0722\n",
            "Epoch [34/200] Batch [304/391] Loss: 0.1790\n",
            "Epoch [34/200] Batch [305/391] Loss: 0.1279\n",
            "Epoch [34/200] Batch [306/391] Loss: 0.2512\n",
            "Epoch [34/200] Batch [307/391] Loss: 0.1476\n",
            "Epoch [34/200] Batch [308/391] Loss: 0.1594\n",
            "Epoch [34/200] Batch [309/391] Loss: 0.2014\n",
            "Epoch [34/200] Batch [310/391] Loss: 0.1882\n",
            "Epoch [34/200] Batch [311/391] Loss: 0.1426\n",
            "Epoch [34/200] Batch [312/391] Loss: 0.0864\n",
            "Epoch [34/200] Batch [313/391] Loss: 0.0643\n",
            "Epoch [34/200] Batch [314/391] Loss: 0.1659\n",
            "Epoch [34/200] Batch [315/391] Loss: 0.1698\n",
            "Epoch [34/200] Batch [316/391] Loss: 0.1558\n",
            "Epoch [34/200] Batch [317/391] Loss: 0.1666\n",
            "Epoch [34/200] Batch [318/391] Loss: 0.0915\n",
            "Epoch [34/200] Batch [319/391] Loss: 0.1913\n",
            "Epoch [34/200] Batch [320/391] Loss: 0.1352\n",
            "Epoch [34/200] Batch [321/391] Loss: 0.1691\n",
            "Epoch [34/200] Batch [322/391] Loss: 0.1945\n",
            "Epoch [34/200] Batch [323/391] Loss: 0.0840\n",
            "Epoch [34/200] Batch [324/391] Loss: 0.1358\n",
            "Epoch [34/200] Batch [325/391] Loss: 0.1250\n",
            "Epoch [34/200] Batch [326/391] Loss: 0.1320\n",
            "Epoch [34/200] Batch [327/391] Loss: 0.1103\n",
            "Epoch [34/200] Batch [328/391] Loss: 0.1095\n",
            "Epoch [34/200] Batch [329/391] Loss: 0.2261\n",
            "Epoch [34/200] Batch [330/391] Loss: 0.0647\n",
            "Epoch [34/200] Batch [331/391] Loss: 0.1471\n",
            "Epoch [34/200] Batch [332/391] Loss: 0.2050\n",
            "Epoch [34/200] Batch [333/391] Loss: 0.0905\n",
            "Epoch [34/200] Batch [334/391] Loss: 0.1155\n",
            "Epoch [34/200] Batch [335/391] Loss: 0.1286\n",
            "Epoch [34/200] Batch [336/391] Loss: 0.1111\n",
            "Epoch [34/200] Batch [337/391] Loss: 0.1571\n",
            "Epoch [34/200] Batch [338/391] Loss: 0.0805\n",
            "Epoch [34/200] Batch [339/391] Loss: 0.0965\n",
            "Epoch [34/200] Batch [340/391] Loss: 0.0972\n",
            "Epoch [34/200] Batch [341/391] Loss: 0.1306\n",
            "Epoch [34/200] Batch [342/391] Loss: 0.1242\n",
            "Epoch [34/200] Batch [343/391] Loss: 0.1465\n",
            "Epoch [34/200] Batch [344/391] Loss: 0.1230\n",
            "Epoch [34/200] Batch [345/391] Loss: 0.1500\n",
            "Epoch [34/200] Batch [346/391] Loss: 0.0887\n",
            "Epoch [34/200] Batch [347/391] Loss: 0.1265\n",
            "Epoch [34/200] Batch [348/391] Loss: 0.1492\n",
            "Epoch [34/200] Batch [349/391] Loss: 0.1562\n",
            "Epoch [34/200] Batch [350/391] Loss: 0.1541\n",
            "Epoch [34/200] Batch [351/391] Loss: 0.1750\n",
            "Epoch [34/200] Batch [352/391] Loss: 0.1328\n",
            "Epoch [34/200] Batch [353/391] Loss: 0.0799\n",
            "Epoch [34/200] Batch [354/391] Loss: 0.1456\n",
            "Epoch [34/200] Batch [355/391] Loss: 0.1521\n",
            "Epoch [34/200] Batch [356/391] Loss: 0.1881\n",
            "Epoch [34/200] Batch [357/391] Loss: 0.1875\n",
            "Epoch [34/200] Batch [358/391] Loss: 0.1525\n",
            "Epoch [34/200] Batch [359/391] Loss: 0.2318\n",
            "Epoch [34/200] Batch [360/391] Loss: 0.1465\n",
            "Epoch [34/200] Batch [361/391] Loss: 0.0738\n",
            "Epoch [34/200] Batch [362/391] Loss: 0.1391\n",
            "Epoch [34/200] Batch [363/391] Loss: 0.0829\n",
            "Epoch [34/200] Batch [364/391] Loss: 0.1547\n",
            "Epoch [34/200] Batch [365/391] Loss: 0.1163\n",
            "Epoch [34/200] Batch [366/391] Loss: 0.1038\n",
            "Epoch [34/200] Batch [367/391] Loss: 0.0954\n",
            "Epoch [34/200] Batch [368/391] Loss: 0.1571\n",
            "Epoch [34/200] Batch [369/391] Loss: 0.1536\n",
            "Epoch [34/200] Batch [370/391] Loss: 0.1298\n",
            "Epoch [34/200] Batch [371/391] Loss: 0.1307\n",
            "Epoch [34/200] Batch [372/391] Loss: 0.1855\n",
            "Epoch [34/200] Batch [373/391] Loss: 0.1105\n",
            "Epoch [34/200] Batch [374/391] Loss: 0.1439\n",
            "Epoch [34/200] Batch [375/391] Loss: 0.2991\n",
            "Epoch [34/200] Batch [376/391] Loss: 0.0861\n",
            "Epoch [34/200] Batch [377/391] Loss: 0.1426\n",
            "Epoch [34/200] Batch [378/391] Loss: 0.1811\n",
            "Epoch [34/200] Batch [379/391] Loss: 0.0854\n",
            "Epoch [34/200] Batch [380/391] Loss: 0.1440\n",
            "Epoch [34/200] Batch [381/391] Loss: 0.1150\n",
            "Epoch [34/200] Batch [382/391] Loss: 0.0851\n",
            "Epoch [34/200] Batch [383/391] Loss: 0.1363\n",
            "Epoch [34/200] Batch [384/391] Loss: 0.1206\n",
            "Epoch [34/200] Batch [385/391] Loss: 0.1073\n",
            "Epoch [34/200] Batch [386/391] Loss: 0.1738\n",
            "Epoch [34/200] Batch [387/391] Loss: 0.1366\n",
            "Epoch [34/200] Batch [388/391] Loss: 0.1272\n",
            "Epoch [34/200] Batch [389/391] Loss: 0.0853\n",
            "Epoch [34/200] Batch [390/391] Loss: 0.2111\n",
            "Epoch [34/200] Batch [391/391] Loss: 0.0661\n",
            "Epoch [34/200] - Train Loss: 0.1227 - Test Loss: 1.1088 - Train Acc: 84.36% - Test Acc: 74.59%\n",
            "Epoch [35/200] Batch [1/391] Loss: 0.0817\n",
            "Epoch [35/200] Batch [2/391] Loss: 0.1074\n",
            "Epoch [35/200] Batch [3/391] Loss: 0.0902\n",
            "Epoch [35/200] Batch [4/391] Loss: 0.1396\n",
            "Epoch [35/200] Batch [5/391] Loss: 0.0411\n",
            "Epoch [35/200] Batch [6/391] Loss: 0.1167\n",
            "Epoch [35/200] Batch [7/391] Loss: 0.1076\n",
            "Epoch [35/200] Batch [8/391] Loss: 0.1158\n",
            "Epoch [35/200] Batch [9/391] Loss: 0.0836\n",
            "Epoch [35/200] Batch [10/391] Loss: 0.1143\n",
            "Epoch [35/200] Batch [11/391] Loss: 0.0661\n",
            "Epoch [35/200] Batch [12/391] Loss: 0.0645\n",
            "Epoch [35/200] Batch [13/391] Loss: 0.0591\n",
            "Epoch [35/200] Batch [14/391] Loss: 0.0809\n",
            "Epoch [35/200] Batch [15/391] Loss: 0.1549\n",
            "Epoch [35/200] Batch [16/391] Loss: 0.1131\n",
            "Epoch [35/200] Batch [17/391] Loss: 0.0677\n",
            "Epoch [35/200] Batch [18/391] Loss: 0.1057\n",
            "Epoch [35/200] Batch [19/391] Loss: 0.1275\n",
            "Epoch [35/200] Batch [20/391] Loss: 0.0503\n",
            "Epoch [35/200] Batch [21/391] Loss: 0.1168\n",
            "Epoch [35/200] Batch [22/391] Loss: 0.1318\n",
            "Epoch [35/200] Batch [23/391] Loss: 0.0733\n",
            "Epoch [35/200] Batch [24/391] Loss: 0.0999\n",
            "Epoch [35/200] Batch [25/391] Loss: 0.0338\n",
            "Epoch [35/200] Batch [26/391] Loss: 0.1156\n",
            "Epoch [35/200] Batch [27/391] Loss: 0.0574\n",
            "Epoch [35/200] Batch [28/391] Loss: 0.0913\n",
            "Epoch [35/200] Batch [29/391] Loss: 0.0650\n",
            "Epoch [35/200] Batch [30/391] Loss: 0.0881\n",
            "Epoch [35/200] Batch [31/391] Loss: 0.0971\n",
            "Epoch [35/200] Batch [32/391] Loss: 0.0657\n",
            "Epoch [35/200] Batch [33/391] Loss: 0.0852\n",
            "Epoch [35/200] Batch [34/391] Loss: 0.0660\n",
            "Epoch [35/200] Batch [35/391] Loss: 0.0519\n",
            "Epoch [35/200] Batch [36/391] Loss: 0.1383\n",
            "Epoch [35/200] Batch [37/391] Loss: 0.0807\n",
            "Epoch [35/200] Batch [38/391] Loss: 0.1528\n",
            "Epoch [35/200] Batch [39/391] Loss: 0.1228\n",
            "Epoch [35/200] Batch [40/391] Loss: 0.0946\n",
            "Epoch [35/200] Batch [41/391] Loss: 0.0841\n",
            "Epoch [35/200] Batch [42/391] Loss: 0.1263\n",
            "Epoch [35/200] Batch [43/391] Loss: 0.0741\n",
            "Epoch [35/200] Batch [44/391] Loss: 0.0486\n",
            "Epoch [35/200] Batch [45/391] Loss: 0.1083\n",
            "Epoch [35/200] Batch [46/391] Loss: 0.0567\n",
            "Epoch [35/200] Batch [47/391] Loss: 0.1017\n",
            "Epoch [35/200] Batch [48/391] Loss: 0.0691\n",
            "Epoch [35/200] Batch [49/391] Loss: 0.0632\n",
            "Epoch [35/200] Batch [50/391] Loss: 0.0964\n",
            "Epoch [35/200] Batch [51/391] Loss: 0.1197\n",
            "Epoch [35/200] Batch [52/391] Loss: 0.0829\n",
            "Epoch [35/200] Batch [53/391] Loss: 0.1052\n",
            "Epoch [35/200] Batch [54/391] Loss: 0.0565\n",
            "Epoch [35/200] Batch [55/391] Loss: 0.0574\n",
            "Epoch [35/200] Batch [56/391] Loss: 0.1274\n",
            "Epoch [35/200] Batch [57/391] Loss: 0.0847\n",
            "Epoch [35/200] Batch [58/391] Loss: 0.0985\n",
            "Epoch [35/200] Batch [59/391] Loss: 0.1139\n",
            "Epoch [35/200] Batch [60/391] Loss: 0.1079\n",
            "Epoch [35/200] Batch [61/391] Loss: 0.1241\n",
            "Epoch [35/200] Batch [62/391] Loss: 0.0436\n",
            "Epoch [35/200] Batch [63/391] Loss: 0.1160\n",
            "Epoch [35/200] Batch [64/391] Loss: 0.0764\n",
            "Epoch [35/200] Batch [65/391] Loss: 0.0488\n",
            "Epoch [35/200] Batch [66/391] Loss: 0.1007\n",
            "Epoch [35/200] Batch [67/391] Loss: 0.1393\n",
            "Epoch [35/200] Batch [68/391] Loss: 0.0664\n",
            "Epoch [35/200] Batch [69/391] Loss: 0.0568\n",
            "Epoch [35/200] Batch [70/391] Loss: 0.0730\n",
            "Epoch [35/200] Batch [71/391] Loss: 0.0883\n",
            "Epoch [35/200] Batch [72/391] Loss: 0.1316\n",
            "Epoch [35/200] Batch [73/391] Loss: 0.0737\n",
            "Epoch [35/200] Batch [74/391] Loss: 0.0599\n",
            "Epoch [35/200] Batch [75/391] Loss: 0.0575\n",
            "Epoch [35/200] Batch [76/391] Loss: 0.1606\n",
            "Epoch [35/200] Batch [77/391] Loss: 0.0509\n",
            "Epoch [35/200] Batch [78/391] Loss: 0.1685\n",
            "Epoch [35/200] Batch [79/391] Loss: 0.0669\n",
            "Epoch [35/200] Batch [80/391] Loss: 0.0651\n",
            "Epoch [35/200] Batch [81/391] Loss: 0.0953\n",
            "Epoch [35/200] Batch [82/391] Loss: 0.0601\n",
            "Epoch [35/200] Batch [83/391] Loss: 0.1759\n",
            "Epoch [35/200] Batch [84/391] Loss: 0.0816\n",
            "Epoch [35/200] Batch [85/391] Loss: 0.0394\n",
            "Epoch [35/200] Batch [86/391] Loss: 0.0571\n",
            "Epoch [35/200] Batch [87/391] Loss: 0.0911\n",
            "Epoch [35/200] Batch [88/391] Loss: 0.1531\n",
            "Epoch [35/200] Batch [89/391] Loss: 0.1575\n",
            "Epoch [35/200] Batch [90/391] Loss: 0.0648\n",
            "Epoch [35/200] Batch [91/391] Loss: 0.0979\n",
            "Epoch [35/200] Batch [92/391] Loss: 0.0746\n",
            "Epoch [35/200] Batch [93/391] Loss: 0.0987\n",
            "Epoch [35/200] Batch [94/391] Loss: 0.0646\n",
            "Epoch [35/200] Batch [95/391] Loss: 0.0992\n",
            "Epoch [35/200] Batch [96/391] Loss: 0.0662\n",
            "Epoch [35/200] Batch [97/391] Loss: 0.0803\n",
            "Epoch [35/200] Batch [98/391] Loss: 0.0483\n",
            "Epoch [35/200] Batch [99/391] Loss: 0.1302\n",
            "Epoch [35/200] Batch [100/391] Loss: 0.1008\n",
            "Epoch [35/200] Batch [101/391] Loss: 0.1050\n",
            "Epoch [35/200] Batch [102/391] Loss: 0.0684\n",
            "Epoch [35/200] Batch [103/391] Loss: 0.0779\n",
            "Epoch [35/200] Batch [104/391] Loss: 0.0741\n",
            "Epoch [35/200] Batch [105/391] Loss: 0.0922\n",
            "Epoch [35/200] Batch [106/391] Loss: 0.1377\n",
            "Epoch [35/200] Batch [107/391] Loss: 0.0928\n",
            "Epoch [35/200] Batch [108/391] Loss: 0.1003\n",
            "Epoch [35/200] Batch [109/391] Loss: 0.1240\n",
            "Epoch [35/200] Batch [110/391] Loss: 0.1416\n",
            "Epoch [35/200] Batch [111/391] Loss: 0.1339\n",
            "Epoch [35/200] Batch [112/391] Loss: 0.0535\n",
            "Epoch [35/200] Batch [113/391] Loss: 0.1329\n",
            "Epoch [35/200] Batch [114/391] Loss: 0.1222\n",
            "Epoch [35/200] Batch [115/391] Loss: 0.0753\n",
            "Epoch [35/200] Batch [116/391] Loss: 0.0904\n",
            "Epoch [35/200] Batch [117/391] Loss: 0.0500\n",
            "Epoch [35/200] Batch [118/391] Loss: 0.0985\n",
            "Epoch [35/200] Batch [119/391] Loss: 0.0555\n",
            "Epoch [35/200] Batch [120/391] Loss: 0.1136\n",
            "Epoch [35/200] Batch [121/391] Loss: 0.0719\n",
            "Epoch [35/200] Batch [122/391] Loss: 0.0472\n",
            "Epoch [35/200] Batch [123/391] Loss: 0.0578\n",
            "Epoch [35/200] Batch [124/391] Loss: 0.0579\n",
            "Epoch [35/200] Batch [125/391] Loss: 0.0722\n",
            "Epoch [35/200] Batch [126/391] Loss: 0.1435\n",
            "Epoch [35/200] Batch [127/391] Loss: 0.0629\n",
            "Epoch [35/200] Batch [128/391] Loss: 0.1312\n",
            "Epoch [35/200] Batch [129/391] Loss: 0.0747\n",
            "Epoch [35/200] Batch [130/391] Loss: 0.1102\n",
            "Epoch [35/200] Batch [131/391] Loss: 0.0685\n",
            "Epoch [35/200] Batch [132/391] Loss: 0.0599\n",
            "Epoch [35/200] Batch [133/391] Loss: 0.0953\n",
            "Epoch [35/200] Batch [134/391] Loss: 0.0722\n",
            "Epoch [35/200] Batch [135/391] Loss: 0.1307\n",
            "Epoch [35/200] Batch [136/391] Loss: 0.0561\n",
            "Epoch [35/200] Batch [137/391] Loss: 0.0462\n",
            "Epoch [35/200] Batch [138/391] Loss: 0.1312\n",
            "Epoch [35/200] Batch [139/391] Loss: 0.1278\n",
            "Epoch [35/200] Batch [140/391] Loss: 0.0182\n",
            "Epoch [35/200] Batch [141/391] Loss: 0.1200\n",
            "Epoch [35/200] Batch [142/391] Loss: 0.0521\n",
            "Epoch [35/200] Batch [143/391] Loss: 0.1275\n",
            "Epoch [35/200] Batch [144/391] Loss: 0.0483\n",
            "Epoch [35/200] Batch [145/391] Loss: 0.0315\n",
            "Epoch [35/200] Batch [146/391] Loss: 0.1377\n",
            "Epoch [35/200] Batch [147/391] Loss: 0.0873\n",
            "Epoch [35/200] Batch [148/391] Loss: 0.0508\n",
            "Epoch [35/200] Batch [149/391] Loss: 0.0793\n",
            "Epoch [35/200] Batch [150/391] Loss: 0.1130\n",
            "Epoch [35/200] Batch [151/391] Loss: 0.0751\n",
            "Epoch [35/200] Batch [152/391] Loss: 0.0791\n",
            "Epoch [35/200] Batch [153/391] Loss: 0.1225\n",
            "Epoch [35/200] Batch [154/391] Loss: 0.0402\n",
            "Epoch [35/200] Batch [155/391] Loss: 0.0579\n",
            "Epoch [35/200] Batch [156/391] Loss: 0.1450\n",
            "Epoch [35/200] Batch [157/391] Loss: 0.0757\n",
            "Epoch [35/200] Batch [158/391] Loss: 0.1008\n",
            "Epoch [35/200] Batch [159/391] Loss: 0.0919\n",
            "Epoch [35/200] Batch [160/391] Loss: 0.0435\n",
            "Epoch [35/200] Batch [161/391] Loss: 0.1038\n",
            "Epoch [35/200] Batch [162/391] Loss: 0.0739\n",
            "Epoch [35/200] Batch [163/391] Loss: 0.0953\n",
            "Epoch [35/200] Batch [164/391] Loss: 0.1333\n",
            "Epoch [35/200] Batch [165/391] Loss: 0.0446\n",
            "Epoch [35/200] Batch [166/391] Loss: 0.1315\n",
            "Epoch [35/200] Batch [167/391] Loss: 0.1101\n",
            "Epoch [35/200] Batch [168/391] Loss: 0.0697\n",
            "Epoch [35/200] Batch [169/391] Loss: 0.0672\n",
            "Epoch [35/200] Batch [170/391] Loss: 0.1182\n",
            "Epoch [35/200] Batch [171/391] Loss: 0.1086\n",
            "Epoch [35/200] Batch [172/391] Loss: 0.1405\n",
            "Epoch [35/200] Batch [173/391] Loss: 0.0775\n",
            "Epoch [35/200] Batch [174/391] Loss: 0.0794\n",
            "Epoch [35/200] Batch [175/391] Loss: 0.1456\n",
            "Epoch [35/200] Batch [176/391] Loss: 0.0767\n",
            "Epoch [35/200] Batch [177/391] Loss: 0.1177\n",
            "Epoch [35/200] Batch [178/391] Loss: 0.0711\n",
            "Epoch [35/200] Batch [179/391] Loss: 0.1195\n",
            "Epoch [35/200] Batch [180/391] Loss: 0.1038\n",
            "Epoch [35/200] Batch [181/391] Loss: 0.0397\n",
            "Epoch [35/200] Batch [182/391] Loss: 0.1253\n",
            "Epoch [35/200] Batch [183/391] Loss: 0.1156\n",
            "Epoch [35/200] Batch [184/391] Loss: 0.0496\n",
            "Epoch [35/200] Batch [185/391] Loss: 0.1017\n",
            "Epoch [35/200] Batch [186/391] Loss: 0.0745\n",
            "Epoch [35/200] Batch [187/391] Loss: 0.1242\n",
            "Epoch [35/200] Batch [188/391] Loss: 0.1073\n",
            "Epoch [35/200] Batch [189/391] Loss: 0.1157\n",
            "Epoch [35/200] Batch [190/391] Loss: 0.0858\n",
            "Epoch [35/200] Batch [191/391] Loss: 0.1020\n",
            "Epoch [35/200] Batch [192/391] Loss: 0.0746\n",
            "Epoch [35/200] Batch [193/391] Loss: 0.0767\n",
            "Epoch [35/200] Batch [194/391] Loss: 0.1334\n",
            "Epoch [35/200] Batch [195/391] Loss: 0.1104\n",
            "Epoch [35/200] Batch [196/391] Loss: 0.1052\n",
            "Epoch [35/200] Batch [197/391] Loss: 0.1265\n",
            "Epoch [35/200] Batch [198/391] Loss: 0.0726\n",
            "Epoch [35/200] Batch [199/391] Loss: 0.0713\n",
            "Epoch [35/200] Batch [200/391] Loss: 0.0591\n",
            "Epoch [35/200] Batch [201/391] Loss: 0.0461\n",
            "Epoch [35/200] Batch [202/391] Loss: 0.0940\n",
            "Epoch [35/200] Batch [203/391] Loss: 0.0814\n",
            "Epoch [35/200] Batch [204/391] Loss: 0.0841\n",
            "Epoch [35/200] Batch [205/391] Loss: 0.1643\n",
            "Epoch [35/200] Batch [206/391] Loss: 0.0553\n",
            "Epoch [35/200] Batch [207/391] Loss: 0.1332\n",
            "Epoch [35/200] Batch [208/391] Loss: 0.1097\n",
            "Epoch [35/200] Batch [209/391] Loss: 0.1821\n",
            "Epoch [35/200] Batch [210/391] Loss: 0.1128\n",
            "Epoch [35/200] Batch [211/391] Loss: 0.1821\n",
            "Epoch [35/200] Batch [212/391] Loss: 0.0970\n",
            "Epoch [35/200] Batch [213/391] Loss: 0.0776\n",
            "Epoch [35/200] Batch [214/391] Loss: 0.1125\n",
            "Epoch [35/200] Batch [215/391] Loss: 0.2126\n",
            "Epoch [35/200] Batch [216/391] Loss: 0.0946\n",
            "Epoch [35/200] Batch [217/391] Loss: 0.1087\n",
            "Epoch [35/200] Batch [218/391] Loss: 0.1064\n",
            "Epoch [35/200] Batch [219/391] Loss: 0.1058\n",
            "Epoch [35/200] Batch [220/391] Loss: 0.0972\n",
            "Epoch [35/200] Batch [221/391] Loss: 0.0640\n",
            "Epoch [35/200] Batch [222/391] Loss: 0.0981\n",
            "Epoch [35/200] Batch [223/391] Loss: 0.1028\n",
            "Epoch [35/200] Batch [224/391] Loss: 0.0658\n",
            "Epoch [35/200] Batch [225/391] Loss: 0.0949\n",
            "Epoch [35/200] Batch [226/391] Loss: 0.1534\n",
            "Epoch [35/200] Batch [227/391] Loss: 0.1361\n",
            "Epoch [35/200] Batch [228/391] Loss: 0.0819\n",
            "Epoch [35/200] Batch [229/391] Loss: 0.0790\n",
            "Epoch [35/200] Batch [230/391] Loss: 0.0587\n",
            "Epoch [35/200] Batch [231/391] Loss: 0.1169\n",
            "Epoch [35/200] Batch [232/391] Loss: 0.1842\n",
            "Epoch [35/200] Batch [233/391] Loss: 0.1255\n",
            "Epoch [35/200] Batch [234/391] Loss: 0.1224\n",
            "Epoch [35/200] Batch [235/391] Loss: 0.0583\n",
            "Epoch [35/200] Batch [236/391] Loss: 0.0556\n",
            "Epoch [35/200] Batch [237/391] Loss: 0.0398\n",
            "Epoch [35/200] Batch [238/391] Loss: 0.1156\n",
            "Epoch [35/200] Batch [239/391] Loss: 0.0813\n",
            "Epoch [35/200] Batch [240/391] Loss: 0.0739\n",
            "Epoch [35/200] Batch [241/391] Loss: 0.1586\n",
            "Epoch [35/200] Batch [242/391] Loss: 0.1504\n",
            "Epoch [35/200] Batch [243/391] Loss: 0.0588\n",
            "Epoch [35/200] Batch [244/391] Loss: 0.2182\n",
            "Epoch [35/200] Batch [245/391] Loss: 0.1134\n",
            "Epoch [35/200] Batch [246/391] Loss: 0.0788\n",
            "Epoch [35/200] Batch [247/391] Loss: 0.0718\n",
            "Epoch [35/200] Batch [248/391] Loss: 0.1074\n",
            "Epoch [35/200] Batch [249/391] Loss: 0.1375\n",
            "Epoch [35/200] Batch [250/391] Loss: 0.1009\n",
            "Epoch [35/200] Batch [251/391] Loss: 0.1372\n",
            "Epoch [35/200] Batch [252/391] Loss: 0.1033\n",
            "Epoch [35/200] Batch [253/391] Loss: 0.0757\n",
            "Epoch [35/200] Batch [254/391] Loss: 0.1286\n",
            "Epoch [35/200] Batch [255/391] Loss: 0.0851\n",
            "Epoch [35/200] Batch [256/391] Loss: 0.1431\n",
            "Epoch [35/200] Batch [257/391] Loss: 0.0927\n",
            "Epoch [35/200] Batch [258/391] Loss: 0.0972\n",
            "Epoch [35/200] Batch [259/391] Loss: 0.0603\n",
            "Epoch [35/200] Batch [260/391] Loss: 0.0900\n",
            "Epoch [35/200] Batch [261/391] Loss: 0.0858\n",
            "Epoch [35/200] Batch [262/391] Loss: 0.0490\n",
            "Epoch [35/200] Batch [263/391] Loss: 0.1431\n",
            "Epoch [35/200] Batch [264/391] Loss: 0.1876\n",
            "Epoch [35/200] Batch [265/391] Loss: 0.0706\n",
            "Epoch [35/200] Batch [266/391] Loss: 0.0752\n",
            "Epoch [35/200] Batch [267/391] Loss: 0.0886\n",
            "Epoch [35/200] Batch [268/391] Loss: 0.1069\n",
            "Epoch [35/200] Batch [269/391] Loss: 0.2001\n",
            "Epoch [35/200] Batch [270/391] Loss: 0.0944\n",
            "Epoch [35/200] Batch [271/391] Loss: 0.0812\n",
            "Epoch [35/200] Batch [272/391] Loss: 0.1495\n",
            "Epoch [35/200] Batch [273/391] Loss: 0.0645\n",
            "Epoch [35/200] Batch [274/391] Loss: 0.1111\n",
            "Epoch [35/200] Batch [275/391] Loss: 0.0911\n",
            "Epoch [35/200] Batch [276/391] Loss: 0.1591\n",
            "Epoch [35/200] Batch [277/391] Loss: 0.0560\n",
            "Epoch [35/200] Batch [278/391] Loss: 0.1355\n",
            "Epoch [35/200] Batch [279/391] Loss: 0.1340\n",
            "Epoch [35/200] Batch [280/391] Loss: 0.1282\n",
            "Epoch [35/200] Batch [281/391] Loss: 0.1808\n",
            "Epoch [35/200] Batch [282/391] Loss: 0.1066\n",
            "Epoch [35/200] Batch [283/391] Loss: 0.0716\n",
            "Epoch [35/200] Batch [284/391] Loss: 0.0709\n",
            "Epoch [35/200] Batch [285/391] Loss: 0.1019\n",
            "Epoch [35/200] Batch [286/391] Loss: 0.0613\n",
            "Epoch [35/200] Batch [287/391] Loss: 0.1497\n",
            "Epoch [35/200] Batch [288/391] Loss: 0.0524\n",
            "Epoch [35/200] Batch [289/391] Loss: 0.1333\n",
            "Epoch [35/200] Batch [290/391] Loss: 0.1993\n",
            "Epoch [35/200] Batch [291/391] Loss: 0.1103\n",
            "Epoch [35/200] Batch [292/391] Loss: 0.1216\n",
            "Epoch [35/200] Batch [293/391] Loss: 0.0694\n",
            "Epoch [35/200] Batch [294/391] Loss: 0.0603\n",
            "Epoch [35/200] Batch [295/391] Loss: 0.1744\n",
            "Epoch [35/200] Batch [296/391] Loss: 0.1109\n",
            "Epoch [35/200] Batch [297/391] Loss: 0.1169\n",
            "Epoch [35/200] Batch [298/391] Loss: 0.1466\n",
            "Epoch [35/200] Batch [299/391] Loss: 0.0615\n",
            "Epoch [35/200] Batch [300/391] Loss: 0.0902\n",
            "Epoch [35/200] Batch [301/391] Loss: 0.1420\n",
            "Epoch [35/200] Batch [302/391] Loss: 0.0886\n",
            "Epoch [35/200] Batch [303/391] Loss: 0.1207\n",
            "Epoch [35/200] Batch [304/391] Loss: 0.1445\n",
            "Epoch [35/200] Batch [305/391] Loss: 0.1148\n",
            "Epoch [35/200] Batch [306/391] Loss: 0.0664\n",
            "Epoch [35/200] Batch [307/391] Loss: 0.1365\n",
            "Epoch [35/200] Batch [308/391] Loss: 0.1383\n",
            "Epoch [35/200] Batch [309/391] Loss: 0.0646\n",
            "Epoch [35/200] Batch [310/391] Loss: 0.1264\n",
            "Epoch [35/200] Batch [311/391] Loss: 0.0754\n",
            "Epoch [35/200] Batch [312/391] Loss: 0.1004\n",
            "Epoch [35/200] Batch [313/391] Loss: 0.1094\n",
            "Epoch [35/200] Batch [314/391] Loss: 0.1024\n",
            "Epoch [35/200] Batch [315/391] Loss: 0.1339\n",
            "Epoch [35/200] Batch [316/391] Loss: 0.0780\n",
            "Epoch [35/200] Batch [317/391] Loss: 0.1333\n",
            "Epoch [35/200] Batch [318/391] Loss: 0.1578\n",
            "Epoch [35/200] Batch [319/391] Loss: 0.1918\n",
            "Epoch [35/200] Batch [320/391] Loss: 0.0611\n",
            "Epoch [35/200] Batch [321/391] Loss: 0.1100\n",
            "Epoch [35/200] Batch [322/391] Loss: 0.0906\n",
            "Epoch [35/200] Batch [323/391] Loss: 0.1250\n",
            "Epoch [35/200] Batch [324/391] Loss: 0.1192\n",
            "Epoch [35/200] Batch [325/391] Loss: 0.2164\n",
            "Epoch [35/200] Batch [326/391] Loss: 0.1324\n",
            "Epoch [35/200] Batch [327/391] Loss: 0.1628\n",
            "Epoch [35/200] Batch [328/391] Loss: 0.1582\n",
            "Epoch [35/200] Batch [329/391] Loss: 0.1068\n",
            "Epoch [35/200] Batch [330/391] Loss: 0.0861\n",
            "Epoch [35/200] Batch [331/391] Loss: 0.1274\n",
            "Epoch [35/200] Batch [332/391] Loss: 0.1195\n",
            "Epoch [35/200] Batch [333/391] Loss: 0.1419\n",
            "Epoch [35/200] Batch [334/391] Loss: 0.1492\n",
            "Epoch [35/200] Batch [335/391] Loss: 0.0973\n",
            "Epoch [35/200] Batch [336/391] Loss: 0.2252\n",
            "Epoch [35/200] Batch [337/391] Loss: 0.1122\n",
            "Epoch [35/200] Batch [338/391] Loss: 0.0573\n",
            "Epoch [35/200] Batch [339/391] Loss: 0.1228\n",
            "Epoch [35/200] Batch [340/391] Loss: 0.1950\n",
            "Epoch [35/200] Batch [341/391] Loss: 0.1108\n",
            "Epoch [35/200] Batch [342/391] Loss: 0.0922\n",
            "Epoch [35/200] Batch [343/391] Loss: 0.0653\n",
            "Epoch [35/200] Batch [344/391] Loss: 0.1208\n",
            "Epoch [35/200] Batch [345/391] Loss: 0.1770\n",
            "Epoch [35/200] Batch [346/391] Loss: 0.1408\n",
            "Epoch [35/200] Batch [347/391] Loss: 0.1515\n",
            "Epoch [35/200] Batch [348/391] Loss: 0.1489\n",
            "Epoch [35/200] Batch [349/391] Loss: 0.1234\n",
            "Epoch [35/200] Batch [350/391] Loss: 0.1179\n",
            "Epoch [35/200] Batch [351/391] Loss: 0.1131\n",
            "Epoch [35/200] Batch [352/391] Loss: 0.0970\n",
            "Epoch [35/200] Batch [353/391] Loss: 0.1196\n",
            "Epoch [35/200] Batch [354/391] Loss: 0.0918\n",
            "Epoch [35/200] Batch [355/391] Loss: 0.0638\n",
            "Epoch [35/200] Batch [356/391] Loss: 0.0867\n",
            "Epoch [35/200] Batch [357/391] Loss: 0.1201\n",
            "Epoch [35/200] Batch [358/391] Loss: 0.1944\n",
            "Epoch [35/200] Batch [359/391] Loss: 0.1257\n",
            "Epoch [35/200] Batch [360/391] Loss: 0.1147\n",
            "Epoch [35/200] Batch [361/391] Loss: 0.1026\n",
            "Epoch [35/200] Batch [362/391] Loss: 0.1365\n",
            "Epoch [35/200] Batch [363/391] Loss: 0.1093\n",
            "Epoch [35/200] Batch [364/391] Loss: 0.1244\n",
            "Epoch [35/200] Batch [365/391] Loss: 0.1722\n",
            "Epoch [35/200] Batch [366/391] Loss: 0.2688\n",
            "Epoch [35/200] Batch [367/391] Loss: 0.0699\n",
            "Epoch [35/200] Batch [368/391] Loss: 0.0394\n",
            "Epoch [35/200] Batch [369/391] Loss: 0.1150\n",
            "Epoch [35/200] Batch [370/391] Loss: 0.1631\n",
            "Epoch [35/200] Batch [371/391] Loss: 0.1323\n",
            "Epoch [35/200] Batch [372/391] Loss: 0.1343\n",
            "Epoch [35/200] Batch [373/391] Loss: 0.1668\n",
            "Epoch [35/200] Batch [374/391] Loss: 0.0833\n",
            "Epoch [35/200] Batch [375/391] Loss: 0.1033\n",
            "Epoch [35/200] Batch [376/391] Loss: 0.1412\n",
            "Epoch [35/200] Batch [377/391] Loss: 0.1251\n",
            "Epoch [35/200] Batch [378/391] Loss: 0.0875\n",
            "Epoch [35/200] Batch [379/391] Loss: 0.0890\n",
            "Epoch [35/200] Batch [380/391] Loss: 0.1573\n",
            "Epoch [35/200] Batch [381/391] Loss: 0.1404\n",
            "Epoch [35/200] Batch [382/391] Loss: 0.0650\n",
            "Epoch [35/200] Batch [383/391] Loss: 0.0832\n",
            "Epoch [35/200] Batch [384/391] Loss: 0.0706\n",
            "Epoch [35/200] Batch [385/391] Loss: 0.0685\n",
            "Epoch [35/200] Batch [386/391] Loss: 0.0555\n",
            "Epoch [35/200] Batch [387/391] Loss: 0.0626\n",
            "Epoch [35/200] Batch [388/391] Loss: 0.2779\n",
            "Epoch [35/200] Batch [389/391] Loss: 0.1251\n",
            "Epoch [35/200] Batch [390/391] Loss: 0.1038\n",
            "Epoch [35/200] Batch [391/391] Loss: 0.1684\n",
            "Epoch [35/200] - Train Loss: 0.1024 - Test Loss: 1.1720 - Train Acc: 82.46% - Test Acc: 74.25%\n",
            "Early stopping triggered. No improvement in test loss for 10 epochs.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# enable cuda for faster gpu\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# modified architecture parameters:\n",
        "# 7 intermediate blocks instead of 3\n",
        "#  7 convolutional layers per block instead of 3\n",
        "#  Constant 64 channels for all blocks\n",
        "model = CustomCNN(\n",
        "    in_channels=3,\n",
        "    num_blocks=7,\n",
        "    num_convs_per_block=7,\n",
        "    base_channels=64,\n",
        "    num_classes=10,\n",
        "    hidden_dim=64\n",
        ").to(device)\n",
        "\n",
        "#Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0007, weight_decay=1e-4)\n",
        "\n",
        "# scheduler\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n",
        "\n",
        "#parameters\n",
        "num_epochs = 200\n",
        "train_losses = []              # Average loss per epoch\n",
        "test_losses = []               # Average test loss per epoch\n",
        "train_batch_losses = []        # List of lists: each inner list contains losses for each training batch in that epoch\n",
        "train_accuracies = []          # Training accuracy per epoch\n",
        "test_accuracies = []           # testing accuracy per epoch\n",
        "\n",
        "# Early stopping\n",
        "patience = 10\n",
        "best_loss = float('inf')\n",
        "epochs_without_improvement = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    epoch_batch_losses = []\n",
        "\n",
        "    # Training over batches\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()          # backpropagation\n",
        "        optimizer.step()         # Update weights\n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        running_loss += batch_loss             # accumulate loss for the epoch\n",
        "        epoch_batch_losses.append(batch_loss)  # store this batch loss\n",
        "\n",
        "        # Print the loss for training batch\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] Batch [{batch_idx+1}/{len(train_loader)}] Loss: {batch_loss:.4f}\")\n",
        "\n",
        "\n",
        "    train_batch_losses.append(epoch_batch_losses)\n",
        "\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    train_losses.append(avg_loss)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # evaluation - train\n",
        "    model.eval()\n",
        "    train_correct, train_total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "    train_acc = 100 * train_correct / train_total\n",
        "    train_accuracies.append(train_acc)\n",
        "\n",
        "    # evaluation - test\n",
        "    test_correct, test_total = 0, 0\n",
        "    test_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            test_total += labels.size(0)\n",
        "            test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # average test loss and accuracy\n",
        "    avg_test_loss = test_loss / len(test_loader)\n",
        "    test_losses.append(avg_test_loss)\n",
        "    test_acc = 100 * test_correct / test_total\n",
        "    test_accuracies.append(test_acc)\n",
        "\n",
        "    # epoch-level statistics\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {avg_loss:.4f} - Test Loss: {avg_test_loss:.4f} - Train Acc: {train_acc:.2f}% - Test Acc: {test_acc:.2f}%\")\n",
        "\n",
        "    # Early Stoppinng\n",
        "    if avg_test_loss < best_loss:\n",
        "        best_loss = avg_test_loss\n",
        "        epochs_without_improvement = 0\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "        print(f\"Saved new best model with test loss: {avg_test_loss:.4f}\")\n",
        "    else:\n",
        "        epochs_without_improvement += 1\n",
        "\n",
        "    if epochs_without_improvement >= patience:\n",
        "        print(\"Early stopping triggered. No improvement in test loss for\", patience, \"epochs.\")\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsKmg-VPoqYN"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'custom_cnn.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#accuracy per epoch for train & test sets\n",
        "epochs = range(1, len(train_accuracies) + 1)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(epochs, train_accuracies, label='Training Accuracy', marker='o')\n",
        "plt.plot(epochs, test_accuracies, label='Testing Accuracy', marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Training and Testing Accuracy over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "ev2SNqmMK9ca",
        "outputId": "447d8662-771e-4d6b-dc94-4f1f9bff6f89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# training loss per batch for each epoch\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "for epoch_idx, batch_losses in enumerate(train_batch_losses):\n",
        "    batch_indices = np.arange(1, len(batch_losses) + 1)\n",
        "    plt.plot(batch_indices, batch_losses, label=f\"Epoch {epoch_idx + 1}\")\n",
        "\n",
        "plt.xlabel(\"Batch Number\")\n",
        "plt.ylabel(\"Training Loss\")\n",
        "plt.title(\"Training Loss per Batch Across Epochs\")\n",
        "plt.legend(loc='upper right', bbox_to_anchor=(1.2, 1.0), fontsize='small')\n",
        "plt.grid(True)\n",
        "\n",
        "# Save the figure\n",
        "plt.savefig(\"train_loss_per_batch_per_epoch.png\", bbox_inches='tight', dpi=300)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "C1gagBhQRUX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HBfeW3atLP3-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}